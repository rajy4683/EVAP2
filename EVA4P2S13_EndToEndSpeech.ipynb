{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4P2S13_EndToEndSpeech.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f6e3b0a089245f8a01a9b046aa08f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af3aca4a0ada47e991c5ee8a8f9d4dd6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a34bc12c6e449cb9996e6836d97f20c",
              "IPY_MODEL_3a49cd59e48241cabf80f9c04368efab"
            ]
          }
        },
        "af3aca4a0ada47e991c5ee8a8f9d4dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a34bc12c6e449cb9996e6836d97f20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_167d87f38572475fa5d7a0655e2321fc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6387309499,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6387309499,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1a43927a9034fdaa074d0945cc2255d"
          }
        },
        "3a49cd59e48241cabf80f9c04368efab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2afe7a21ba174c8f971bcc62f2b20595",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.95G/5.95G [27:54&lt;00:00, 3.81MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55d4606b360e410aa317d30f767c923a"
          }
        },
        "167d87f38572475fa5d7a0655e2321fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1a43927a9034fdaa074d0945cc2255d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2afe7a21ba174c8f971bcc62f2b20595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55d4606b360e410aa317d30f767c923a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f01d75959294a7aa4f7cce06752ef14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_156d986dc2864d508967518245297ba7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31cf638896ce47e5a7f2f616af580358",
              "IPY_MODEL_6d3589907f2f4a6d90312ddb1d2febae"
            ]
          }
        },
        "156d986dc2864d508967518245297ba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31cf638896ce47e5a7f2f616af580358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0281a505220485990d55729f1d5390e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 346663984,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 346663984,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e616dda39e4b447eaa7d773deb42ae3f"
          }
        },
        "6d3589907f2f4a6d90312ddb1d2febae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b301b06111b84d898a641a6bc36226f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:20&lt;00:00, 16.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7233066e39f4a3ab2bb678a8dba3bc9"
          }
        },
        "a0281a505220485990d55729f1d5390e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e616dda39e4b447eaa7d773deb42ae3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b301b06111b84d898a641a6bc36226f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7233066e39f4a3ab2bb678a8dba3bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/EVAP2/blob/master/EVA4P2S13_EndToEndSpeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibD6bsRPl8Qu"
      },
      "source": [
        "# Building an end-to-end Speech Recognition model in PyTorch - [AssemblyAI](https://www.assemblyai.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipt6Qiu0IRhq",
        "outputId": "dddd6ede-7134-4e3f-fa02-597c46e618bc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Nov 28 04:20:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fXgsDQmK09"
      },
      "source": [
        "## installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utq5aJcai77-",
        "outputId": "87ed1ea7-8e86-4594-d7da-36ab998d65c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkQItq6GqyEf",
        "outputId": "af2da5ac-477e-47ee-bc13-6a9bc4ed6d38"
      },
      "source": [
        "!pip install torch==1.5.0+cu92 torchvision==0.6.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (603.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 603.7MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (6.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.5MB 58.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu92) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0+cu92) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.0+cu92) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.5.0+cu92 torchvision-0.6.0+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ZQoYZETVQ5"
      },
      "source": [
        "!mkdir ./data && cp /content/drive/MyDrive/P2S13/* ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfN8o17Bdp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a592807-f441-479c-f264-48689ed67265"
      },
      "source": [
        "!pip install torchaudio==0.5.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/7d/8e01e21175dd2c9bb1b7e014e0c56cdd02618e2db5bebb4f52f6fdf253cb/torchaudio-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio==0.5.0) (1.5.0+cu92)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchaudio==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchaudio==0.5.0) (1.18.5)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKHvy8DmOCQ"
      },
      "source": [
        "## Setting up your data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVJs4Bk8FjjO"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths\n",
        "\n",
        "\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XdSlhAQnDEA"
      },
      "source": [
        "## The Model\n",
        "Base of of Deep Speech 2 with some personal improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65H1-PCjm-FB"
      },
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuguNEzKnMOn"
      },
      "source": [
        "## The Training and Evaluating Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydkqGeOwnPGY"
      },
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data \n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms)  # (batch, time, n_class)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        iter_meter.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter, best_test_loss):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data \n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "    if (test_loss < best_test_loss):\n",
        "        print(\"Saving model as current test_loss {} < prev test_loss {}\".format(test_loss,  best_test_loss))\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model, \"/content/drive/MyDrive/P2S13/aisound3.pt\")\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "    return best_test_loss\n",
        "\n",
        "\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10,\n",
        "        train_url=\"train-clean-100\", test_url=\"test-clean\", model=None):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    best_test_loss = 10000\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "    if model is None:\n",
        "        model = SpeechRecognitionModel(\n",
        "            hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "            hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "            ).to(device)\n",
        "\n",
        "    #print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "    \n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
        "        best_test_loss = test(model, device, test_loader, criterion, epoch, iter_meter,best_test_loss)\n",
        "    return model,best_test_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxRIb_WempDq"
      },
      "source": [
        "## GPU runtime\n",
        "If you are using a GPU runtime, this will let you know what GPU and how much memory is available. Adjust your batch_size depending on which GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXvlWZeVpXfX"
      },
      "source": [
        "## Train\n",
        "this will download the data on first run and may take a while. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZodve8PGKfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fe009d-b28c-4827-c5fb-0b50f2e7169d"
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpeechRecognitionModel(\n",
            "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (rescnn_layers): Sequential(\n",
            "    (0): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualCNN(\n",
            "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (dropout1): Dropout(p=0.1, inplace=False)\n",
            "      (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      (layer_norm1): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (layer_norm2): CNNLayerNorm(\n",
            "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (birnn_layers): Sequential(\n",
            "    (0): BidirectionalGRU(\n",
            "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (1): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (2): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (3): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (4): BidirectionalGRU(\n",
            "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): GELU()\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
            "  )\n",
            ")\n",
            "Num Model Parameters 23705373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 7.135164\n",
            "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 2.907269\n",
            "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 2.871370\n",
            "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 2.867666\n",
            "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 2.880453\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 2.870226\n",
            "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 2.846278\n",
            "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 2.854156\n",
            "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 2.871846\n",
            "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 2.842757\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 2.867656\n",
            "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 2.855094\n",
            "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 2.830516\n",
            "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 2.833497\n",
            "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 2.777325\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 2.753911\n",
            "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 2.542130\n",
            "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 2.522579\n",
            "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 2.291599\n",
            "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 2.130032\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 1.950706\n",
            "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 1.970427\n",
            "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 1.848711\n",
            "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 1.996054\n",
            "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 1.807109\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 1.744986\n",
            "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 1.720820\n",
            "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 1.619144\n",
            "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 1.827003\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.4597, Average CER: 0.435368 Average WER: 0.9403\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 1.786760\n",
            "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 1.738881\n",
            "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 1.510260\n",
            "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 1.612170\n",
            "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 1.561059\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 1.584345\n",
            "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 1.284727\n",
            "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 1.424203\n",
            "Train Epoch: 2 [8000/28539 (28%)]\tLoss: 1.504083\n",
            "Train Epoch: 2 [9000/28539 (32%)]\tLoss: 1.398966\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 1.312371\n",
            "Train Epoch: 2 [11000/28539 (39%)]\tLoss: 1.438622\n",
            "Train Epoch: 2 [12000/28539 (42%)]\tLoss: 1.294131\n",
            "Train Epoch: 2 [13000/28539 (46%)]\tLoss: 1.281464\n",
            "Train Epoch: 2 [14000/28539 (49%)]\tLoss: 1.264281\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 1.370176\n",
            "Train Epoch: 2 [16000/28539 (56%)]\tLoss: 1.232126\n",
            "Train Epoch: 2 [17000/28539 (60%)]\tLoss: 1.576124\n",
            "Train Epoch: 2 [18000/28539 (63%)]\tLoss: 1.235629\n",
            "Train Epoch: 2 [19000/28539 (67%)]\tLoss: 1.457265\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 1.311906\n",
            "Train Epoch: 2 [21000/28539 (74%)]\tLoss: 1.347340\n",
            "Train Epoch: 2 [22000/28539 (77%)]\tLoss: 1.171749\n",
            "Train Epoch: 2 [23000/28539 (81%)]\tLoss: 1.250410\n",
            "Train Epoch: 2 [24000/28539 (84%)]\tLoss: 1.245848\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 1.285731\n",
            "Train Epoch: 2 [26000/28539 (91%)]\tLoss: 1.152531\n",
            "Train Epoch: 2 [27000/28539 (95%)]\tLoss: 1.288280\n",
            "Train Epoch: 2 [28000/28539 (98%)]\tLoss: 1.296756\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.0150, Average CER: 0.313178 Average WER: 0.7785\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 1.167058\n",
            "Train Epoch: 3 [1000/28539 (4%)]\tLoss: 1.148298\n",
            "Train Epoch: 3 [2000/28539 (7%)]\tLoss: 1.185989\n",
            "Train Epoch: 3 [3000/28539 (11%)]\tLoss: 1.525135\n",
            "Train Epoch: 3 [4000/28539 (14%)]\tLoss: 1.085834\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 1.313670\n",
            "Train Epoch: 3 [6000/28539 (21%)]\tLoss: 1.285125\n",
            "Train Epoch: 3 [7000/28539 (25%)]\tLoss: 1.216660\n",
            "Train Epoch: 3 [8000/28539 (28%)]\tLoss: 1.245303\n",
            "Train Epoch: 3 [9000/28539 (32%)]\tLoss: 1.197123\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 1.105602\n",
            "Train Epoch: 3 [11000/28539 (39%)]\tLoss: 1.021181\n",
            "Train Epoch: 3 [12000/28539 (42%)]\tLoss: 1.169446\n",
            "Train Epoch: 3 [13000/28539 (46%)]\tLoss: 1.115764\n",
            "Train Epoch: 3 [14000/28539 (49%)]\tLoss: 1.098222\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 1.229046\n",
            "Train Epoch: 3 [16000/28539 (56%)]\tLoss: 1.198157\n",
            "Train Epoch: 3 [17000/28539 (60%)]\tLoss: 1.068709\n",
            "Train Epoch: 3 [18000/28539 (63%)]\tLoss: 1.294406\n",
            "Train Epoch: 3 [19000/28539 (67%)]\tLoss: 1.172883\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 0.948447\n",
            "Train Epoch: 3 [21000/28539 (74%)]\tLoss: 1.178844\n",
            "Train Epoch: 3 [22000/28539 (77%)]\tLoss: 1.097755\n",
            "Train Epoch: 3 [23000/28539 (81%)]\tLoss: 1.075294\n",
            "Train Epoch: 3 [24000/28539 (84%)]\tLoss: 1.161660\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 1.277614\n",
            "Train Epoch: 3 [26000/28539 (91%)]\tLoss: 1.175608\n",
            "Train Epoch: 3 [27000/28539 (95%)]\tLoss: 1.144678\n",
            "Train Epoch: 3 [28000/28539 (98%)]\tLoss: 1.036482\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.8554, Average CER: 0.262559 Average WER: 0.7043\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 1.020084\n",
            "Train Epoch: 4 [1000/28539 (4%)]\tLoss: 1.046367\n",
            "Train Epoch: 4 [2000/28539 (7%)]\tLoss: 0.949924\n",
            "Train Epoch: 4 [3000/28539 (11%)]\tLoss: 0.929268\n",
            "Train Epoch: 4 [4000/28539 (14%)]\tLoss: 1.183887\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 0.961380\n",
            "Train Epoch: 4 [6000/28539 (21%)]\tLoss: 0.966151\n",
            "Train Epoch: 4 [7000/28539 (25%)]\tLoss: 0.880902\n",
            "Train Epoch: 4 [8000/28539 (28%)]\tLoss: 1.040990\n",
            "Train Epoch: 4 [9000/28539 (32%)]\tLoss: 1.111686\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 1.053486\n",
            "Train Epoch: 4 [11000/28539 (39%)]\tLoss: 1.005297\n",
            "Train Epoch: 4 [12000/28539 (42%)]\tLoss: 1.113862\n",
            "Train Epoch: 4 [13000/28539 (46%)]\tLoss: 1.028931\n",
            "Train Epoch: 4 [14000/28539 (49%)]\tLoss: 1.012121\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 0.892684\n",
            "Train Epoch: 4 [16000/28539 (56%)]\tLoss: 1.004587\n",
            "Train Epoch: 4 [17000/28539 (60%)]\tLoss: 0.931094\n",
            "Train Epoch: 4 [18000/28539 (63%)]\tLoss: 0.943921\n",
            "Train Epoch: 4 [19000/28539 (67%)]\tLoss: 0.957169\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 1.072336\n",
            "Train Epoch: 4 [21000/28539 (74%)]\tLoss: 0.856417\n",
            "Train Epoch: 4 [22000/28539 (77%)]\tLoss: 1.044280\n",
            "Train Epoch: 4 [23000/28539 (81%)]\tLoss: 0.866607\n",
            "Train Epoch: 4 [24000/28539 (84%)]\tLoss: 0.899270\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 0.960837\n",
            "Train Epoch: 4 [26000/28539 (91%)]\tLoss: 0.795780\n",
            "Train Epoch: 4 [27000/28539 (95%)]\tLoss: 1.051539\n",
            "Train Epoch: 4 [28000/28539 (98%)]\tLoss: 0.901184\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.7415, Average CER: 0.225532 Average WER: 0.6295\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 0.733207\n",
            "Train Epoch: 5 [1000/28539 (4%)]\tLoss: 0.857712\n",
            "Train Epoch: 5 [2000/28539 (7%)]\tLoss: 1.060131\n",
            "Train Epoch: 5 [3000/28539 (11%)]\tLoss: 0.870150\n",
            "Train Epoch: 5 [4000/28539 (14%)]\tLoss: 0.925745\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 0.970115\n",
            "Train Epoch: 5 [6000/28539 (21%)]\tLoss: 0.665609\n",
            "Train Epoch: 5 [7000/28539 (25%)]\tLoss: 0.798477\n",
            "Train Epoch: 5 [8000/28539 (28%)]\tLoss: 0.859500\n",
            "Train Epoch: 5 [9000/28539 (32%)]\tLoss: 0.813330\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 0.926959\n",
            "Train Epoch: 5 [11000/28539 (39%)]\tLoss: 0.839069\n",
            "Train Epoch: 5 [12000/28539 (42%)]\tLoss: 0.857146\n",
            "Train Epoch: 5 [13000/28539 (46%)]\tLoss: 0.949225\n",
            "Train Epoch: 5 [14000/28539 (49%)]\tLoss: 0.784484\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 0.912953\n",
            "Train Epoch: 5 [16000/28539 (56%)]\tLoss: 0.829268\n",
            "Train Epoch: 5 [17000/28539 (60%)]\tLoss: 0.907771\n",
            "Train Epoch: 5 [18000/28539 (63%)]\tLoss: 0.842880\n",
            "Train Epoch: 5 [19000/28539 (67%)]\tLoss: 0.912420\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 0.851491\n",
            "Train Epoch: 5 [21000/28539 (74%)]\tLoss: 0.911972\n",
            "Train Epoch: 5 [22000/28539 (77%)]\tLoss: 0.918003\n",
            "Train Epoch: 5 [23000/28539 (81%)]\tLoss: 0.953381\n",
            "Train Epoch: 5 [24000/28539 (84%)]\tLoss: 0.914397\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 0.739345\n",
            "Train Epoch: 5 [26000/28539 (91%)]\tLoss: 0.806525\n",
            "Train Epoch: 5 [27000/28539 (95%)]\tLoss: 0.861526\n",
            "Train Epoch: 5 [28000/28539 (98%)]\tLoss: 0.767831\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.6684, Average CER: 0.202513 Average WER: 0.5758\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 0.653778\n",
            "Train Epoch: 6 [1000/28539 (4%)]\tLoss: 0.832271\n",
            "Train Epoch: 6 [2000/28539 (7%)]\tLoss: 0.835372\n",
            "Train Epoch: 6 [3000/28539 (11%)]\tLoss: 0.801844\n",
            "Train Epoch: 6 [4000/28539 (14%)]\tLoss: 0.832037\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 0.775557\n",
            "Train Epoch: 6 [6000/28539 (21%)]\tLoss: 0.758845\n",
            "Train Epoch: 6 [7000/28539 (25%)]\tLoss: 0.730669\n",
            "Train Epoch: 6 [8000/28539 (28%)]\tLoss: 0.929270\n",
            "Train Epoch: 6 [9000/28539 (32%)]\tLoss: 0.630368\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 0.769636\n",
            "Train Epoch: 6 [11000/28539 (39%)]\tLoss: 0.845477\n",
            "Train Epoch: 6 [12000/28539 (42%)]\tLoss: 0.882390\n",
            "Train Epoch: 6 [13000/28539 (46%)]\tLoss: 0.937629\n",
            "Train Epoch: 6 [14000/28539 (49%)]\tLoss: 0.791404\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 0.870977\n",
            "Train Epoch: 6 [16000/28539 (56%)]\tLoss: 0.825500\n",
            "Train Epoch: 6 [17000/28539 (60%)]\tLoss: 0.722764\n",
            "Train Epoch: 6 [18000/28539 (63%)]\tLoss: 0.803549\n",
            "Train Epoch: 6 [19000/28539 (67%)]\tLoss: 0.774734\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 0.732038\n",
            "Train Epoch: 6 [21000/28539 (74%)]\tLoss: 0.954506\n",
            "Train Epoch: 6 [22000/28539 (77%)]\tLoss: 0.701698\n",
            "Train Epoch: 6 [23000/28539 (81%)]\tLoss: 0.802297\n",
            "Train Epoch: 6 [24000/28539 (84%)]\tLoss: 0.822842\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 0.607961\n",
            "Train Epoch: 6 [26000/28539 (91%)]\tLoss: 0.895440\n",
            "Train Epoch: 6 [27000/28539 (95%)]\tLoss: 0.763880\n",
            "Train Epoch: 6 [28000/28539 (98%)]\tLoss: 0.711978\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.6126, Average CER: 0.184322 Average WER: 0.5337\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 0.637002\n",
            "Train Epoch: 7 [1000/28539 (4%)]\tLoss: 0.934636\n",
            "Train Epoch: 7 [2000/28539 (7%)]\tLoss: 0.904947\n",
            "Train Epoch: 7 [3000/28539 (11%)]\tLoss: 0.715539\n",
            "Train Epoch: 7 [4000/28539 (14%)]\tLoss: 0.796341\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 0.778393\n",
            "Train Epoch: 7 [6000/28539 (21%)]\tLoss: 0.858543\n",
            "Train Epoch: 7 [7000/28539 (25%)]\tLoss: 0.674216\n",
            "Train Epoch: 7 [8000/28539 (28%)]\tLoss: 0.794999\n",
            "Train Epoch: 7 [9000/28539 (32%)]\tLoss: 0.766565\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 0.927203\n",
            "Train Epoch: 7 [11000/28539 (39%)]\tLoss: 0.608639\n",
            "Train Epoch: 7 [12000/28539 (42%)]\tLoss: 0.851504\n",
            "Train Epoch: 7 [13000/28539 (46%)]\tLoss: 0.980096\n",
            "Train Epoch: 7 [14000/28539 (49%)]\tLoss: 0.928317\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.734232\n",
            "Train Epoch: 7 [16000/28539 (56%)]\tLoss: 0.594144\n",
            "Train Epoch: 7 [17000/28539 (60%)]\tLoss: 0.802620\n",
            "Train Epoch: 7 [18000/28539 (63%)]\tLoss: 0.689337\n",
            "Train Epoch: 7 [19000/28539 (67%)]\tLoss: 0.738636\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 0.831909\n",
            "Train Epoch: 7 [21000/28539 (74%)]\tLoss: 0.772880\n",
            "Train Epoch: 7 [22000/28539 (77%)]\tLoss: 0.620925\n",
            "Train Epoch: 7 [23000/28539 (81%)]\tLoss: 0.795739\n",
            "Train Epoch: 7 [24000/28539 (84%)]\tLoss: 0.702069\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 0.764485\n",
            "Train Epoch: 7 [26000/28539 (91%)]\tLoss: 0.752988\n",
            "Train Epoch: 7 [27000/28539 (95%)]\tLoss: 0.815450\n",
            "Train Epoch: 7 [28000/28539 (98%)]\tLoss: 0.760088\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.5720, Average CER: 0.173002 Average WER: 0.5103\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 0.601156\n",
            "Train Epoch: 8 [1000/28539 (4%)]\tLoss: 0.619221\n",
            "Train Epoch: 8 [2000/28539 (7%)]\tLoss: 0.914948\n",
            "Train Epoch: 8 [3000/28539 (11%)]\tLoss: 0.708733\n",
            "Train Epoch: 8 [4000/28539 (14%)]\tLoss: 0.696474\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 0.573982\n",
            "Train Epoch: 8 [6000/28539 (21%)]\tLoss: 0.743479\n",
            "Train Epoch: 8 [7000/28539 (25%)]\tLoss: 0.672204\n",
            "Train Epoch: 8 [8000/28539 (28%)]\tLoss: 0.655888\n",
            "Train Epoch: 8 [9000/28539 (32%)]\tLoss: 0.641209\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 0.784693\n",
            "Train Epoch: 8 [11000/28539 (39%)]\tLoss: 0.832425\n",
            "Train Epoch: 8 [12000/28539 (42%)]\tLoss: 0.718503\n",
            "Train Epoch: 8 [13000/28539 (46%)]\tLoss: 0.688207\n",
            "Train Epoch: 8 [14000/28539 (49%)]\tLoss: 0.655412\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.673688\n",
            "Train Epoch: 8 [16000/28539 (56%)]\tLoss: 0.736080\n",
            "Train Epoch: 8 [17000/28539 (60%)]\tLoss: 0.570119\n",
            "Train Epoch: 8 [18000/28539 (63%)]\tLoss: 0.741675\n",
            "Train Epoch: 8 [19000/28539 (67%)]\tLoss: 0.783087\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 0.886801\n",
            "Train Epoch: 8 [21000/28539 (74%)]\tLoss: 0.687327\n",
            "Train Epoch: 8 [22000/28539 (77%)]\tLoss: 0.561307\n",
            "Train Epoch: 8 [23000/28539 (81%)]\tLoss: 0.663522\n",
            "Train Epoch: 8 [24000/28539 (84%)]\tLoss: 0.762771\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 0.602433\n",
            "Train Epoch: 8 [26000/28539 (91%)]\tLoss: 0.610780\n",
            "Train Epoch: 8 [27000/28539 (95%)]\tLoss: 0.660084\n",
            "Train Epoch: 8 [28000/28539 (98%)]\tLoss: 0.606854\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.5479, Average CER: 0.162727 Average WER: 0.4856\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.657487\n",
            "Train Epoch: 9 [1000/28539 (4%)]\tLoss: 0.677214\n",
            "Train Epoch: 9 [2000/28539 (7%)]\tLoss: 0.647339\n",
            "Train Epoch: 9 [3000/28539 (11%)]\tLoss: 0.693166\n",
            "Train Epoch: 9 [4000/28539 (14%)]\tLoss: 0.615983\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.732408\n",
            "Train Epoch: 9 [6000/28539 (21%)]\tLoss: 0.818730\n",
            "Train Epoch: 9 [7000/28539 (25%)]\tLoss: 0.667813\n",
            "Train Epoch: 9 [8000/28539 (28%)]\tLoss: 0.593577\n",
            "Train Epoch: 9 [9000/28539 (32%)]\tLoss: 0.583555\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.605984\n",
            "Train Epoch: 9 [11000/28539 (39%)]\tLoss: 0.730029\n",
            "Train Epoch: 9 [12000/28539 (42%)]\tLoss: 0.565570\n",
            "Train Epoch: 9 [13000/28539 (46%)]\tLoss: 0.791155\n",
            "Train Epoch: 9 [14000/28539 (49%)]\tLoss: 0.705839\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.837533\n",
            "Train Epoch: 9 [16000/28539 (56%)]\tLoss: 0.618463\n",
            "Train Epoch: 9 [17000/28539 (60%)]\tLoss: 0.667527\n",
            "Train Epoch: 9 [18000/28539 (63%)]\tLoss: 0.839908\n",
            "Train Epoch: 9 [19000/28539 (67%)]\tLoss: 0.735150\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.556278\n",
            "Train Epoch: 9 [21000/28539 (74%)]\tLoss: 0.848113\n",
            "Train Epoch: 9 [22000/28539 (77%)]\tLoss: 0.836597\n",
            "Train Epoch: 9 [23000/28539 (81%)]\tLoss: 0.611564\n",
            "Train Epoch: 9 [24000/28539 (84%)]\tLoss: 0.845042\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 0.719917\n",
            "Train Epoch: 9 [26000/28539 (91%)]\tLoss: 0.766156\n",
            "Train Epoch: 9 [27000/28539 (95%)]\tLoss: 0.610927\n",
            "Train Epoch: 9 [28000/28539 (98%)]\tLoss: 0.688165\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.5294, Average CER: 0.157895 Average WER: 0.4702\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.612044\n",
            "Train Epoch: 10 [1000/28539 (4%)]\tLoss: 0.671699\n",
            "Train Epoch: 10 [2000/28539 (7%)]\tLoss: 0.713832\n",
            "Train Epoch: 10 [3000/28539 (11%)]\tLoss: 0.676900\n",
            "Train Epoch: 10 [4000/28539 (14%)]\tLoss: 0.742398\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.583972\n",
            "Train Epoch: 10 [6000/28539 (21%)]\tLoss: 0.543142\n",
            "Train Epoch: 10 [7000/28539 (25%)]\tLoss: 0.727072\n",
            "Train Epoch: 10 [8000/28539 (28%)]\tLoss: 0.527187\n",
            "Train Epoch: 10 [9000/28539 (32%)]\tLoss: 0.731961\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.719316\n",
            "Train Epoch: 10 [11000/28539 (39%)]\tLoss: 0.690158\n",
            "Train Epoch: 10 [12000/28539 (42%)]\tLoss: 0.621388\n",
            "Train Epoch: 10 [13000/28539 (46%)]\tLoss: 0.639781\n",
            "Train Epoch: 10 [14000/28539 (49%)]\tLoss: 0.564071\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.961175\n",
            "Train Epoch: 10 [16000/28539 (56%)]\tLoss: 0.595331\n",
            "Train Epoch: 10 [17000/28539 (60%)]\tLoss: 0.720355\n",
            "Train Epoch: 10 [18000/28539 (63%)]\tLoss: 0.676543\n",
            "Train Epoch: 10 [19000/28539 (67%)]\tLoss: 0.494414\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.515867\n",
            "Train Epoch: 10 [21000/28539 (74%)]\tLoss: 0.503462\n",
            "Train Epoch: 10 [22000/28539 (77%)]\tLoss: 0.597237\n",
            "Train Epoch: 10 [23000/28539 (81%)]\tLoss: 0.723368\n",
            "Train Epoch: 10 [24000/28539 (84%)]\tLoss: 0.622620\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.690721\n",
            "Train Epoch: 10 [26000/28539 (91%)]\tLoss: 0.727110\n",
            "Train Epoch: 10 [27000/28539 (95%)]\tLoss: 0.547827\n",
            "Train Epoch: 10 [28000/28539 (98%)]\tLoss: 0.639986\n",
            "\n",
            "evaluating...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n",
            "  normalized, onesided, return_complex)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "  normalized, onesided, return_complex)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.5181, Average CER: 0.153969 Average WER: 0.4608\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92kVVEr7GR6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240ba429-de97-4760-fc7f-692064e3d892"
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "model_op = torch.load(\"/content/drive/MyDrive/aisound.pt\")\n",
        "model_op2,best_test_loss_op = main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set, model=model_op)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Model Parameters 23705373\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 1.047564\n",
            "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 0.968826\n",
            "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 0.928556\n",
            "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 0.779015\n",
            "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 0.879779\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 0.965954\n",
            "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 0.912945\n",
            "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 0.694497\n",
            "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 0.961894\n",
            "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 0.837076\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 0.788627\n",
            "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 0.843630\n",
            "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 0.877701\n",
            "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 0.824994\n",
            "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 0.757335\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 0.844560\n",
            "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 0.683253\n",
            "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 0.646446\n",
            "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 0.758766\n",
            "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 0.820690\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 0.768193\n",
            "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 0.639255\n",
            "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 0.570576\n",
            "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 0.738427\n",
            "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 0.800070\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 0.563867\n",
            "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 0.584944\n",
            "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 0.507971\n",
            "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 0.426544\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.6034477212046852 < prev test_loss 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type SpeechRecognitionModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type ResidualCNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CNNLayerNorm. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BidirectionalGRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.6034, Average CER: 0.167814 Average WER: 0.4938\n",
            "\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 0.674060\n",
            "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 0.864787\n",
            "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 0.674821\n",
            "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 0.763270\n",
            "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 0.698752\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 0.708263\n",
            "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 0.620228\n",
            "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 0.627530\n",
            "Train Epoch: 2 [8000/28539 (28%)]\tLoss: 0.585919\n",
            "Train Epoch: 2 [9000/28539 (32%)]\tLoss: 0.667907\n",
            "Train Epoch: 2 [10000/28539 (35%)]\tLoss: 0.625960\n",
            "Train Epoch: 2 [11000/28539 (39%)]\tLoss: 0.729672\n",
            "Train Epoch: 2 [12000/28539 (42%)]\tLoss: 0.824971\n",
            "Train Epoch: 2 [13000/28539 (46%)]\tLoss: 0.682706\n",
            "Train Epoch: 2 [14000/28539 (49%)]\tLoss: 0.695533\n",
            "Train Epoch: 2 [15000/28539 (53%)]\tLoss: 0.686567\n",
            "Train Epoch: 2 [16000/28539 (56%)]\tLoss: 0.664907\n",
            "Train Epoch: 2 [17000/28539 (60%)]\tLoss: 0.817893\n",
            "Train Epoch: 2 [18000/28539 (63%)]\tLoss: 0.696891\n",
            "Train Epoch: 2 [19000/28539 (67%)]\tLoss: 0.725358\n",
            "Train Epoch: 2 [20000/28539 (70%)]\tLoss: 0.644032\n",
            "Train Epoch: 2 [21000/28539 (74%)]\tLoss: 0.609319\n",
            "Train Epoch: 2 [22000/28539 (77%)]\tLoss: 0.711434\n",
            "Train Epoch: 2 [23000/28539 (81%)]\tLoss: 0.572100\n",
            "Train Epoch: 2 [24000/28539 (84%)]\tLoss: 0.558208\n",
            "Train Epoch: 2 [25000/28539 (88%)]\tLoss: 0.706540\n",
            "Train Epoch: 2 [26000/28539 (91%)]\tLoss: 0.663818\n",
            "Train Epoch: 2 [27000/28539 (95%)]\tLoss: 0.581097\n",
            "Train Epoch: 2 [28000/28539 (98%)]\tLoss: 0.936041\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.5439177756659855 < prev test_loss 0.6034477212046852\n",
            "Test set: Average loss: 0.5439, Average CER: 0.160493 Average WER: 0.4744\n",
            "\n",
            "Train Epoch: 3 [0/28539 (0%)]\tLoss: 0.655972\n",
            "Train Epoch: 3 [1000/28539 (4%)]\tLoss: 0.721811\n",
            "Train Epoch: 3 [2000/28539 (7%)]\tLoss: 0.655046\n",
            "Train Epoch: 3 [3000/28539 (11%)]\tLoss: 0.726329\n",
            "Train Epoch: 3 [4000/28539 (14%)]\tLoss: 0.705200\n",
            "Train Epoch: 3 [5000/28539 (18%)]\tLoss: 0.904457\n",
            "Train Epoch: 3 [6000/28539 (21%)]\tLoss: 0.514671\n",
            "Train Epoch: 3 [7000/28539 (25%)]\tLoss: 0.647248\n",
            "Train Epoch: 3 [8000/28539 (28%)]\tLoss: 0.563677\n",
            "Train Epoch: 3 [9000/28539 (32%)]\tLoss: 0.774668\n",
            "Train Epoch: 3 [10000/28539 (35%)]\tLoss: 0.702386\n",
            "Train Epoch: 3 [11000/28539 (39%)]\tLoss: 0.899675\n",
            "Train Epoch: 3 [12000/28539 (42%)]\tLoss: 0.979121\n",
            "Train Epoch: 3 [13000/28539 (46%)]\tLoss: 0.839924\n",
            "Train Epoch: 3 [14000/28539 (49%)]\tLoss: 0.600495\n",
            "Train Epoch: 3 [15000/28539 (53%)]\tLoss: 0.721342\n",
            "Train Epoch: 3 [16000/28539 (56%)]\tLoss: 0.565914\n",
            "Train Epoch: 3 [17000/28539 (60%)]\tLoss: 0.582673\n",
            "Train Epoch: 3 [18000/28539 (63%)]\tLoss: 0.716825\n",
            "Train Epoch: 3 [19000/28539 (67%)]\tLoss: 0.609130\n",
            "Train Epoch: 3 [20000/28539 (70%)]\tLoss: 0.626268\n",
            "Train Epoch: 3 [21000/28539 (74%)]\tLoss: 0.623358\n",
            "Train Epoch: 3 [22000/28539 (77%)]\tLoss: 0.607693\n",
            "Train Epoch: 3 [23000/28539 (81%)]\tLoss: 0.746461\n",
            "Train Epoch: 3 [24000/28539 (84%)]\tLoss: 0.582926\n",
            "Train Epoch: 3 [25000/28539 (88%)]\tLoss: 0.687030\n",
            "Train Epoch: 3 [26000/28539 (91%)]\tLoss: 0.705417\n",
            "Train Epoch: 3 [27000/28539 (95%)]\tLoss: 0.636609\n",
            "Train Epoch: 3 [28000/28539 (98%)]\tLoss: 0.678472\n",
            "\n",
            "evaluating...\n",
            "Test set: Average loss: 0.5483, Average CER: 0.158937 Average WER: 0.4690\n",
            "\n",
            "Train Epoch: 4 [0/28539 (0%)]\tLoss: 0.813159\n",
            "Train Epoch: 4 [1000/28539 (4%)]\tLoss: 0.812639\n",
            "Train Epoch: 4 [2000/28539 (7%)]\tLoss: 0.666114\n",
            "Train Epoch: 4 [3000/28539 (11%)]\tLoss: 0.857555\n",
            "Train Epoch: 4 [4000/28539 (14%)]\tLoss: 0.644642\n",
            "Train Epoch: 4 [5000/28539 (18%)]\tLoss: 0.766226\n",
            "Train Epoch: 4 [6000/28539 (21%)]\tLoss: 0.520264\n",
            "Train Epoch: 4 [7000/28539 (25%)]\tLoss: 0.714992\n",
            "Train Epoch: 4 [8000/28539 (28%)]\tLoss: 0.601047\n",
            "Train Epoch: 4 [9000/28539 (32%)]\tLoss: 0.784062\n",
            "Train Epoch: 4 [10000/28539 (35%)]\tLoss: 0.877840\n",
            "Train Epoch: 4 [11000/28539 (39%)]\tLoss: 0.702680\n",
            "Train Epoch: 4 [12000/28539 (42%)]\tLoss: 0.738023\n",
            "Train Epoch: 4 [13000/28539 (46%)]\tLoss: 0.602632\n",
            "Train Epoch: 4 [14000/28539 (49%)]\tLoss: 0.646274\n",
            "Train Epoch: 4 [15000/28539 (53%)]\tLoss: 0.907007\n",
            "Train Epoch: 4 [16000/28539 (56%)]\tLoss: 0.711076\n",
            "Train Epoch: 4 [17000/28539 (60%)]\tLoss: 0.834770\n",
            "Train Epoch: 4 [18000/28539 (63%)]\tLoss: 0.673850\n",
            "Train Epoch: 4 [19000/28539 (67%)]\tLoss: 0.728180\n",
            "Train Epoch: 4 [20000/28539 (70%)]\tLoss: 0.789385\n",
            "Train Epoch: 4 [21000/28539 (74%)]\tLoss: 0.621748\n",
            "Train Epoch: 4 [22000/28539 (77%)]\tLoss: 0.676385\n",
            "Train Epoch: 4 [23000/28539 (81%)]\tLoss: 0.731596\n",
            "Train Epoch: 4 [24000/28539 (84%)]\tLoss: 0.839868\n",
            "Train Epoch: 4 [25000/28539 (88%)]\tLoss: 0.645481\n",
            "Train Epoch: 4 [26000/28539 (91%)]\tLoss: 0.632381\n",
            "Train Epoch: 4 [27000/28539 (95%)]\tLoss: 0.589256\n",
            "Train Epoch: 4 [28000/28539 (98%)]\tLoss: 0.735179\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.5345034375786777 < prev test_loss 0.5439177756659855\n",
            "Test set: Average loss: 0.5345, Average CER: 0.155651 Average WER: 0.4621\n",
            "\n",
            "Train Epoch: 5 [0/28539 (0%)]\tLoss: 0.614927\n",
            "Train Epoch: 5 [1000/28539 (4%)]\tLoss: 0.608223\n",
            "Train Epoch: 5 [2000/28539 (7%)]\tLoss: 0.588338\n",
            "Train Epoch: 5 [3000/28539 (11%)]\tLoss: 0.504904\n",
            "Train Epoch: 5 [4000/28539 (14%)]\tLoss: 0.771636\n",
            "Train Epoch: 5 [5000/28539 (18%)]\tLoss: 0.598905\n",
            "Train Epoch: 5 [6000/28539 (21%)]\tLoss: 0.681568\n",
            "Train Epoch: 5 [7000/28539 (25%)]\tLoss: 0.659397\n",
            "Train Epoch: 5 [8000/28539 (28%)]\tLoss: 0.589607\n",
            "Train Epoch: 5 [9000/28539 (32%)]\tLoss: 0.669524\n",
            "Train Epoch: 5 [10000/28539 (35%)]\tLoss: 0.622134\n",
            "Train Epoch: 5 [11000/28539 (39%)]\tLoss: 0.630780\n",
            "Train Epoch: 5 [12000/28539 (42%)]\tLoss: 0.718264\n",
            "Train Epoch: 5 [13000/28539 (46%)]\tLoss: 0.678138\n",
            "Train Epoch: 5 [14000/28539 (49%)]\tLoss: 0.518315\n",
            "Train Epoch: 5 [15000/28539 (53%)]\tLoss: 0.694313\n",
            "Train Epoch: 5 [16000/28539 (56%)]\tLoss: 0.682924\n",
            "Train Epoch: 5 [17000/28539 (60%)]\tLoss: 0.653118\n",
            "Train Epoch: 5 [18000/28539 (63%)]\tLoss: 0.563414\n",
            "Train Epoch: 5 [19000/28539 (67%)]\tLoss: 0.547285\n",
            "Train Epoch: 5 [20000/28539 (70%)]\tLoss: 0.644602\n",
            "Train Epoch: 5 [21000/28539 (74%)]\tLoss: 0.524299\n",
            "Train Epoch: 5 [22000/28539 (77%)]\tLoss: 0.593584\n",
            "Train Epoch: 5 [23000/28539 (81%)]\tLoss: 0.578543\n",
            "Train Epoch: 5 [24000/28539 (84%)]\tLoss: 0.656513\n",
            "Train Epoch: 5 [25000/28539 (88%)]\tLoss: 0.507762\n",
            "Train Epoch: 5 [26000/28539 (91%)]\tLoss: 0.610048\n",
            "Train Epoch: 5 [27000/28539 (95%)]\tLoss: 0.641763\n",
            "Train Epoch: 5 [28000/28539 (98%)]\tLoss: 0.733311\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.5187159536676555 < prev test_loss 0.5345034375786777\n",
            "Test set: Average loss: 0.5187, Average CER: 0.149183 Average WER: 0.4466\n",
            "\n",
            "Train Epoch: 6 [0/28539 (0%)]\tLoss: 0.699136\n",
            "Train Epoch: 6 [1000/28539 (4%)]\tLoss: 0.515962\n",
            "Train Epoch: 6 [2000/28539 (7%)]\tLoss: 0.554733\n",
            "Train Epoch: 6 [3000/28539 (11%)]\tLoss: 0.639383\n",
            "Train Epoch: 6 [4000/28539 (14%)]\tLoss: 0.564496\n",
            "Train Epoch: 6 [5000/28539 (18%)]\tLoss: 0.520397\n",
            "Train Epoch: 6 [6000/28539 (21%)]\tLoss: 0.530430\n",
            "Train Epoch: 6 [7000/28539 (25%)]\tLoss: 0.488473\n",
            "Train Epoch: 6 [8000/28539 (28%)]\tLoss: 0.804534\n",
            "Train Epoch: 6 [9000/28539 (32%)]\tLoss: 0.621047\n",
            "Train Epoch: 6 [10000/28539 (35%)]\tLoss: 0.628491\n",
            "Train Epoch: 6 [11000/28539 (39%)]\tLoss: 0.572810\n",
            "Train Epoch: 6 [12000/28539 (42%)]\tLoss: 0.751590\n",
            "Train Epoch: 6 [13000/28539 (46%)]\tLoss: 0.689873\n",
            "Train Epoch: 6 [14000/28539 (49%)]\tLoss: 0.513506\n",
            "Train Epoch: 6 [15000/28539 (53%)]\tLoss: 0.555267\n",
            "Train Epoch: 6 [16000/28539 (56%)]\tLoss: 0.727868\n",
            "Train Epoch: 6 [17000/28539 (60%)]\tLoss: 0.562981\n",
            "Train Epoch: 6 [18000/28539 (63%)]\tLoss: 0.690063\n",
            "Train Epoch: 6 [19000/28539 (67%)]\tLoss: 0.461610\n",
            "Train Epoch: 6 [20000/28539 (70%)]\tLoss: 0.572192\n",
            "Train Epoch: 6 [21000/28539 (74%)]\tLoss: 0.694186\n",
            "Train Epoch: 6 [22000/28539 (77%)]\tLoss: 0.734358\n",
            "Train Epoch: 6 [23000/28539 (81%)]\tLoss: 0.427785\n",
            "Train Epoch: 6 [24000/28539 (84%)]\tLoss: 0.604813\n",
            "Train Epoch: 6 [25000/28539 (88%)]\tLoss: 0.564750\n",
            "Train Epoch: 6 [26000/28539 (91%)]\tLoss: 0.693237\n",
            "Train Epoch: 6 [27000/28539 (95%)]\tLoss: 0.520882\n",
            "Train Epoch: 6 [28000/28539 (98%)]\tLoss: 0.582448\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.4951853089546431 < prev test_loss 0.5187159536676555\n",
            "Test set: Average loss: 0.4952, Average CER: 0.143771 Average WER: 0.4308\n",
            "\n",
            "Train Epoch: 7 [0/28539 (0%)]\tLoss: 0.482695\n",
            "Train Epoch: 7 [1000/28539 (4%)]\tLoss: 0.583741\n",
            "Train Epoch: 7 [2000/28539 (7%)]\tLoss: 0.568357\n",
            "Train Epoch: 7 [3000/28539 (11%)]\tLoss: 0.654913\n",
            "Train Epoch: 7 [4000/28539 (14%)]\tLoss: 0.412070\n",
            "Train Epoch: 7 [5000/28539 (18%)]\tLoss: 0.447594\n",
            "Train Epoch: 7 [6000/28539 (21%)]\tLoss: 0.503461\n",
            "Train Epoch: 7 [7000/28539 (25%)]\tLoss: 0.504607\n",
            "Train Epoch: 7 [8000/28539 (28%)]\tLoss: 0.558048\n",
            "Train Epoch: 7 [9000/28539 (32%)]\tLoss: 0.530233\n",
            "Train Epoch: 7 [10000/28539 (35%)]\tLoss: 0.544840\n",
            "Train Epoch: 7 [11000/28539 (39%)]\tLoss: 0.555470\n",
            "Train Epoch: 7 [12000/28539 (42%)]\tLoss: 0.639562\n",
            "Train Epoch: 7 [13000/28539 (46%)]\tLoss: 0.596337\n",
            "Train Epoch: 7 [14000/28539 (49%)]\tLoss: 0.494108\n",
            "Train Epoch: 7 [15000/28539 (53%)]\tLoss: 0.468620\n",
            "Train Epoch: 7 [16000/28539 (56%)]\tLoss: 0.477620\n",
            "Train Epoch: 7 [17000/28539 (60%)]\tLoss: 0.552413\n",
            "Train Epoch: 7 [18000/28539 (63%)]\tLoss: 0.554364\n",
            "Train Epoch: 7 [19000/28539 (67%)]\tLoss: 0.569172\n",
            "Train Epoch: 7 [20000/28539 (70%)]\tLoss: 0.551728\n",
            "Train Epoch: 7 [21000/28539 (74%)]\tLoss: 0.726960\n",
            "Train Epoch: 7 [22000/28539 (77%)]\tLoss: 0.555219\n",
            "Train Epoch: 7 [23000/28539 (81%)]\tLoss: 0.608374\n",
            "Train Epoch: 7 [24000/28539 (84%)]\tLoss: 0.501629\n",
            "Train Epoch: 7 [25000/28539 (88%)]\tLoss: 0.609767\n",
            "Train Epoch: 7 [26000/28539 (91%)]\tLoss: 0.533557\n",
            "Train Epoch: 7 [27000/28539 (95%)]\tLoss: 0.613705\n",
            "Train Epoch: 7 [28000/28539 (98%)]\tLoss: 0.536689\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.4684688000733614 < prev test_loss 0.4951853089546431\n",
            "Test set: Average loss: 0.4685, Average CER: 0.135661 Average WER: 0.4106\n",
            "\n",
            "Train Epoch: 8 [0/28539 (0%)]\tLoss: 0.529200\n",
            "Train Epoch: 8 [1000/28539 (4%)]\tLoss: 0.543175\n",
            "Train Epoch: 8 [2000/28539 (7%)]\tLoss: 0.546518\n",
            "Train Epoch: 8 [3000/28539 (11%)]\tLoss: 0.597522\n",
            "Train Epoch: 8 [4000/28539 (14%)]\tLoss: 0.637964\n",
            "Train Epoch: 8 [5000/28539 (18%)]\tLoss: 0.512771\n",
            "Train Epoch: 8 [6000/28539 (21%)]\tLoss: 0.644526\n",
            "Train Epoch: 8 [7000/28539 (25%)]\tLoss: 0.649611\n",
            "Train Epoch: 8 [8000/28539 (28%)]\tLoss: 0.491836\n",
            "Train Epoch: 8 [9000/28539 (32%)]\tLoss: 0.514374\n",
            "Train Epoch: 8 [10000/28539 (35%)]\tLoss: 0.628542\n",
            "Train Epoch: 8 [11000/28539 (39%)]\tLoss: 0.567463\n",
            "Train Epoch: 8 [12000/28539 (42%)]\tLoss: 0.631778\n",
            "Train Epoch: 8 [13000/28539 (46%)]\tLoss: 0.519466\n",
            "Train Epoch: 8 [14000/28539 (49%)]\tLoss: 0.465684\n",
            "Train Epoch: 8 [15000/28539 (53%)]\tLoss: 0.525546\n",
            "Train Epoch: 8 [16000/28539 (56%)]\tLoss: 0.574659\n",
            "Train Epoch: 8 [17000/28539 (60%)]\tLoss: 0.464331\n",
            "Train Epoch: 8 [18000/28539 (63%)]\tLoss: 0.475023\n",
            "Train Epoch: 8 [19000/28539 (67%)]\tLoss: 0.455340\n",
            "Train Epoch: 8 [20000/28539 (70%)]\tLoss: 0.576310\n",
            "Train Epoch: 8 [21000/28539 (74%)]\tLoss: 0.467226\n",
            "Train Epoch: 8 [22000/28539 (77%)]\tLoss: 0.503637\n",
            "Train Epoch: 8 [23000/28539 (81%)]\tLoss: 0.578452\n",
            "Train Epoch: 8 [24000/28539 (84%)]\tLoss: 0.513287\n",
            "Train Epoch: 8 [25000/28539 (88%)]\tLoss: 0.656918\n",
            "Train Epoch: 8 [26000/28539 (91%)]\tLoss: 0.557284\n",
            "Train Epoch: 8 [27000/28539 (95%)]\tLoss: 0.481803\n",
            "Train Epoch: 8 [28000/28539 (98%)]\tLoss: 0.577375\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.4550123778918315 < prev test_loss 0.4684688000733614\n",
            "Test set: Average loss: 0.4550, Average CER: 0.130327 Average WER: 0.3960\n",
            "\n",
            "Train Epoch: 9 [0/28539 (0%)]\tLoss: 0.516668\n",
            "Train Epoch: 9 [1000/28539 (4%)]\tLoss: 0.606571\n",
            "Train Epoch: 9 [2000/28539 (7%)]\tLoss: 0.489030\n",
            "Train Epoch: 9 [3000/28539 (11%)]\tLoss: 0.560112\n",
            "Train Epoch: 9 [4000/28539 (14%)]\tLoss: 0.481763\n",
            "Train Epoch: 9 [5000/28539 (18%)]\tLoss: 0.413036\n",
            "Train Epoch: 9 [6000/28539 (21%)]\tLoss: 0.561996\n",
            "Train Epoch: 9 [7000/28539 (25%)]\tLoss: 0.471692\n",
            "Train Epoch: 9 [8000/28539 (28%)]\tLoss: 0.517875\n",
            "Train Epoch: 9 [9000/28539 (32%)]\tLoss: 0.465387\n",
            "Train Epoch: 9 [10000/28539 (35%)]\tLoss: 0.475424\n",
            "Train Epoch: 9 [11000/28539 (39%)]\tLoss: 0.548195\n",
            "Train Epoch: 9 [12000/28539 (42%)]\tLoss: 0.418967\n",
            "Train Epoch: 9 [13000/28539 (46%)]\tLoss: 0.566881\n",
            "Train Epoch: 9 [14000/28539 (49%)]\tLoss: 0.572774\n",
            "Train Epoch: 9 [15000/28539 (53%)]\tLoss: 0.579440\n",
            "Train Epoch: 9 [16000/28539 (56%)]\tLoss: 0.461348\n",
            "Train Epoch: 9 [17000/28539 (60%)]\tLoss: 0.553619\n",
            "Train Epoch: 9 [18000/28539 (63%)]\tLoss: 0.449883\n",
            "Train Epoch: 9 [19000/28539 (67%)]\tLoss: 0.585355\n",
            "Train Epoch: 9 [20000/28539 (70%)]\tLoss: 0.486664\n",
            "Train Epoch: 9 [21000/28539 (74%)]\tLoss: 0.334759\n",
            "Train Epoch: 9 [22000/28539 (77%)]\tLoss: 0.478483\n",
            "Train Epoch: 9 [23000/28539 (81%)]\tLoss: 0.420795\n",
            "Train Epoch: 9 [24000/28539 (84%)]\tLoss: 0.596375\n",
            "Train Epoch: 9 [25000/28539 (88%)]\tLoss: 0.511621\n",
            "Train Epoch: 9 [26000/28539 (91%)]\tLoss: 0.653378\n",
            "Train Epoch: 9 [27000/28539 (95%)]\tLoss: 0.493736\n",
            "Train Epoch: 9 [28000/28539 (98%)]\tLoss: 0.403299\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.45240519679229685 < prev test_loss 0.4550123778918315\n",
            "Test set: Average loss: 0.4524, Average CER: 0.129186 Average WER: 0.3940\n",
            "\n",
            "Train Epoch: 10 [0/28539 (0%)]\tLoss: 0.442889\n",
            "Train Epoch: 10 [1000/28539 (4%)]\tLoss: 0.428011\n",
            "Train Epoch: 10 [2000/28539 (7%)]\tLoss: 0.493120\n",
            "Train Epoch: 10 [3000/28539 (11%)]\tLoss: 0.435966\n",
            "Train Epoch: 10 [4000/28539 (14%)]\tLoss: 0.554939\n",
            "Train Epoch: 10 [5000/28539 (18%)]\tLoss: 0.474242\n",
            "Train Epoch: 10 [6000/28539 (21%)]\tLoss: 0.432724\n",
            "Train Epoch: 10 [7000/28539 (25%)]\tLoss: 0.633540\n",
            "Train Epoch: 10 [8000/28539 (28%)]\tLoss: 0.416817\n",
            "Train Epoch: 10 [9000/28539 (32%)]\tLoss: 0.587197\n",
            "Train Epoch: 10 [10000/28539 (35%)]\tLoss: 0.461502\n",
            "Train Epoch: 10 [11000/28539 (39%)]\tLoss: 0.461102\n",
            "Train Epoch: 10 [12000/28539 (42%)]\tLoss: 0.653724\n",
            "Train Epoch: 10 [13000/28539 (46%)]\tLoss: 0.496496\n",
            "Train Epoch: 10 [14000/28539 (49%)]\tLoss: 0.403223\n",
            "Train Epoch: 10 [15000/28539 (53%)]\tLoss: 0.517007\n",
            "Train Epoch: 10 [16000/28539 (56%)]\tLoss: 0.522271\n",
            "Train Epoch: 10 [17000/28539 (60%)]\tLoss: 0.392468\n",
            "Train Epoch: 10 [18000/28539 (63%)]\tLoss: 0.464432\n",
            "Train Epoch: 10 [19000/28539 (67%)]\tLoss: 0.504318\n",
            "Train Epoch: 10 [20000/28539 (70%)]\tLoss: 0.455607\n",
            "Train Epoch: 10 [21000/28539 (74%)]\tLoss: 0.476899\n",
            "Train Epoch: 10 [22000/28539 (77%)]\tLoss: 0.632116\n",
            "Train Epoch: 10 [23000/28539 (81%)]\tLoss: 0.388231\n",
            "Train Epoch: 10 [24000/28539 (84%)]\tLoss: 0.452805\n",
            "Train Epoch: 10 [25000/28539 (88%)]\tLoss: 0.474303\n",
            "Train Epoch: 10 [26000/28539 (91%)]\tLoss: 0.457717\n",
            "Train Epoch: 10 [27000/28539 (95%)]\tLoss: 0.554892\n",
            "Train Epoch: 10 [28000/28539 (98%)]\tLoss: 0.605074\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.44274744232192303 < prev test_loss 0.45240519679229685\n",
            "Test set: Average loss: 0.4427, Average CER: 0.124566 Average WER: 0.3796\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3f6e3b0a089245f8a01a9b046aa08f58",
            "af3aca4a0ada47e991c5ee8a8f9d4dd6",
            "4a34bc12c6e449cb9996e6836d97f20c",
            "3a49cd59e48241cabf80f9c04368efab",
            "167d87f38572475fa5d7a0655e2321fc",
            "f1a43927a9034fdaa074d0945cc2255d",
            "2afe7a21ba174c8f971bcc62f2b20595",
            "55d4606b360e410aa317d30f767c923a",
            "9f01d75959294a7aa4f7cce06752ef14",
            "156d986dc2864d508967518245297ba7",
            "31cf638896ce47e5a7f2f616af580358",
            "6d3589907f2f4a6d90312ddb1d2febae",
            "a0281a505220485990d55729f1d5390e",
            "e616dda39e4b447eaa7d773deb42ae3f",
            "b301b06111b84d898a641a6bc36226f0",
            "a7233066e39f4a3ab2bb678a8dba3bc9"
          ]
        },
        "id": "voIPi8YrFa3d",
        "outputId": "f82289b6-737d-4a3d-ca9e-8fd38ffb5d1c"
      },
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "model_op = torch.load(\"/content/drive/MyDrive/P2S13/aisound3.pt\")\n",
        "model_op2,best_test_loss_op = main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set, model=model_op)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f6e3b0a089245f8a01a9b046aa08f58",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6387309499.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f01d75959294a7aa4f7cce06752ef14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=346663984.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num Model Parameters 23705373\n",
            "Train Epoch: 1 [0/28539 (0%)]\tLoss: 0.454566\n",
            "Train Epoch: 1 [1000/28539 (4%)]\tLoss: 0.442151\n",
            "Train Epoch: 1 [2000/28539 (7%)]\tLoss: 0.522667\n",
            "Train Epoch: 1 [3000/28539 (11%)]\tLoss: 0.354080\n",
            "Train Epoch: 1 [4000/28539 (14%)]\tLoss: 0.511420\n",
            "Train Epoch: 1 [5000/28539 (18%)]\tLoss: 0.543448\n",
            "Train Epoch: 1 [6000/28539 (21%)]\tLoss: 0.553612\n",
            "Train Epoch: 1 [7000/28539 (25%)]\tLoss: 0.406260\n",
            "Train Epoch: 1 [8000/28539 (28%)]\tLoss: 0.585254\n",
            "Train Epoch: 1 [9000/28539 (32%)]\tLoss: 0.463110\n",
            "Train Epoch: 1 [10000/28539 (35%)]\tLoss: 0.443648\n",
            "Train Epoch: 1 [11000/28539 (39%)]\tLoss: 0.530933\n",
            "Train Epoch: 1 [12000/28539 (42%)]\tLoss: 0.587255\n",
            "Train Epoch: 1 [13000/28539 (46%)]\tLoss: 0.505934\n",
            "Train Epoch: 1 [14000/28539 (49%)]\tLoss: 0.547821\n",
            "Train Epoch: 1 [15000/28539 (53%)]\tLoss: 0.581341\n",
            "Train Epoch: 1 [16000/28539 (56%)]\tLoss: 0.447537\n",
            "Train Epoch: 1 [17000/28539 (60%)]\tLoss: 0.418922\n",
            "Train Epoch: 1 [18000/28539 (63%)]\tLoss: 0.490420\n",
            "Train Epoch: 1 [19000/28539 (67%)]\tLoss: 0.568878\n",
            "Train Epoch: 1 [20000/28539 (70%)]\tLoss: 0.590847\n",
            "Train Epoch: 1 [21000/28539 (74%)]\tLoss: 0.477306\n",
            "Train Epoch: 1 [22000/28539 (77%)]\tLoss: 0.401746\n",
            "Train Epoch: 1 [23000/28539 (81%)]\tLoss: 0.546403\n",
            "Train Epoch: 1 [24000/28539 (84%)]\tLoss: 0.663825\n",
            "Train Epoch: 1 [25000/28539 (88%)]\tLoss: 0.467124\n",
            "Train Epoch: 1 [26000/28539 (91%)]\tLoss: 0.516430\n",
            "Train Epoch: 1 [27000/28539 (95%)]\tLoss: 0.447980\n",
            "Train Epoch: 1 [28000/28539 (98%)]\tLoss: 0.389780\n",
            "\n",
            "evaluating...\n",
            "Saving model as current test_loss 0.4631160326472677 < prev test_loss 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type SpeechRecognitionModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type ResidualCNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CNNLayerNorm. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BidirectionalGRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.4631, Average CER: 0.129323 Average WER: 0.3939\n",
            "\n",
            "Train Epoch: 2 [0/28539 (0%)]\tLoss: 0.463753\n",
            "Train Epoch: 2 [1000/28539 (4%)]\tLoss: 0.569464\n",
            "Train Epoch: 2 [2000/28539 (7%)]\tLoss: 0.460235\n",
            "Train Epoch: 2 [3000/28539 (11%)]\tLoss: 0.640374\n",
            "Train Epoch: 2 [4000/28539 (14%)]\tLoss: 0.499412\n",
            "Train Epoch: 2 [5000/28539 (18%)]\tLoss: 0.557883\n",
            "Train Epoch: 2 [6000/28539 (21%)]\tLoss: 0.414785\n",
            "Train Epoch: 2 [7000/28539 (25%)]\tLoss: 0.461332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmiqGrGgFkZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}