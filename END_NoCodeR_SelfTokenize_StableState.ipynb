{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "END_NoCodeR_SelfTokenize_StableState.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a893ee4858a49609614dc740b46cae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63b5833a915b43d286a3ffa1fed36bb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd5a5ded35054f4bb73511632fad31d0",
              "IPY_MODEL_7045a506e6e746bd9dc9e6d5bbc10b48"
            ]
          }
        },
        "63b5833a915b43d286a3ffa1fed36bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd5a5ded35054f4bb73511632fad31d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_679adf2dc3da486baaf7912e2e48c197",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898822,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898822,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e51e5d4e63bf48d1a800c0e2cfdad4ee"
          }
        },
        "7045a506e6e746bd9dc9e6d5bbc10b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d26546ee67284cccaef0e545665f0d29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:03&lt;00:00, 287kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09eeff2dd75e496184bc4ba281e8ee1e"
          }
        },
        "679adf2dc3da486baaf7912e2e48c197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e51e5d4e63bf48d1a800c0e2cfdad4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d26546ee67284cccaef0e545665f0d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09eeff2dd75e496184bc4ba281e8ee1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3253380c6f2417d9604121872071dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71568abfe3094ce194aba20dbef6bfa3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45374e949fbd47f1a57bd55ccc3a2c9a",
              "IPY_MODEL_95003b3d053d4fdd988f8d397490007e"
            ]
          }
        },
        "71568abfe3094ce194aba20dbef6bfa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45374e949fbd47f1a57bd55ccc3a2c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_923bf52abfb04510a4ad2e016640897f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5e8208b97cf43448ba8c8e2f33ba084"
          }
        },
        "95003b3d053d4fdd988f8d397490007e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e84338ae51f84b3a837309f8ed348b99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:01&lt;00:00, 373kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a327090cbd9f4fafa919c3a58a4b05ec"
          }
        },
        "923bf52abfb04510a4ad2e016640897f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5e8208b97cf43448ba8c8e2f33ba084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e84338ae51f84b3a837309f8ed348b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a327090cbd9f4fafa919c3a58a4b05ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb9c09cbae1a41bc94ef7ffaef2ea5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c0ea3e9a91d4cabb889acb4a02987dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c74955c560204b718c3b398698d9fa06",
              "IPY_MODEL_29ff0901506247cdbcac326182360f0c"
            ]
          }
        },
        "2c0ea3e9a91d4cabb889acb4a02987dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c74955c560204b718c3b398698d9fa06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_32ac71a5deb347b8bc14f00441ae9bd0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d1da9f67638477c9137b59a6b9c10e3"
          }
        },
        "29ff0901506247cdbcac326182360f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_998bae5ca6a34d6099e9364bd3319b63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [00:00&lt;00:00, 168B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c269906d100f42a2be3a072b48977db2"
          }
        },
        "32ac71a5deb347b8bc14f00441ae9bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d1da9f67638477c9137b59a6b9c10e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "998bae5ca6a34d6099e9364bd3319b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c269906d100f42a2be3a072b48977db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a582e15bf734bf2b46a36a478c7a94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a3bba28e8e04a6bad991fb650a349dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ed58796e4904704b6319c39845bc589",
              "IPY_MODEL_cc1b04e349c54000a286badc9305aade"
            ]
          }
        },
        "2a3bba28e8e04a6bad991fb650a349dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ed58796e4904704b6319c39845bc589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6911b7d7e0eb4ce99328016ea76420c4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baf5c04e99d8403088ab9b1a0082ba4f"
          }
        },
        "cc1b04e349c54000a286badc9305aade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_00f09554950b49e081843c07e6d118eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25.0/25.0 [00:00&lt;00:00, 75.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_527f2887609c45d5bac35249f859474c"
          }
        },
        "6911b7d7e0eb4ce99328016ea76420c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baf5c04e99d8403088ab9b1a0082ba4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "00f09554950b49e081843c07e6d118eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "527f2887609c45d5bac35249f859474c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c926f03975ce4799b8762ce734acf3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c07cd844b61144d1963e182b07b0b264",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3670a84980aa449bb1ddfedc909b307a",
              "IPY_MODEL_d6c23996604e415aa3c421675552b24c"
            ]
          }
        },
        "c07cd844b61144d1963e182b07b0b264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3670a84980aa449bb1ddfedc909b307a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_18a0f9bb4f924f23b7468ea2657516d4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 498,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 498,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6339399688f741b3aeb54dd4a3b81213"
          }
        },
        "d6c23996604e415aa3c421675552b24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_377fb906a5414627b70c1dbd72d77db2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498/498 [00:01&lt;00:00, 303B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1fab4c407b849a098afd864112d5909"
          }
        },
        "18a0f9bb4f924f23b7468ea2657516d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6339399688f741b3aeb54dd4a3b81213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "377fb906a5414627b70c1dbd72d77db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1fab4c407b849a098afd864112d5909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/EVAP2/blob/master/END_NoCodeR_SelfTokenize_StableState.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOdNYOq_V5C3",
        "outputId": "99e342c8-2b32-4af6-b52f-c3718017f3fa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 10 16:06:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4uN4sSQlA7w"
      },
      "source": [
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import fileinput\r\n",
        "import re\r\n",
        "import itertools\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from IPython.core.display import display, HTML\r\n",
        "#import seaborn as sns\r\n",
        "import dateutil.parser\r\n",
        "import datetime\r\n",
        "#from ipyfilechooser import FileChooser\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import gzip\r\n",
        "import dateutil.parser\r\n",
        "from datetime import datetime\r\n",
        "import sys\r\n",
        "import glob\r\n",
        "import matplotlib.dates as mdates\r\n",
        "from datetime import timedelta\r\n",
        "import ipywidgets as widgets\r\n",
        "from IPython.display import display\r\n",
        "import torch\r\n",
        "import json\r\n",
        "import random\r\n",
        "import spacy\r\n",
        "from pprint import pprint\r\n",
        "import six\r\n",
        "import sys, token, tokenize\r\n",
        "import ast\r\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\r\n",
        "                              TensorDataset)\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time\r\n",
        "from torch.utils.data.distributed import DistributedSampler\r\n",
        "#from tensorboardX import SummaryWriter\r\n",
        "from tqdm import tqdm, trange\r\n",
        "USE_CUDA = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\r\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzTyfBvwcT50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb2b665-0ce6-48a5-b3ec-3a4850ba5675"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRNwGADTvOuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cae70b-6c5b-4944-dc8e-a150e0440c69"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=e4e2251f0c93184cc71d44c6b202259a1327fb40572a0a1e6db193edda67153d\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XDZbeWK6u_"
      },
      "source": [
        "from torch.jit import script, trace\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\r\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\r\n",
        "import tokenize"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_7b5amJJIQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea84783-55c5-4ad6-c4ad-6aba7e3cff3e"
      },
      "source": [
        "%%bash\r\n",
        "python -m spacy download en\r\n",
        "python -m spacy download de"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py): started\n",
            "  Building wheel for de-core-news-sm (setup.py): finished with status 'done'\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=32433f781fd3dafcacb10b6857fc89b16e71fb49eff4c234ce2630f6bedee6e4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1jvv7syg/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2mâœ” Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqKpFyhplfvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1952bf-c4cf-48ca-fa8d-c96c408bfd3c"
      },
      "source": [
        "!wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\r\n",
        "!wget -O gpt2_bpe_encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\r\n",
        "\r\n",
        "!unzip /content/python.zip\r\n",
        "!cp /content/python/final/jsonl/train/python_train_0.jsonl.gz .\r\n",
        "!gzip -d /content/python_train_0.jsonl.gz\r\n",
        "\r\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/english_python_data.txt .\r\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/english_python_cleaned.txt .\r\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone.csv ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-10 16:08:03--  https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.230.109\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.230.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 940909997 (897M) [application/zip]\n",
            "Saving to: â€˜python.zipâ€™\n",
            "\n",
            "python.zip          100%[===================>] 897.32M  35.3MB/s    in 26s     \n",
            "\n",
            "2021-03-10 16:08:29 (34.2 MB/s) - â€˜python.zipâ€™ saved [940909997/940909997]\n",
            "\n",
            "--2021-03-10 16:08:30--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [text/plain]\n",
            "Saving to: â€˜gpt2_bpe_encoder.jsonâ€™\n",
            "\n",
            "gpt2_bpe_encoder.js 100%[===================>]   1018K  1.26MB/s    in 0.8s    \n",
            "\n",
            "2021-03-10 16:08:31 (1.26 MB/s) - â€˜gpt2_bpe_encoder.jsonâ€™ saved [1042301/1042301]\n",
            "\n",
            "Archive:  /content/python.zip\n",
            "   creating: python/\n",
            "   creating: python/final/\n",
            "   creating: python/final/jsonl/\n",
            "   creating: python/final/jsonl/train/\n",
            "  inflating: python/final/jsonl/train/python_train_9.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_12.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_10.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_0.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_6.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_2.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_4.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_8.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_11.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_5.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_13.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_3.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_1.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_7.jsonl.gz  \n",
            "   creating: python/final/jsonl/test/\n",
            "  inflating: python/final/jsonl/test/python_test_0.jsonl.gz  \n",
            "   creating: python/final/jsonl/valid/\n",
            "  inflating: python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
            "  inflating: python_dedupe_definitions_v2.pkl  \n",
            "  inflating: python_licenses.pkl     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGoF0UiKmLg-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "2a893ee4858a49609614dc740b46cae6",
            "63b5833a915b43d286a3ffa1fed36bb6",
            "fd5a5ded35054f4bb73511632fad31d0",
            "7045a506e6e746bd9dc9e6d5bbc10b48",
            "679adf2dc3da486baaf7912e2e48c197",
            "e51e5d4e63bf48d1a800c0e2cfdad4ee",
            "d26546ee67284cccaef0e545665f0d29",
            "09eeff2dd75e496184bc4ba281e8ee1e",
            "c3253380c6f2417d9604121872071dc6",
            "71568abfe3094ce194aba20dbef6bfa3",
            "45374e949fbd47f1a57bd55ccc3a2c9a",
            "95003b3d053d4fdd988f8d397490007e",
            "923bf52abfb04510a4ad2e016640897f",
            "e5e8208b97cf43448ba8c8e2f33ba084",
            "e84338ae51f84b3a837309f8ed348b99",
            "a327090cbd9f4fafa919c3a58a4b05ec",
            "cb9c09cbae1a41bc94ef7ffaef2ea5ab",
            "2c0ea3e9a91d4cabb889acb4a02987dd",
            "c74955c560204b718c3b398698d9fa06",
            "29ff0901506247cdbcac326182360f0c",
            "32ac71a5deb347b8bc14f00441ae9bd0",
            "8d1da9f67638477c9137b59a6b9c10e3",
            "998bae5ca6a34d6099e9364bd3319b63",
            "c269906d100f42a2be3a072b48977db2",
            "3a582e15bf734bf2b46a36a478c7a94d",
            "2a3bba28e8e04a6bad991fb650a349dc",
            "4ed58796e4904704b6319c39845bc589",
            "cc1b04e349c54000a286badc9305aade",
            "6911b7d7e0eb4ce99328016ea76420c4",
            "baf5c04e99d8403088ab9b1a0082ba4f",
            "00f09554950b49e081843c07e6d118eb",
            "527f2887609c45d5bac35249f859474c",
            "c926f03975ce4799b8762ce734acf3ff",
            "c07cd844b61144d1963e182b07b0b264",
            "3670a84980aa449bb1ddfedc909b307a",
            "d6c23996604e415aa3c421675552b24c",
            "18a0f9bb4f924f23b7468ea2657516d4",
            "6339399688f741b3aeb54dd4a3b81213",
            "377fb906a5414627b70c1dbd72d77db2",
            "e1fab4c407b849a098afd864112d5909"
          ]
        },
        "outputId": "b0b4f6f3-0447-4345-bbef-9411808bfec0"
      },
      "source": [
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\r\n",
        "from transformers import AutoTokenizer, AutoModel\r\n",
        "\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\r\n",
        "auto_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "def tokenize_en(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\r\n",
        "#model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\r\n",
        "#model.to(device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a893ee4858a49609614dc740b46cae6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3253380c6f2417d9604121872071dc6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb9c09cbae1a41bc94ef7ffaef2ea5ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a582e15bf734bf2b46a36a478c7a94d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=25.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c926f03975ce4799b8762ce734acf3ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=498.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NPC5Tjn-eHe"
      },
      "source": [
        "\"\"\"\r\n",
        "    Removes docstrings and comments\r\n",
        "\"\"\"\r\n",
        "def remove_docstrings_comments(src_string, doc_string=None, debug=False):\r\n",
        "    mod = []\r\n",
        "\r\n",
        "    prev_toktype = token.INDENT\r\n",
        "    first_line = None\r\n",
        "    last_lineno = -1\r\n",
        "    last_col = 0\r\n",
        "    try:\r\n",
        "        #tokgen = tokenize.generate_tokens(source.readline)\r\n",
        "        tokgen = tokenize.generate_tokens(six.StringIO(src_string.rstrip()).readline)\r\n",
        "        for toktype, ttext, (slineno, scol), (elineno, ecol), ltext in tokgen:\r\n",
        "            if 0:   # Change to if 1 to see the tokens fly by.\r\n",
        "                print(\"%10s %-14s %-20r %r\" % (\r\n",
        "                    tokenize.tok_name.get(toktype, toktype),\r\n",
        "                    \"%d.%d-%d.%d\" % (slineno, scol, elineno, ecol),\r\n",
        "                    ttext, ltext\r\n",
        "                    ))\r\n",
        "            if slineno > last_lineno:\r\n",
        "                last_col = 0\r\n",
        "            if scol > last_col:\r\n",
        "                mod.append(\" \" * (scol - last_col))\r\n",
        "            if toktype == token.STRING and prev_toktype == token.INDENT:\r\n",
        "                # Docstring\r\n",
        "                mod.append(\"#--\")\r\n",
        "            elif toktype == tokenize.COMMENT:\r\n",
        "                # Comment\r\n",
        "                mod.append(\"##\")\r\n",
        "            else:\r\n",
        "                mod.append(ttext)\r\n",
        "            prev_toktype = toktype\r\n",
        "            last_col = ecol\r\n",
        "            last_lineno = elineno\r\n",
        "        return \"\".join(mod)\r\n",
        "    except:\r\n",
        "        print(doc_string)\r\n",
        "        print(src_string )\r\n",
        "        print(sys.exc_info())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1px_H2FL3xEE"
      },
      "source": [
        "### CodeSearchNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0T-ZXnm-z3J"
      },
      "source": [
        "columns_long_list = ['repo', 'path', 'url', 'code', \r\n",
        "                     'code_tokens', 'docstring', 'docstring_tokens', \r\n",
        "                     'language', 'partition']\r\n",
        "\r\n",
        "with open(\"/content/python_train_0.jsonl\",'r') as f:\r\n",
        "    pd.concat([pd.read_json(f, \r\n",
        "                            orient='records', \r\n",
        "                            lines=True)[columns_long_list] \r\n",
        "                        ], sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4kcq2qc--AE"
      },
      "source": [
        "with open(\"/content/python_train_0.jsonl\",'r') as f:\r\n",
        "    my_df=pd.read_json(f, \r\n",
        "                orient='records', \r\n",
        "                lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhJZMD7y-bev"
      },
      "source": [
        "my_df_copy = my_df.loc[:20000,['docstring', 'code']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMGDaIM-_L62"
      },
      "source": [
        "my_df_copy['docstring_len'] =my_df_copy['docstring'].apply(lambda x: len(x))\r\n",
        "my_df_copy['code_len'] = my_df_copy['code'].apply(lambda x: len(x))\r\n",
        "my_df_copy['cleaned_code'] = my_df_copy.apply(lambda x: remove_docstrings_comments(x.code, x.docstring), axis=1)\r\n",
        "my_df_copy['cleaned_code_len'] = my_df_copy['cleaned_code'].apply(lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08lnHBCS_CFs",
        "outputId": "8114131b-94f5-4d73-8cc5-a8949c4617e5"
      },
      "source": [
        "my_df_copy[my_df_copy['cleaned_code_len'] <= 256].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "docstring           5612\n",
              "code                5612\n",
              "docstring_len       5612\n",
              "code_len            5612\n",
              "cleaned_code        5612\n",
              "cleaned_code_len    5612\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltpMfQiZTFhA"
      },
      "source": [
        "with open(\"gpt2_bpe_encoder.json\") as f:\r\n",
        "    gpt2_bpe=json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JA2hXmMeGWl"
      },
      "source": [
        "my_df_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kglj0SUbeIP7"
      },
      "source": [
        "nl_to_pl_df = nl_to_pl_df.append(my_df_copy,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c35HYbYxWBk7"
      },
      "source": [
        "### Create datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nobKWg_DJ5Xp"
      },
      "source": [
        "nl_to_pl_df = pd.read_csv('/content/end_capstone.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prv7EIAX5aOj"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7nruWfNQNB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "94e0f5ff-080e-468c-9bf8-4b9339b04c27"
      },
      "source": [
        "print(nl_to_pl_df['code_len'].max(),nl_to_pl_df['code_len'].min())\r\n",
        "print(nl_to_pl_df['docstring_len'].max(),nl_to_pl_df['docstring_len'].min())\r\n",
        "nl_to_pl_df[nl_to_pl_df['code_len'] ==0]\r\n",
        "nl_to_pl_df[(nl_to_pl_df['code_len'] > 256) & (nl_to_pl_df['code_len'] < 512)] "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2443 11\n",
            "313 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docstring</th>\n",
              "      <th>code</th>\n",
              "      <th>docstring_len</th>\n",
              "      <th>code_len</th>\n",
              "      <th>cleaned_code</th>\n",
              "      <th>cleaned_code_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td># Write a program to check whether a number is...</td>\n",
              "      <td>num = 337\\n\\nif num &gt; 1:\\n    for i in range(2...</td>\n",
              "      <td>60</td>\n",
              "      <td>311</td>\n",
              "      <td>num = 337\\n\\nif num &gt; 1:\\n    for i in range(2...</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td># Write a program to find the factorial of a n...</td>\n",
              "      <td>num = 13\\nfactorial = 1\\n\\nif num &lt; 0:\\n    pr...</td>\n",
              "      <td>52</td>\n",
              "      <td>265</td>\n",
              "      <td>num = 13\\nfactorial = 1\\n\\nif num &lt; 0:\\n    pr...</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td># Write a function that takes in height(m) and...</td>\n",
              "      <td>\\ndef bmi(height: \"Meters\", weight: \"Kgs\"):\\n ...</td>\n",
              "      <td>98</td>\n",
              "      <td>450</td>\n",
              "      <td>\\ndef bmi(height: \"Meters\", weight: \"Kgs\"):\\n ...</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td># write a python program to sort dictionary it...</td>\n",
              "      <td>dict1 = {'car': [7, 6, 3],  \\n        'bike': ...</td>\n",
              "      <td>50</td>\n",
              "      <td>262</td>\n",
              "      <td>dict1 = {'car': [7, 6, 3],  \\n        'bike': ...</td>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td># write a python program to Get the maximum an...</td>\n",
              "      <td>\\nmy_dict = {'x':500, 'y':5874, 'z': 560}\\n\\nk...</td>\n",
              "      <td>78</td>\n",
              "      <td>276</td>\n",
              "      <td>\\nmy_dict = {'x':500, 'y':5874, 'z': 560}\\n\\nk...</td>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4352</th>\n",
              "      <td># Define a class named Shape and its subclass ...</td>\n",
              "      <td>\\n\\nclass Shape(object):\\n    def __init__(sel...</td>\n",
              "      <td>234</td>\n",
              "      <td>314</td>\n",
              "      <td>\\n\\nclass Shape(object):\\n    def __init__(sel...</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4354</th>\n",
              "      <td># Write a python program for a binary search f...</td>\n",
              "      <td>import math\\ndef bin_search(li, element):\\n   ...</td>\n",
              "      <td>171</td>\n",
              "      <td>390</td>\n",
              "      <td>import math\\ndef bin_search(li, element):\\n   ...</td>\n",
              "      <td>388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4359</th>\n",
              "      <td># Write a python program to check if a number ...</td>\n",
              "      <td>n = int(input(\"Enter any number: \"))\\nsum1 = 0...</td>\n",
              "      <td>67</td>\n",
              "      <td>261</td>\n",
              "      <td>n = int(input(\"Enter any number: \"))\\nsum1 = 0...</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4360</th>\n",
              "      <td># Write a python program to Check if a Number ...</td>\n",
              "      <td>sum1 = 0\\nnum = int(input(\"Enter a number:\"))\\...</td>\n",
              "      <td>65</td>\n",
              "      <td>347</td>\n",
              "      <td>sum1 = 0\\nnum = int(input(\"Enter a number:\"))\\...</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4362</th>\n",
              "      <td># Write python program to find whether-number-...</td>\n",
              "      <td>def is_power_of_two(n):\\n    \"\"\"Return True if...</td>\n",
              "      <td>56</td>\n",
              "      <td>310</td>\n",
              "      <td>def is_power_of_two(n):\\n    #--\\n    if n &lt;= ...</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>613 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              docstring  ... cleaned_code_len\n",
              "5     # Write a program to check whether a number is...  ...              308\n",
              "7     # Write a program to find the factorial of a n...  ...              262\n",
              "53    # Write a function that takes in height(m) and...  ...              447\n",
              "62    # write a python program to sort dictionary it...  ...              260\n",
              "74    # write a python program to Get the maximum an...  ...              274\n",
              "...                                                 ...  ...              ...\n",
              "4352  # Define a class named Shape and its subclass ...  ...              312\n",
              "4354  # Write a python program for a binary search f...  ...              388\n",
              "4359  # Write a python program to check if a number ...  ...              259\n",
              "4360  # Write a python program to Check if a Number ...  ...              345\n",
              "4362  # Write python program to find whether-number-...  ...              270\n",
              "\n",
              "[613 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJUyE3S39KWy"
      },
      "source": [
        "def set_seed(seed):\r\n",
        "    random.seed(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    # if n_gpu > 0:\r\n",
        "    #     torch.cuda.manual_seed_all(seed)\r\n",
        "set_seed(0x1112233)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDY67cXevhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04dbc50b-a7e1-481b-86ca-5d4ec1ce9aee"
      },
      "source": [
        "!cp -rf /content/drive/MyDrive/EVA4/END_Capstone/cubert .\r\n",
        "!pip install -r /content/cubert/requirements.txt\r\n",
        "sys.path.append(\"/content/cubert/\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 5.6MB/s \n",
            "\u001b[?25hCollecting dopamine-rl==3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/a8/7cf1fe1b5b11a7165c8901bc50091e3fa68f97f48fb4035f31cf6fc675f2/dopamine_rl-3.0.1-py3-none-any.whl (84kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from -r /content/cubert/requirements.txt (line 3)) (2019.12.20)\n",
            "Collecting tensor2tensor\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/7c/9e87d30cefad5cbc390bb7f626efb3ded9b19416b8160f1a1278da81b218/tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 16.2MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow->-r /content/cubert/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: opencv-python>=3.4.1.15 in /usr/local/lib/python3.7/dist-packages (from dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (4.1.2.30)\n",
            "Requirement already satisfied: gym>=0.10.5 in /usr/local/lib/python3.7/dist-packages (from dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (0.17.3)\n",
            "Requirement already satisfied: Pillow>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: gin-config>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (0.10.0)\n",
            "Collecting kfac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/36/06fe2c757044bb51906fef231ac48cc5bf9a277fc9a8c7e1108d7e9e8cfd/kfac-0.2.3-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194kB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.23.0)\n",
            "Collecting tf-slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 358kB 36.8MB/s \n",
            "\u001b[?25hCollecting bz2file\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (4.1.3)\n",
            "Collecting tensorflow-probability==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/3a/c10b6c22320531c774402ac7186d1b673374e2a9d12502cbc8d811e4601c/tensorflow_probability-0.7.0-py2.py3-none-any.whl (981kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 983kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.7.1)\n",
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 706kB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (4.41.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (4.0.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.12.8)\n",
            "Collecting mesh-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/20/23bbc94034e16bb1ace73e9e7922226e31d6d36b88dcfa257d2c59b3f465/mesh_tensorflow-0.1.18-py3-none-any.whl (361kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368kB 35.2MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.4.1)\n",
            "Collecting tensorflow-gan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/2e/62922111d7d50e1900e3030764743ea7735540ce103b3ab30fd5cd2d8a2b/tensorflow_gan-2.0.0-py2.py3-none-any.whl (365kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368kB 40.9MB/s \n",
            "\u001b[?25hCollecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 655kB 41.3MB/s \n",
            "\u001b[?25hCollecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.6MB 38.3MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (0.36.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.10.5->dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.10.5->dopamine-rl==3.0.1->-r /content/cubert/requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.11.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.17.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (4.7.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.7.0->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.3.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (20.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.28.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (5.1.2)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.26.1)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.27.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (54.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gan->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (0.11.0)\n",
            "Collecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Collecting greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/25/f52f0dde4135833c2f85eae30a749d260231065b46942534df8366d7e1ec/greenlet-1.0.0-cp37-cp37m-manylinux2010_x86_64.whl (160kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 37.8MB/s \n",
            "\u001b[?25hCollecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/42/d8f11eaef844bee267821281fffe445e49cf31b486d72a81821a9d45cd0a/zope.interface-5.2.0-cp37-cp37m-manylinux2010_x86_64.whl (237kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (3.3.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (1.53.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (3.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client->tensor2tensor->-r /content/cubert/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15->-r /content/cubert/requirements.txt (line 5)) (3.7.4.3)\n",
            "Building wheels for collected packages: bz2file, pypng, gast\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-cp37-none-any.whl size=6884 sha256=cb910d33c9797025a7912ceb0e00f26e13984559df5e402b8648bcb985bd48ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp37-none-any.whl size=67163 sha256=9b359d4ee3330e3d391af4f29dc153c082f3bd78f9721f8859ea8b25d981f72b\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=0306f6a6b2e4b803246cd5d73081efc89f0480b6b910708389d58afcf51fea8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built bz2file pypng gast\n",
            "\u001b[31mERROR: kfac 0.2.3 has requirement tensorflow-probability==0.8, but you'll have tensorflow-probability 0.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: bert-tensorflow, dopamine-rl, tensorflow-probability, kfac, tf-slim, bz2file, tensorflow-addons, mesh-tensorflow, gunicorn, tensorflow-gan, pypng, zope.event, greenlet, zope.interface, gevent, tensor2tensor, keras-applications, tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: dopamine-rl 1.0.5\n",
            "    Uninstalling dopamine-rl-1.0.5:\n",
            "      Successfully uninstalled dopamine-rl-1.0.5\n",
            "  Found existing installation: tensorflow-probability 0.12.1\n",
            "    Uninstalling tensorflow-probability-0.12.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.12.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed bert-tensorflow-1.0.4 bz2file-0.98 dopamine-rl-3.0.1 gast-0.2.2 gevent-21.1.2 greenlet-1.0.0 gunicorn-20.0.4 keras-applications-1.0.8 kfac-0.2.3 mesh-tensorflow-0.1.18 pypng-0.0.20 tensor2tensor-1.15.7 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-addons-0.12.1 tensorflow-estimator-1.15.1 tensorflow-gan-2.0.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3k4UAjKgagA"
      },
      "source": [
        "\"\"\"A Python tokenizer subclass of CuBertTokenizer.\"\"\"\r\n",
        "import keyword\r\n",
        "import re\r\n",
        "import tokenize\r\n",
        "import typing\r\n",
        "from typing import Any\r\n",
        "from typing import List\r\n",
        "from typing import Sequence\r\n",
        "from typing import Tuple\r\n",
        "from absl import logging\r\n",
        "from cubert import cubert_tokenizer\r\n",
        "from cubert import unified_tokenizer\r\n",
        "\r\n",
        "\r\n",
        "class PythonTokenizer2(cubert_tokenizer.CuBertTokenizer):\r\n",
        "  \"\"\"Tokenizer that extracts Python's lexical elements preserving strings.\"\"\"\r\n",
        "  _TOKEN_TYPE_MAP = {\r\n",
        "      tokenize.COMMENT: unified_tokenizer.TokenKind.COMMENT,\r\n",
        "      tokenize.DEDENT: unified_tokenizer.TokenKind.KEYWORD,\r\n",
        "      tokenize.ENDMARKER: unified_tokenizer.TokenKind.EOS,\r\n",
        "      tokenize.ERRORTOKEN: unified_tokenizer.TokenKind.ERROR,\r\n",
        "      tokenize.INDENT: unified_tokenizer.TokenKind.KEYWORD,\r\n",
        "      tokenize.NEWLINE: unified_tokenizer.TokenKind.NEWLINE,\r\n",
        "      tokenize.NL: unified_tokenizer.TokenKind.PUNCTUATION,\r\n",
        "      tokenize.NUMBER: unified_tokenizer.TokenKind.NUMBER,\r\n",
        "      tokenize.OP: unified_tokenizer.TokenKind.PUNCTUATION,\r\n",
        "      tokenize.STRING: unified_tokenizer.TokenKind.STRING,\r\n",
        "  }\r\n",
        "  _REVERSE_TOKEN_MAP = {\r\n",
        "      cubert_tokenizer.token_from_token_type(tokenize.INDENT):\r\n",
        "          tokenize.INDENT,\r\n",
        "      cubert_tokenizer.token_from_token_type(tokenize.DEDENT):\r\n",
        "          tokenize.DEDENT,\r\n",
        "      unified_tokenizer.quote_special(unified_tokenizer.TokenKind.EOS.name):\r\n",
        "          tokenize.ENDMARKER,\r\n",
        "      unified_tokenizer.quote_special(unified_tokenizer.TokenKind.ERROR.name):\r\n",
        "          tokenize.ERRORTOKEN,\r\n",
        "      unified_tokenizer.quote_special(unified_tokenizer.TokenKind.NEWLINE.name):\r\n",
        "          tokenize.NEWLINE,\r\n",
        "      cubert_tokenizer.token_from_token_type(tokenize.NL):\r\n",
        "          tokenize.NL,\r\n",
        "  }\r\n",
        "  # Adding the end-of-string anchor \\Z below, since re.fullmatch wasn't\r\n",
        "  # available in Python2.\r\n",
        "  _NUMBERS = re.compile('(' + tokenize.Number + r')\\Z')  # pytype: disable=module-attr\r\n",
        "  _SINGLE_STRINGS = re.compile('(' + tokenize.String + r')\\Z')  # pytype: disable=module-attr\r\n",
        "  _TRIPLE_STRING_BEGINNINGS = re.compile(tokenize.Triple)  # pytype: disable=module-attr\r\n",
        "  _COMMENTS = re.compile('(' + tokenize.Comment + r')\\Z')  # pytype: disable=module-attr\r\n",
        "\r\n",
        "  _EXACT_TOKEN_TYPES = tokenize.EXACT_TOKEN_TYPES.keys()  # pytype: disable=module-attr\r\n",
        "\r\n",
        "  # Token types that CubertTokenizer will tokenize by their type and not\r\n",
        "  # content.\r\n",
        "  _TOKEN_TYPES_TO_TOKENIZE_BY_TYPE = [\r\n",
        "      tokenize.NEWLINE, tokenize.DEDENT, tokenize.NL\r\n",
        "  ]\r\n",
        "\r\n",
        "  def tokenize_and_abstract(\r\n",
        "      self,\r\n",
        "      source_code):\r\n",
        "    \"\"\"Produces a language-agnostic tokenization of the input code.\"\"\"\r\n",
        "    agnostic_tokens: List[unified_tokenizer.AbstractToken] = []\r\n",
        "\r\n",
        "    try:\r\n",
        "      token_tuples = unified_tokenizer.code_to_tokens(source_code)\r\n",
        "    except (tokenize.TokenError, IndentationError) as e:\r\n",
        "      logging.warning('The tokenizer raised exception `%s` while parsing %s', e,\r\n",
        "                      source_code)\r\n",
        "\r\n",
        "      # We don't try to do recovery from errors quite yet. Emit just an\r\n",
        "      # error and end-of-sequence and return.\r\n",
        "      agnostic_tokens.append(\r\n",
        "          unified_tokenizer.AbstractToken(\r\n",
        "              unified_tokenizer.quote_special(\r\n",
        "                  unified_tokenizer.TokenKind.ERROR.name),\r\n",
        "              unified_tokenizer.TokenKind.ERROR,\r\n",
        "              unified_tokenizer.TokenMetadata(\r\n",
        "                  start=unified_tokenizer.Position(\r\n",
        "                      line=0, column=0),\r\n",
        "                  end=unified_tokenizer.Position(\r\n",
        "                      line=0, column=0))))\r\n",
        "      agnostic_tokens.append(\r\n",
        "          unified_tokenizer.AbstractToken(\r\n",
        "              unified_tokenizer.quote_special(\r\n",
        "                  unified_tokenizer.TokenKind.EOS.name),\r\n",
        "              unified_tokenizer.TokenKind.EOS,\r\n",
        "              unified_tokenizer.TokenMetadata(\r\n",
        "                  start=unified_tokenizer.Position(\r\n",
        "                      line=0, column=0),\r\n",
        "                  end=unified_tokenizer.Position(\r\n",
        "                      line=0, column=0))))\r\n",
        "      return agnostic_tokens\r\n",
        "\r\n",
        "    for token_tuple in token_tuples:\r\n",
        "      spelling = token_tuple.string\r\n",
        "      kind = token_tuple.type\r\n",
        "\r\n",
        "      # We'll adjust the spelling of some tokens, e.g., those that we\r\n",
        "      # tokenize by their type rather than their original spelling. Indentation\r\n",
        "      # and dedentation tokens are like that.\r\n",
        "      adjusted_spelling = spelling\r\n",
        "      token_kind = unified_tokenizer.TokenKind.NONE\r\n",
        "      if kind == tokenize.NAME:\r\n",
        "        # Disambiguate identifiers from keywords.\r\n",
        "        if keyword.iskeyword(spelling):\r\n",
        "          token_kind = unified_tokenizer.TokenKind.KEYWORD\r\n",
        "        else:\r\n",
        "          token_kind = unified_tokenizer.TokenKind.IDENTIFIER\r\n",
        "      else:\r\n",
        "        if kind in PythonTokenizer2._TOKEN_TYPES_TO_TOKENIZE_BY_TYPE:\r\n",
        "          # Replace spelling with type.\r\n",
        "          adjusted_spelling = cubert_tokenizer.token_from_token_type(kind)\r\n",
        "        elif kind is tokenize.INDENT:\r\n",
        "          # For INDENT, in particular, we also record the actual spelling too.\r\n",
        "          adjusted_spelling = '{indent}{spelling}'.format(\r\n",
        "              indent=cubert_tokenizer.token_from_token_type(kind),\r\n",
        "              spelling=spelling)\r\n",
        "          #print(adjusted_spelling)\r\n",
        "        elif kind == tokenize.ENDMARKER:\r\n",
        "          adjusted_spelling = unified_tokenizer.quote_special(\r\n",
        "              unified_tokenizer.TokenKind.EOS.name)\r\n",
        "\r\n",
        "        # Map everything according to table.\r\n",
        "        try:\r\n",
        "          token_kind = PythonTokenizer2._TOKEN_TYPE_MAP[kind]\r\n",
        "        except KeyError as ke:\r\n",
        "          # It's possible we're here because of async/await. Those kept being\r\n",
        "          # turned into keywords and then removed from keywords, so we can't\r\n",
        "          # rely on knowing which they are. We'll check by spelling.\r\n",
        "          # See: https://bugs.python.org/issue30406\r\n",
        "          # and https://bugs.python.org/issue33260\r\n",
        "          # and https://bugs.python.org/issue35975\r\n",
        "          if spelling in ('async', 'await'):\r\n",
        "            token_kind = unified_tokenizer.TokenKind.KEYWORD\r\n",
        "          else:\r\n",
        "            raise ValueError('While trying to turn Python token %r into an '\r\n",
        "                             'agnostic one, raised %r.' %\r\n",
        "                             ((spelling, kind), ke))\r\n",
        "\r\n",
        "      start_line, start_column = token_tuple.start\r\n",
        "      end_line, end_column = token_tuple.end\r\n",
        "      # Unlike other languages, NEWLINE tokens are reported as ending on the\r\n",
        "      # same line as where they started. We adjust that here, to stick to the\r\n",
        "      # same convention as other tokenizers.\r\n",
        "      if ((token_kind == unified_tokenizer.TokenKind.NEWLINE) or\r\n",
        "          (kind == tokenize.NL)):\r\n",
        "        end_line = start_line + 1\r\n",
        "        end_column = 0\r\n",
        "\r\n",
        "      agnostic_tokens.append(\r\n",
        "          unified_tokenizer.AbstractToken(\r\n",
        "              spelling=adjusted_spelling, kind=token_kind,\r\n",
        "              metadata=unified_tokenizer.TokenMetadata(\r\n",
        "                  # Python's tokenizer counts lines starting from 1, so we\r\n",
        "                  # have to offset what we read from the `TokenInfo` tuple.\r\n",
        "                  start=unified_tokenizer.Position(\r\n",
        "                      line=start_line - 1, column=start_column),\r\n",
        "                  end=unified_tokenizer.Position(\r\n",
        "                      line=end_line - 1, column=end_column))))\r\n",
        "    #print(agnostic_tokens)\r\n",
        "    return agnostic_tokens\r\n",
        "\r\n",
        "  def untokenize_abstract(self, whole_tokens):\r\n",
        "    # Reconstruct Python tokenizer tuples, so that Python's untokenize can be\r\n",
        "    # invoked.\r\n",
        "    token_tuples: List[Tuple[int, str]] = []\r\n",
        "\r\n",
        "    for whole_token in whole_tokens:\r\n",
        "      if whole_token in PythonTokenizer2._EXACT_TOKEN_TYPES:\r\n",
        "        token_tuples.append((tokenize.OP, whole_token))\r\n",
        "      elif cubert_tokenizer.token_from_token_type(\r\n",
        "          tokenize.INDENT) in whole_token:\r\n",
        "        # We baked the type and spelling into one token. Break them up.\r\n",
        "        spelling = whole_token.replace(\r\n",
        "            cubert_tokenizer.token_from_token_type(tokenize.INDENT), '')\r\n",
        "        token_tuples.append((tokenize.INDENT, spelling))\r\n",
        "      elif whole_token in PythonTokenizer2._REVERSE_TOKEN_MAP:\r\n",
        "        python_kind = PythonTokenizer2._REVERSE_TOKEN_MAP[whole_token]\r\n",
        "        if python_kind in (tokenize.DEDENT, tokenize.ENDMARKER,\r\n",
        "                           tokenize.ERRORTOKEN):\r\n",
        "          spelling = ''\r\n",
        "        else:  # python_kind in (tokenize.NEWLINE, tokenize.NL)\r\n",
        "          spelling = '\\n'\r\n",
        "        token_tuples.append((python_kind, spelling))\r\n",
        "      elif keyword.iskeyword(whole_token):\r\n",
        "        token_tuples.append((tokenize.NAME, whole_token))\r\n",
        "      elif PythonTokenizer2._NUMBERS.match(whole_token):\r\n",
        "        token_tuples.append((tokenize.NUMBER, whole_token))\r\n",
        "      elif PythonTokenizer2._SINGLE_STRINGS.match(whole_token):\r\n",
        "        token_tuples.append((tokenize.STRING, whole_token))\r\n",
        "      elif PythonTokenizer2._TRIPLE_STRING_BEGINNINGS.match(whole_token):\r\n",
        "        token_tuples.append((tokenize.STRING, whole_token))\r\n",
        "      elif PythonTokenizer2._COMMENTS.match(whole_token):\r\n",
        "        token_tuples.append((tokenize.COMMENT, whole_token))\r\n",
        "      else:\r\n",
        "        # Everything else we map back to NAME.\r\n",
        "        token_tuples.append((tokenize.NAME, whole_token))\r\n",
        "\r\n",
        "    reconstructed = tokenize.untokenize(typing.cast(Any, token_tuples))\r\n",
        "    return reconstructed\r\n",
        "\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOS_mSj8hIOK"
      },
      "source": [
        "def get_lang_specific_tokens(init_tokenizer, code_snip):\r\n",
        "    #tokens_complete = init_tokenizer.tokenize(source_code=code_snip)\r\n",
        "    tokens = init_tokenizer.tokenize_and_abstract(source_code=code_snip )\r\n",
        "    conditioned = init_tokenizer.condition_full_tokens(tokens)\r\n",
        "    agnostic_token_lists = unified_tokenizer._agnostic_tokens_to_lists_of_token_lists(conditioned)\r\n",
        "    with_identifiers_heuristically_split = unified_tokenizer._subtokenize_identifiers_heuristically(\r\n",
        "        agnostic_token_lists)\r\n",
        "    with_string_tokens_heuristically_split = unified_tokenizer._subtokenize_strings_heuristically(\r\n",
        "        with_identifiers_heuristically_split)\r\n",
        "    shortened_subtokens = unified_tokenizer._shorten_subtokens(with_string_tokens_heuristically_split, 20)\r\n",
        "    sanitization_mapping = init_tokenizer.get_mappings()\r\n",
        "    subtoken_lists = unified_tokenizer.sanitize_subtoken_lists(shortened_subtokens,\r\n",
        "                                            sanitization_mapping,\r\n",
        "                                            unified_tokenizer.SENTINEL)\r\n",
        "    #flat_toks =unified_tokenizer.flatten_subtoken_lists(subtoken_lists)\r\n",
        "    test_spellings = []\r\n",
        "    test_tok_types = []\r\n",
        "    for t in subtoken_lists:\r\n",
        "        #if(len(t.spelling) == 1):\r\n",
        "        #print(len(t.spellings))\r\n",
        "        test_spellings.extend(t.spellings)\r\n",
        "        match=False\r\n",
        "        for cubert_token in set(init_tokenizer._REVERSE_TOKEN_MAP.keys()):\r\n",
        "            #print(\"Checking for:\",cubert_token)\r\n",
        "            if cubert_token in t.spellings[0]:\r\n",
        "                #print(t.spellings)\r\n",
        "                selected_token = tokenize.tok_name[init_tokenizer._REVERSE_TOKEN_MAP[cubert_token]]\r\n",
        "                test_tok_types.extend([selected_token]*len(t.spellings))\r\n",
        "                match=True          \r\n",
        "        if match == False:\r\n",
        "            test_tok_types.extend([t.kind.name]*len(t.spellings))\r\n",
        "    return test_spellings, test_tok_types\r\n",
        "\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h03QcbEIhLeg"
      },
      "source": [
        "class NewVectorizer():\r\n",
        "    def __init__(self, code_piece, tok_type_counter):\r\n",
        "        self.code_piece = code_piece\r\n",
        "        self.tok_type_counter = tok_type_counter\r\n",
        "        self.code_word2idx = {'<s>':0,'</s>':1,'<pad>':2, '<unk>':3}\r\n",
        "        self.code_idx2word = {v:k for k,v in self.code_word2idx.items()}\r\n",
        "        self.toktype_word2idx = {'<s>':0,'</s>':1,'<pad>':2, '<unk>':3}\r\n",
        "        self.toktype_idx2word = {v:k for k,v in self.toktype_word2idx.items()}\r\n",
        "        self.max_tok_length = len(self.toktype_word2idx)\r\n",
        "        self.max_code_length = len(self.code_word2idx)\r\n",
        "        self.UNK_FOR_TOKEN_TYPE = '<unk>'\r\n",
        "        self.UNK_FOR_CODEPIECE = '<unk>'\r\n",
        "        self.ID_UNK_TOKEN_TYPE = self.toktype_word2idx[self.UNK_FOR_TOKEN_TYPE]\r\n",
        "        self.ID_UNK_CODEPIECE = self.code_word2idx[self.UNK_FOR_CODEPIECE]\r\n",
        "\r\n",
        "        self.PAD_FOR_CODEPIECE = '<pad>'\r\n",
        "        self.PAD_FOR_TOKEN_TYPE = '<pad>'\r\n",
        "        self.ID_PAD_FOR_CODEPIECE = self.code_word2idx['<pad>']\r\n",
        "        self.ID_PAD_FOR_TOKEN_TYPE = self.toktype_word2idx['<pad>']\r\n",
        "        \r\n",
        "        self.SOS_FOR_CODEPIECE = '<s>'\r\n",
        "        self.SOS_FOR_TOKEN_TYPE = '<s>'\r\n",
        "        self.ID_SOS_FOR_CODEPIECE = self.code_word2idx['<s>']\r\n",
        "        self.ID_SOS_FOR_TOKEN_TYPE = self.toktype_word2idx['<s>']\r\n",
        "\r\n",
        "        self.EOS_FOR_CODEPIECE = '</s>'\r\n",
        "        self.EOS_FOR_TOKEN_TYPE = '</s>'\r\n",
        "        self.ID_EOS_FOR_CODEPIECE = self.code_word2idx['</s>']\r\n",
        "        self.ID_EOS_FOR_TOKEN_TYPE = self.toktype_word2idx['</s>']\r\n",
        "        self.build_vocab()\r\n",
        "\r\n",
        "    def build_vocab(self):\r\n",
        "        idx=len(self.code_word2idx.keys())\r\n",
        "        for k in self.code_piece.keys():\r\n",
        "            self.code_word2idx[k]=idx\r\n",
        "            self.code_idx2word[idx]=k\r\n",
        "            idx += 1\r\n",
        "        \r\n",
        "        idx=len(self.toktype_word2idx.keys())\r\n",
        "        for k in self.tok_type_counter.keys():\r\n",
        "            self.toktype_word2idx[k]=idx\r\n",
        "            self.toktype_idx2word[idx]=k\r\n",
        "            idx += 1\r\n",
        "\r\n",
        "        self.max_tok_length = len(self.toktype_word2idx.keys())\r\n",
        "        self.max_code_length = len(self.code_word2idx.keys())\r\n",
        "    ### Returns the code piece for a given ID\r\n",
        "    def convert_id_to_codepiece(self, id_for_code):\r\n",
        "        if(id_for_code not in list(self.code_idx2word.keys())):\r\n",
        "            return self.UNK_FOR_CODEPIECE\r\n",
        "        return self.code_idx2word[id_for_code]\r\n",
        "    ### Returns the ID for a given code piece\r\n",
        "    def convert_codepiece_to_id(self, code_piece):\r\n",
        "        if(code_piece not in list(self.code_word2idx.keys())):\r\n",
        "            return self.ID_UNK_CODEPIECE\r\n",
        "        return self.code_word2idx[code_piece]\r\n",
        "    ### Returns the TOKEN ID for a given TOKEN type\r\n",
        "    def convert_toktype_to_id(self, tok_piece):\r\n",
        "        if(tok_piece not in list(self.toktype_word2idx.keys())):\r\n",
        "            print(\"No match for\",tok_piece)\r\n",
        "            return self.ID_UNK_TOKEN_TYPE\r\n",
        "        return self.toktype_word2idx[tok_piece]\r\n",
        "    ### Returns the TOKEN type for a given TOKEN ID\r\n",
        "    def convert_id_to_toktype(self, id_for_toktype):\r\n",
        "        if(id_for_toktype not in list(self.toktype_idx2word.keys())):\r\n",
        "            return self.UNK_FOR_TOKEN_TYPE\r\n",
        "        return self.toktype_idx2word[id_for_toktype]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYzMGFIngltr"
      },
      "source": [
        "import cubert\r\n",
        "from absl import app\r\n",
        "from absl import flags\r\n",
        "from tensor2tensor.data_generators import text_encoder\r\n",
        "import enum\r\n",
        "import cubert_tokenizer\r\n",
        "from cubert import code_to_subtokenized_sentences\r\n",
        "#from cubert import tokenizer_registry\r\n",
        "from cubert import python_tokenizer\r\n",
        "import python_tokenizer\r\n",
        "from tensor2tensor.data_generators import text_encoder_build_subword\r\n",
        "from collections import Counter, defaultdict\r\n",
        "\r\n",
        "@enum.unique\r\n",
        "class TokenizerEnum(enum.Enum):\r\n",
        "  \"\"\"Enum for Tokenizers.\"\"\"\r\n",
        "  #PYTHON = python_tokenizer.PythonTokenizer\r\n",
        "  PYTHON = PythonTokenizer2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7auIaOthNj6"
      },
      "source": [
        "#### Generate and create the Vectorizer instance\r\n",
        "word_counter=Counter()\r\n",
        "init_tokenizer=PythonTokenizer2()\r\n",
        "tok_type_counter = Counter()\r\n",
        "for code_snip in nl_to_pl_df['cleaned_code']:\r\n",
        "    toks, tok_types = get_lang_specific_tokens(init_tokenizer, code_snip)\r\n",
        "    word_counter.update(Counter(toks))\r\n",
        "    tok_type_counter.update(Counter(tok_types))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-QqlOuhd3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f1e7d7-7b58-4f6d-fc46-cc58edd61895"
      },
      "source": [
        "code_tok_vectorizer = NewVectorizer(word_counter, tok_type_counter)\r\n",
        "print(code_tok_vectorizer.max_code_length,code_tok_vectorizer.max_tok_length)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5813 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1HaJbq6BwtV"
      },
      "source": [
        "tok_type_ids = [ code_tok_vectorizer.convert_toktype_to_id(toktype) for toktype in tok_types]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfjy6DJUCCp_",
        "outputId": "56d834e2-8aa8-4556-d214-3a551618a1a4"
      },
      "source": [
        "[ code_tok_vectorizer.convert_id_to_toktype(toktype) for toktype in tok_type_ids] == tok_types"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5epf-rxhjY0"
      },
      "source": [
        "### Old NLP DS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46GU0OzfGeE"
      },
      "source": [
        "tok_ids_list=[]\r\n",
        "class NLPLSingleEntry(object):\r\n",
        "    \"\"\"A single set of features of data.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, \r\n",
        "                 code_ids, \r\n",
        "                 code_mask, \r\n",
        "                 doc_ids,\r\n",
        "                 doc_mask,\r\n",
        "                 ):\r\n",
        "        self.code_ids = code_ids\r\n",
        "        self.code_mask = code_mask\r\n",
        "        self.doc_ids = doc_ids\r\n",
        "        self.doc_mask = doc_mask\r\n",
        "        #self.segment_ids = segment_ids\r\n",
        "        #self.label_id = label_id\r\n",
        "class NLPLDataSet():\r\n",
        "    def __init__(self, \r\n",
        "                 doc_tokenizer, \r\n",
        "                 code_tokenizer):\r\n",
        "        self.doc_tokenizer = doc_tokenizer\r\n",
        "        self.code_tokenizer = code_tokenizer\r\n",
        "\r\n",
        "    def prepare_tokens(self, \r\n",
        "                       samples, \r\n",
        "                       tokenizer, \r\n",
        "                       max_seq_length=0,\r\n",
        "                       data_type=None):\r\n",
        "        \"\"\"\r\n",
        "            Tokenizes an input sequence, adds padding and SOS+EOS \r\n",
        "        \"\"\"\r\n",
        "        toks = tokenizer.tokenize(samples)\r\n",
        "        # print(data_type)\r\n",
        "        # print(toks)\r\n",
        "        if max_seq_length > 2 and len(toks) > max_seq_length - 2:\r\n",
        "            toks = toks[:max_seq_length -2]\r\n",
        "        tok_ids =  tokenizer.convert_tokens_to_ids(toks)\r\n",
        "        ### We use pseudo-BERT process so we will add both CLS and SEP tokens for\r\n",
        "        ### src and target inputs\r\n",
        "        tok_ids = [tokenizer.cls_token_id] + tok_ids + [tokenizer.sep_token_id]\r\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n",
        "        # tokens are attended to.\r\n",
        "        input_mask = [ 1 ] * len(tok_ids)\r\n",
        "\r\n",
        "        if len(tok_ids) < max_seq_length:\r\n",
        "            padding_length = max_seq_length - len(tok_ids)\r\n",
        "            tok_ids = tok_ids + ([tokenizer.pad_token_id] * padding_length)\r\n",
        "            input_mask = input_mask + ([ 0 ] * padding_length) ### Padded tokens are zero-masked\r\n",
        "        \r\n",
        "        # print(tok_ids)\r\n",
        "        return tok_ids, input_mask\r\n",
        "\r\n",
        "    def create_dataset(self,\r\n",
        "                    nl_to_pl_df,\r\n",
        "                    final_ds,\r\n",
        "                    sample_count=10000,\r\n",
        "                    max_doc_len=50,\r\n",
        "                    max_code_len=0):\r\n",
        "        \"\"\"\r\n",
        "            Reads from a dataframe, tokenizes and numericalizes both docstrings \r\n",
        "            and code. \r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        #final_ds = []\r\n",
        "        for idx in nl_to_pl_df.itertuples():\r\n",
        "            ## For SOS and EOS tokens 2 positions are left\r\n",
        "            if not idx.cleaned_code:\r\n",
        "                print(\"Invalid entry, No code found for:\", idx.docstring)\r\n",
        "            \r\n",
        "            doc_toks, doc_mask = self.prepare_tokens(idx.docstring,\r\n",
        "                                                      self.doc_tokenizer,\r\n",
        "                                                      max_doc_len,\r\n",
        "                                                      \"docs\")\r\n",
        "            code_toks, code_mask = self.prepare_tokens(idx.cleaned_code,\r\n",
        "                                                      self.code_tokenizer,\r\n",
        "                                                      max_code_len,\r\n",
        "                                                      \"code\")\r\n",
        "            #code_toks = None\r\n",
        "            ### Skip over current iteration if no valid code found\r\n",
        "\r\n",
        "            # print(code_toks)\r\n",
        "            # print(code_mask)\r\n",
        "            # print(doc_toks)\r\n",
        "            # print(doc_mask)\r\n",
        "            final_entry = NLPLSingleEntry(code_toks, \r\n",
        "                                            code_mask, \r\n",
        "                                            doc_toks, \r\n",
        "                                            doc_mask)\r\n",
        "            # print(final_entry.code_ids)\r\n",
        "            # print(final_entry.code_mask)\r\n",
        "            # print(final_entry.doc_ids)\r\n",
        "            # print(final_entry.doc_mask)\r\n",
        "            final_ds.append(final_entry)\r\n",
        "        #print(len(final_ds))\r\n",
        "        return final_ds\r\n",
        "        "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTR0cQhHhmWC"
      },
      "source": [
        "### New NLP DS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVD-3TjxY1SD"
      },
      "source": [
        "tok_ids_list=[]\r\n",
        "class NLPLSingleEntry(object):\r\n",
        "    \"\"\"A single set of features of data.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, \r\n",
        "                 code_ids,\r\n",
        "                 tok_ids,\r\n",
        "                 code_mask, \r\n",
        "                 doc_ids,\r\n",
        "                 doc_mask,\r\n",
        "                 ):\r\n",
        "        self.code_ids = code_ids\r\n",
        "        self.code_mask = code_mask\r\n",
        "        self.tok_ids = tok_ids\r\n",
        "        self.doc_ids = doc_ids\r\n",
        "        self.doc_mask = doc_mask\r\n",
        "        #self.segment_ids = segment_ids\r\n",
        "        #self.label_id = label_id\r\n",
        "class NLPLDataSet():\r\n",
        "    def __init__(self, \r\n",
        "                 doc_tokenizer, \r\n",
        "                 code_tokenizer,\r\n",
        "                 code_tok_vectorizer):\r\n",
        "        self.doc_tokenizer = doc_tokenizer\r\n",
        "        self.code_tokenizer = code_tokenizer\r\n",
        "        self.code_tok_vectorizer = code_tok_vectorizer\r\n",
        "\r\n",
        "    def prepare_tokens(self, \r\n",
        "                       samples, \r\n",
        "                       tokenizer, \r\n",
        "                       max_seq_length=0,\r\n",
        "                       data_type=None):\r\n",
        "        \"\"\"\r\n",
        "            Tokenizes an input sequence, adds padding and SOS+EOS \r\n",
        "        \"\"\"\r\n",
        "        toks = tokenizer.tokenize(samples)\r\n",
        "        # print(data_type)\r\n",
        "        # print(toks)\r\n",
        "        if max_seq_length > 2 and len(toks) > max_seq_length - 2:\r\n",
        "            toks = toks[:max_seq_length -2]\r\n",
        "        tok_ids =  tokenizer.convert_tokens_to_ids(toks)\r\n",
        "        ### We use pseudo-BERT process so we will add both CLS and SEP tokens for\r\n",
        "        ### src and target inputs\r\n",
        "        tok_ids = [tokenizer.cls_token_id] + tok_ids + [tokenizer.sep_token_id]\r\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n",
        "        # tokens are attended to.\r\n",
        "        input_mask = [ 1 ] * len(tok_ids)\r\n",
        "\r\n",
        "        if len(tok_ids) < max_seq_length:\r\n",
        "            padding_length = max_seq_length - len(tok_ids)\r\n",
        "            tok_ids = tok_ids + ([tokenizer.pad_token_id] * padding_length)\r\n",
        "            input_mask = input_mask + ([ 0 ] * padding_length) ### Padded tokens are zero-masked\r\n",
        "        \r\n",
        "        # print(tok_ids)\r\n",
        "        return tok_ids, input_mask\r\n",
        "    def prepare_code_tokens(self, \r\n",
        "                       samples, \r\n",
        "                       tokenizer, \r\n",
        "                       max_seq_length=0,\r\n",
        "                       data_type=None):\r\n",
        "        \"\"\"\r\n",
        "            Tokenizes an input sequence, adds padding and SOS+EOS \r\n",
        "        \"\"\"\r\n",
        "        _toks, _tok_types = get_lang_specific_tokens(self.code_tokenizer, samples)\r\n",
        "        #print(_tok_types)\r\n",
        "        # print(data_type)\r\n",
        "        # print(toks)\r\n",
        "        if max_seq_length > 2 and len(_toks) > max_seq_length - 2:\r\n",
        "            _toks = _toks[:max_seq_length -2]\r\n",
        "            _tok_types = _tok_types[:max_seq_length -2]\r\n",
        "        #tok_ids =  tokenizer.convert_tokens_to_ids(toks)\r\n",
        "        tok_ids = [ self.code_tok_vectorizer.convert_codepiece_to_id(code) for code in _toks]\r\n",
        "        tok_types = [ self.code_tok_vectorizer.convert_toktype_to_id(toktype) for toktype in _tok_types]\r\n",
        "        \r\n",
        "        ### We use pseudo-BERT process so we will add both CLS and SEP tokens for\r\n",
        "        ### src and target inputs\r\n",
        "        tok_ids = [self.code_tok_vectorizer.ID_SOS_FOR_CODEPIECE] + tok_ids + [self.code_tok_vectorizer.ID_EOS_FOR_CODEPIECE]\r\n",
        "        tok_types = [self.code_tok_vectorizer.ID_SOS_FOR_TOKEN_TYPE] + tok_types + [self.code_tok_vectorizer.ID_EOS_FOR_TOKEN_TYPE]\r\n",
        "        #print(len(tok_ids), len(tok_types))\r\n",
        "        assert(len(tok_ids) == len(tok_types))\r\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n",
        "        # tokens are attended to.\r\n",
        "        input_mask = [ 1 ] * len(tok_ids)\r\n",
        "\r\n",
        "        if len(tok_ids) < max_seq_length:\r\n",
        "            padding_length = max_seq_length - len(tok_ids)\r\n",
        "            tok_ids = tok_ids + ([self.code_tok_vectorizer.ID_PAD_FOR_CODEPIECE] * padding_length)\r\n",
        "            tok_types = tok_types + ([self.code_tok_vectorizer.ID_PAD_FOR_TOKEN_TYPE] * padding_length)\r\n",
        "            input_mask = input_mask + ([ 0 ] * padding_length) ### Padded tokens are zero-masked\r\n",
        "        \r\n",
        "        # print(tok_ids)\r\n",
        "        return tok_ids, tok_types, input_mask\r\n",
        "\r\n",
        "    def create_dataset(self,\r\n",
        "                    nl_to_pl_df,\r\n",
        "                    final_ds,\r\n",
        "                    sample_count=10000,\r\n",
        "                    max_doc_len=50,\r\n",
        "                    max_code_len=0):\r\n",
        "        \"\"\"\r\n",
        "            Reads from a dataframe, tokenizes and numericalizes both docstrings \r\n",
        "            and code. \r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        #final_ds = []\r\n",
        "        for idx in nl_to_pl_df.itertuples():\r\n",
        "            ## For SOS and EOS tokens 2 positions are left\r\n",
        "            if not idx.cleaned_code:\r\n",
        "                print(\"Invalid entry, No code found for:\", idx.docstring)\r\n",
        "            \r\n",
        "            doc_toks, doc_mask = self.prepare_tokens(idx.docstring,\r\n",
        "                                                      self.doc_tokenizer,\r\n",
        "                                                      max_doc_len,\r\n",
        "                                                      \"docs\")\r\n",
        "            code_ids, tok_ids, code_mask = self.prepare_code_tokens(idx.cleaned_code,\r\n",
        "                                                      self.code_tokenizer,\r\n",
        "                                                      max_code_len,\r\n",
        "                                                      \"code\")\r\n",
        "            #code_toks = None\r\n",
        "            ### Skip over current iteration if no valid code found\r\n",
        "\r\n",
        "            # print(code_toks)\r\n",
        "            # print(code_mask)\r\n",
        "            # print(doc_toks)\r\n",
        "            # print(doc_mask)\r\n",
        "            final_entry = NLPLSingleEntry(code_ids,\r\n",
        "                                          tok_ids,\r\n",
        "                                          code_mask, \r\n",
        "                                          doc_toks, \r\n",
        "                                          doc_mask)\r\n",
        "            # print(final_entry.code_ids)\r\n",
        "            # print(final_entry.code_mask)\r\n",
        "            # print(final_entry.doc_ids)\r\n",
        "            # print(final_entry.doc_mask)\r\n",
        "            final_ds.append(final_entry)\r\n",
        "        #print(len(final_ds))\r\n",
        "        return final_ds\r\n",
        "        "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V71S9kbEyhv8"
      },
      "source": [
        "### We will use the same tokenizer for both docstrings and code\r\n",
        "final_ds = []\r\n",
        "MAX_LENGTH=512\r\n",
        "#selected_elems = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= MAX_LENGTH]\r\n",
        "#selected_elems = my_df_copy[my_df_copy['code_len'] <= MAX_LENGTH]\r\n",
        "MAX_VOCAB_LENGTH=256\r\n",
        "assert(MAX_VOCAB_LENGTH <= MAX_LENGTH)\r\n",
        "#selected_elems = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= MAX_LENGTH]\r\n",
        "#selected_elems = my_df_copy[my_df_copy['code_len'] <= MAX_LENGTH]\r\n",
        "init_tokenizer=PythonTokenizer2()\r\n",
        "#selected_elems = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= MAX_VOCAB_LENGTH]\r\n",
        "\r\n",
        "selected_elems = nl_to_pl_df[(nl_to_pl_df['cleaned_code_len'] <= MAX_VOCAB_LENGTH) & (nl_to_pl_df['docstring_len'] <= MAX_VOCAB_LENGTH*2)]\r\n",
        "my_nlpl_ds = NLPLDataSet(auto_tokenizer, init_tokenizer, code_tok_vectorizer).create_dataset(selected_elems, \r\n",
        "                                                                        final_ds, \r\n",
        "                                                                        max_doc_len=MAX_VOCAB_LENGTH, \r\n",
        "                                                                        max_code_len=MAX_VOCAB_LENGTH)\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxroVGJDIGq1"
      },
      "source": [
        "selected_elems.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShA8ITXD9wfe"
      },
      "source": [
        "all_code_ids = torch.tensor([f.code_ids for f in my_nlpl_ds], dtype=torch.long)\r\n",
        "all_code_mask = torch.tensor([f.code_mask for f in my_nlpl_ds], dtype=torch.long)\r\n",
        "all_doc_ids = torch.tensor([f.doc_ids for f in my_nlpl_ds], dtype=torch.long)\r\n",
        "all_doc_mask = torch.tensor([f.doc_mask for f in my_nlpl_ds], dtype=torch.long)\r\n",
        "all_tok_ids = torch.tensor([f.tok_ids for f in my_nlpl_ds], dtype=torch.long)\r\n",
        "# if output_mode == \"classification\":\r\n",
        "#     all_label_ids = torch.tensor([f.label_id for f in my_nlpl_ds], dtype=torch.long)\r\n",
        "\r\n",
        "train_dataset = TensorDataset(all_code_ids,\r\n",
        "                              all_code_mask, \r\n",
        "                              all_doc_ids, \r\n",
        "                              all_doc_mask,\r\n",
        "                              all_tok_ids)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKJG-nAJl3i9"
      },
      "source": [
        "dataset_size = len(train_dataset)\r\n",
        "dataset_indices = list(range(dataset_size))\r\n",
        "np.random.shuffle(dataset_indices)\r\n",
        "val_split_index = int(np.floor(0.2 * dataset_size))\r\n",
        "\r\n",
        "train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRIIkyMl4fY"
      },
      "source": [
        "BATCH_SIZE=8\r\n",
        "train_sampler = SubsetRandomSampler(train_idx)\r\n",
        "val_sampler = SubsetRandomSampler(val_idx)\r\n",
        "\r\n",
        "\r\n",
        "#train_sampler = RandomSampler(train_dataset,) #if args.local_rank == -1 else DistributedSampler(train_dataset)\r\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE, shuffle=False)\r\n",
        "val_dataloader = DataLoader(train_dataset, sampler=val_sampler, batch_size=BATCH_SIZE, shuffle=False)\r\n",
        "\r\n",
        "#train_sampler = RandomSampler(train_dataset) #if args.local_rank == -1 else DistributedSampler(train_dataset)\r\n",
        "\r\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSmbw44v__OU"
      },
      "source": [
        "iter_one = next(iter(train_dataloader))\r\n",
        "iter_one_val = next(iter(val_dataloader))\r\n",
        "\r\n",
        "#iter_one[0]=all_code_ids, \r\n",
        "#iter_one[1]=all_code_mask, \r\n",
        "#iter_one[2]=all_doc_ids, \r\n",
        "#iter_one[3]=all_doc_mask\r\n",
        "#mask_reshape.shape\r\n",
        "# trg = iter_one[0]\r\n",
        "# trg_len = trg.shape[1]\r\n",
        "# trg_pad_mask = iter_one[1].unsqueeze(1).unsqueeze(2) \r\n",
        "# trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len))).bool()\r\n",
        "\r\n",
        "# #trg_sub_mask = [trg len, trg len]\r\n",
        "    \r\n",
        "# trg_mask = trg_pad_mask & trg_sub_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbgAhdfWAIOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3da7f01-62d5-4c64-defd-a1b6d84711a6"
      },
      "source": [
        "iter_one[-1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scH0xbQHKvS3"
      },
      "source": [
        "### Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2wiHHFBuXxi"
      },
      "source": [
        "class TransEncoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 input_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,\r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 1000):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([TransEncoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim,\r\n",
        "                                                  dropout, \r\n",
        "                                                  device) \r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        batch_size = src.shape[0]\r\n",
        "        src_len = src.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "        \r\n",
        "        #pos = [batch size, src len]\r\n",
        "        \r\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            src = layer(src, src_mask)\r\n",
        "            \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "            \r\n",
        "        return src"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_PH9wz_KzuM"
      },
      "source": [
        "class TransEncoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,  \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        #src_mask = [batch size, 1, 1, src len] \r\n",
        "                \r\n",
        "        #self attention\r\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _src = self.positionwise_feedforward(src)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        return src"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodBNJ46LCQo"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert hid_dim % n_heads == 0\r\n",
        "        \r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_heads = n_heads\r\n",
        "        self.head_dim = hid_dim // n_heads\r\n",
        "        \r\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, query, key, value, mask = None):\r\n",
        "        \r\n",
        "        batch_size = query.shape[0]\r\n",
        "        \r\n",
        "        #query = [batch size, query len, hid dim]\r\n",
        "        #key = [batch size, key len, hid dim]\r\n",
        "        #value = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = self.fc_q(query)\r\n",
        "        K = self.fc_k(key)\r\n",
        "        V = self.fc_v(value)\r\n",
        "        \r\n",
        "        #Q = [batch size, query len, hid dim]\r\n",
        "        #K = [batch size, key len, hid dim]\r\n",
        "        #V = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        \r\n",
        "        #Q = [batch size, n heads, query len, head dim]\r\n",
        "        #K = [batch size, n heads, key len, head dim]\r\n",
        "        #V = [batch size, n heads, value len, head dim]\r\n",
        "                \r\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\r\n",
        "        \r\n",
        "        #energy = [batch size, n heads, query len, key len]\r\n",
        "        \r\n",
        "        if mask is not None:\r\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\r\n",
        "        \r\n",
        "        attention = torch.softmax(energy, dim = -1)\r\n",
        "                \r\n",
        "        #attention = [batch size, n heads, query len, key len]\r\n",
        "                \r\n",
        "        x = torch.matmul(self.dropout(attention), V)\r\n",
        "        \r\n",
        "        #x = [batch size, n heads, query len, head dim]\r\n",
        "        \r\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\r\n",
        "        \r\n",
        "        #x = [batch size, query len, n heads, head dim]\r\n",
        "        \r\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        x = self.fc_o(x)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        return x, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK2KNXZSLEAz"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\r\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, pf dim]\r\n",
        "        \r\n",
        "        x = self.fc_2(x)\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH18KwEnLFhF"
      },
      "source": [
        "class TransDecoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 output_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 1000,\r\n",
        "                 tok_type_dim=62):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\r\n",
        "        self.tok_type_embedding = nn.Embedding(tok_type_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([TransDecoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim, \r\n",
        "                                                  dropout, \r\n",
        "                                                  device)\r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
        "        \r\n",
        "        self.fc_out_tok = nn.Linear(hid_dim, tok_type_dim)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask, src_tok_types):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "                \r\n",
        "        batch_size = trg.shape[0]\r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "                            \r\n",
        "        #pos = [batch size, trg len]\r\n",
        "            \r\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + \r\n",
        "                           self.pos_embedding(pos) + \r\n",
        "                           self.tok_type_embedding(src_tok_types))\r\n",
        "                \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        output = self.fc_out(trg)\r\n",
        "        output_tok = self.fc_out_tok(trg)\r\n",
        "        #output =F.softmax(output, dim=2)  \r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "            \r\n",
        "        return output, output_tok, attention"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IChtMK8QLHOP"
      },
      "source": [
        "class TransDecoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        #self attention\r\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "            \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "            \r\n",
        "        #encoder attention\r\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\r\n",
        "        # query, key, value\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "                    \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _trg = self.positionwise_feedforward(trg)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return trg, attention"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swxv3Y0SLJmE"
      },
      "source": [
        "class TransSeq2Seq(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 encoder, \r\n",
        "                 decoder, \r\n",
        "                 src_pad_idx, \r\n",
        "                 trg_pad_idx, \r\n",
        "                 device,\r\n",
        "                 ):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.src_pad_idx = src_pad_idx\r\n",
        "        self.trg_pad_idx = trg_pad_idx\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def make_src_mask(self, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        \r\n",
        "        src_mask = src_mask.unsqueeze(1).unsqueeze(2)\r\n",
        "\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "\r\n",
        "        return src_mask\r\n",
        "    \r\n",
        "    def make_trg_mask(self, trg, trg_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        trg_pad_mask = trg_mask.unsqueeze(1).unsqueeze(2) \r\n",
        "        \"\"\"\r\n",
        "            A boolean tensor of shape [batch size, 1, 1, trg len]\r\n",
        "        \"\"\"\r\n",
        "        \r\n",
        "        \r\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
        "        \r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\r\n",
        "        \r\n",
        "        #trg_sub_mask = [trg len, trg len]\r\n",
        "            \r\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
        "        \r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        return trg_mask\r\n",
        "\r\n",
        "    def forward(self, src, src_mask, trg, trg_mask, src_tok_types):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "                \r\n",
        "        src_mask = self.make_src_mask(src_mask)\r\n",
        "        trg_mask = self.make_trg_mask(trg, trg_mask)\r\n",
        "        \r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        enc_src = self.encoder(src, src_mask)\r\n",
        "        \r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "                \r\n",
        "        output, tok_output, attention = self.decoder(trg, \r\n",
        "                                         enc_src, \r\n",
        "                                         trg_mask, \r\n",
        "                                         src_mask, \r\n",
        "                                         src_tok_types)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return output, tok_output, attention"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJUUj5QLvbw"
      },
      "source": [
        "INPUT_DIM = auto_tokenizer.vocab_size\r\n",
        "OUTPUT_DIM = code_tok_vectorizer.max_code_length\r\n",
        "TOK_TYPE_OUTPUT_DIM = code_tok_vectorizer.max_tok_length\r\n",
        "HID_DIM = 256\r\n",
        "ENC_LAYERS = 3\r\n",
        "DEC_LAYERS = 3\r\n",
        "ENC_HEADS = 8\r\n",
        "DEC_HEADS = 8\r\n",
        "ENC_PF_DIM = 1024\r\n",
        "DEC_PF_DIM = 1024\r\n",
        "ENC_DROPOUT = 0.2\r\n",
        "DEC_DROPOUT = 0.2\r\n",
        "\r\n",
        "enc = TransEncoder(INPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              ENC_LAYERS, \r\n",
        "              ENC_HEADS, \r\n",
        "              ENC_PF_DIM, \r\n",
        "              ENC_DROPOUT, \r\n",
        "              device,\r\n",
        "              max_length=MAX_LENGTH)\r\n",
        "\r\n",
        "dec = TransDecoder(OUTPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              DEC_LAYERS, \r\n",
        "              DEC_HEADS, \r\n",
        "              DEC_PF_DIM, \r\n",
        "              DEC_DROPOUT, \r\n",
        "              device,\r\n",
        "              max_length=MAX_LENGTH,\r\n",
        "              tok_type_dim=TOK_TYPE_OUTPUT_DIM)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzSK7caBygSu",
        "outputId": "a0c13313-277b-4320-cc7a-6d0f1cfc0e5f"
      },
      "source": [
        "code_tok_vectorizer.max_tok_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK3PYSb6gT12"
      },
      "source": [
        "# INPUT_DIM = auto_tokenizer.vocab_size\r\n",
        "# OUTPUT_DIM = auto_tokenizer.vocab_size\r\n",
        "# HID_DIM = 256\r\n",
        "# ENC_LAYERS = 3\r\n",
        "# DEC_LAYERS = 3\r\n",
        "# ENC_HEADS = 8\r\n",
        "# DEC_HEADS = 8\r\n",
        "# ENC_PF_DIM = 1024\r\n",
        "# DEC_PF_DIM = 1024\r\n",
        "# ENC_DROPOUT = 0.2\r\n",
        "# DEC_DROPOUT = 0.2\r\n",
        "\r\n",
        "# enc = TransEncoder(INPUT_DIM, \r\n",
        "#               HID_DIM, \r\n",
        "#               ENC_LAYERS, \r\n",
        "#               ENC_HEADS, \r\n",
        "#               ENC_PF_DIM, \r\n",
        "#               ENC_DROPOUT, \r\n",
        "#               device)\r\n",
        "\r\n",
        "# dec = TransDecoder(OUTPUT_DIM, \r\n",
        "#               HID_DIM, \r\n",
        "#               DEC_LAYERS, \r\n",
        "#               DEC_HEADS, \r\n",
        "#               DEC_PF_DIM, \r\n",
        "#               DEC_DROPOUT, \r\n",
        "#               device,\r\n",
        "#               max_length=MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mtBeOIl5uWg",
        "outputId": "4f072248-06a6-4469-b169-77afc99d49f5"
      },
      "source": [
        "MAX_LENGTH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7yKcgxLPKiv"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olwlAq_B3boJ"
      },
      "source": [
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_baseline_128.pt ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lexhxG9rL8pQ"
      },
      "source": [
        "SRC_PAD_IDX = auto_tokenizer.pad_token_id #SRC.vocab.stoi[SRC.pad_token]\r\n",
        "TRG_PAD_IDX = code_tok_vectorizer.ID_PAD_FOR_TOKEN_TYPE #TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "model = TransSeq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQy4DgdKzAsB"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw9b7bQ-MIWM"
      },
      "source": [
        "def initialize_weights(m):\r\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\r\n",
        "        nn.init.xavier_uniform_(m.weight.data)\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-yLC9A_Mmuo",
        "outputId": "e7bf7234-91d2-4d74-e2be-61f079de4643"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 21,649,861 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhrFXeouMQEb"
      },
      "source": [
        "model.apply(initialize_weights);\r\n",
        "LEARNING_RATE = 0.0005\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqHShEuoNQlw"
      },
      "source": [
        "iter_one = next(iter(train_dataloader))\r\n",
        "batch = tuple(t.to(device) for t in iter_one)\r\n",
        "# inputs = {'input_ids': batch[0],\r\n",
        "#             'attention_mask': batch[1],\r\n",
        "#             'token_type_ids': batch[2] ,\r\n",
        "#             # XLM don't use segment_ids\r\n",
        "#             'labels': batch[3]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cWIuwNUMQXs"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip, device,double_loss=False):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_crit_loss = 0\r\n",
        "    epoch_tok_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        trg = batch[0].to(device)\r\n",
        "        trg_mask = batch[1].to(device)\r\n",
        "        src = batch[2].to(device)\r\n",
        "        src_mask = batch[3].to(device)\r\n",
        "        src_tok_type = batch[4].to(device)\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output, tok_op, _ = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1], src_tok_type[:,:-1])\r\n",
        "                \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "        output = output.contiguous().view(-1, output_dim)\r\n",
        "        trg = trg[:,1:].contiguous().view(-1)\r\n",
        "                \r\n",
        "        #output = [batch size * trg len - 1, output dim]\r\n",
        "        #trg = [batch size * trg len - 1]\r\n",
        "        if(double_loss == True):            \r\n",
        "            tok_op_output_dim = tok_op.shape[-1]            \r\n",
        "            tok_op = tok_op.contiguous().view(-1, tok_op_output_dim)\r\n",
        "            src_tok_type = src_tok_type[:,1:].contiguous().view(-1)\r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]            \r\n",
        "            loss,crit_loss, tok_loss = criterion(output, \r\n",
        "                                                 trg,\r\n",
        "                                                 tok_op,\r\n",
        "                                                 src_tok_type)\r\n",
        "            epoch_crit_loss += crit_loss.item()\r\n",
        "            epoch_tok_loss += tok_loss.item()\r\n",
        "        else:\r\n",
        "            loss = criterion(output, trg)\r\n",
        "            \r\n",
        "        loss.backward()        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        optimizer.step()        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "    \r\n",
        "    if(double_loss == True):  \r\n",
        "        print(f'Train\\tCrit Loss: {epoch_crit_loss/(len(iterator)):.3f} | Token Loss: {epoch_tok_loss/(len(iterator)):.3f}')\r\n",
        "\r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26yD4gOnMr9U"
      },
      "source": [
        "def evaluate(model, iterator, criterion, device,double_loss=False):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_crit_loss = 0\r\n",
        "    epoch_tok_loss = 0\r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            trg = batch[0].to(device)\r\n",
        "            trg_mask = batch[1].to(device)\r\n",
        "            src = batch[2].to(device)\r\n",
        "            src_mask = batch[3].to(device)\r\n",
        "            src_tok_type = batch[4].to(device)\r\n",
        "\r\n",
        "            #output, _ = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1])\r\n",
        "            output, tok_op, _ = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1], src_tok_type[:,:-1])\r\n",
        "            \r\n",
        "            #output = [batch size, trg len - 1, output dim]\r\n",
        "            #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output.contiguous().view(-1, output_dim)\r\n",
        "            trg = trg[:,1:].contiguous().view(-1)\r\n",
        "            \r\n",
        "            if(double_loss == True):            \r\n",
        "                tok_op_output_dim = tok_op.shape[-1]            \r\n",
        "                tok_op = tok_op.contiguous().view(-1, tok_op_output_dim)\r\n",
        "                src_tok_type = src_tok_type[:,1:].contiguous().view(-1)\r\n",
        "                #output = [batch size * trg len - 1, output dim]\r\n",
        "                #trg = [batch size * trg len - 1]            \r\n",
        "                loss,crit_loss, tok_loss = criterion(output, \r\n",
        "                                                     trg,\r\n",
        "                                                     tok_op,\r\n",
        "                                                     src_tok_type)\r\n",
        "                epoch_crit_loss += crit_loss.item()\r\n",
        "                epoch_tok_loss += tok_loss.item()\r\n",
        "            else:\r\n",
        "                loss = criterion(output, trg)\r\n",
        "            \r\n",
        "\r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "            # loss = criterion(output, \r\n",
        "            #                  trg,\r\n",
        "            #                  tok_op,\r\n",
        "            #                  src_tok_type)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "\r\n",
        "    if(double_loss == True):  \r\n",
        "        print(f'Val\\tCrit Loss: {epoch_crit_loss/(len(iterator)):.3f} | Token Loss: {epoch_tok_loss/(len(iterator)):.3f}')  \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGz-LB82MvFT"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHcNK9jmPC7U"
      },
      "source": [
        "# my_torch_weights = torch.ones(auto_tokenizer.vocab_size)\r\n",
        "# my_torch_weights[1437] = 2\r\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX, weight=my_torch_weights.to(device) )\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\r\n",
        "\r\n",
        "class WeightedCrossEntropy(nn.Module):\r\n",
        "    def __init__(self,\r\n",
        "                 code_weights=None,\r\n",
        "                 code_ignore_idx=None,\r\n",
        "                 tok_type_weights=None,\r\n",
        "                 tok_type_ignore_idx=None,\r\n",
        "                 mix_ratio=0.5):\r\n",
        "        \r\n",
        "        super(WeightedCrossEntropy, self).__init__()\r\n",
        "        self.code_weights=code_weights\r\n",
        "        self.code_ignore_idx=code_ignore_idx\r\n",
        "        self.tok_type_weights=tok_type_weights\r\n",
        "        self.tok_type_ignore_idx=tok_type_ignore_idx\r\n",
        "        self.mix_ratio = mix_ratio\r\n",
        "    \r\n",
        "    def forward(self, \r\n",
        "                code_output, \r\n",
        "                code_trg,\r\n",
        "                tok_type_output,\r\n",
        "                tok_type_trg):\r\n",
        "        \r\n",
        "        # code_criterion = nn.CrossEntropyLoss(ignore_index = self.code_ignore_idx,\r\n",
        "        #                                      weight=self.code_weights)\r\n",
        "        # toktype_criterion = nn.CrossEntropyLoss(ignore_index = self.tok_type_ignore_idx,\r\n",
        "        #                                 weight=self.tok_type_weights)\r\n",
        "\r\n",
        "        code_criterion = F.cross_entropy(code_output, \r\n",
        "                                         code_trg, \r\n",
        "                                         weight=self.code_weights,\r\n",
        "                                         ignore_index = self.code_ignore_idx)\r\n",
        "        toktype_criterion = F.cross_entropy(tok_type_output, \r\n",
        "                                         tok_type_trg, \r\n",
        "                                         weight=self.tok_type_weights,\r\n",
        "                                         ignore_index = self.tok_type_ignore_idx)\r\n",
        "        \r\n",
        "        total_loss = self.mix_ratio * code_criterion + (1-self.mix_ratio )*toktype_criterion\r\n",
        "        return total_loss, code_criterion, toktype_criterion\r\n",
        "\r\n",
        "criterion = WeightedCrossEntropy(code_ignore_idx=TRG_PAD_IDX, \r\n",
        "                                 tok_type_ignore_idx=TRG_PAD_IDX,\r\n",
        "                                 mix_ratio=0.9999)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HwsjJd3PiGf",
        "outputId": "d88b06d3-8eda-44d2-bb81-14301f3f3895"
      },
      "source": [
        "batch = next(iter(train_dataloader))\r\n",
        "trg = batch[0].to(device)\r\n",
        "trg_mask = batch[1].to(device)\r\n",
        "src = batch[2].to(device)\r\n",
        "src_mask = batch[3].to(device)\r\n",
        "src_tok_types = batch[4].to(device)\r\n",
        "print(trg.shape, trg_mask.shape, src.shape, src_mask.shape, src_tok_types.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 256]) torch.Size([8, 256]) torch.Size([8, 256]) torch.Size([8, 256]) torch.Size([8, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaK3e2iMP66R"
      },
      "source": [
        "model.train()\r\n",
        "#with torch.no_grad():\r\n",
        "output,tok_op,attend_val = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1], src_tok_types[:,:-1])\r\n",
        "    # output_dim = output.shape[-1]\r\n",
        "    \r\n",
        "    # output = output.contiguous().view(-1, output_dim)\r\n",
        "    # trg = trg[:,1:].contiguous().view(-1)\r\n",
        "    \r\n",
        "    #output = [batch size * trg len - 1, output dim]\r\n",
        "    #trg = [batch size * trg len - 1]\r\n",
        "    \r\n",
        "    #loss = criterion(output, trg)\r\n",
        "    #print(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY5d6VwOTrKc"
      },
      "source": [
        "nl_pl_to_df = pd.read_csv('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNgUyTyZ_k0m",
        "outputId": "742d1e3a-0e7f-4cc3-d498-38b5972869f9"
      },
      "source": [
        "output.shape, tok_op.shape, attend_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 255, 5809]),\n",
              " torch.Size([8, 255, 62]),\n",
              " torch.Size([8, 8, 255, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxDsVPtGYvcd"
      },
      "source": [
        "output_dim = output.shape[-1]\r\n",
        "\r\n",
        "output = output.contiguous().view(-1, output_dim)\r\n",
        "trg = trg[:,1:].contiguous().view(-1)\r\n",
        "\r\n",
        "tok_output_dim = tok_op.shape[-1]\r\n",
        "tok_op = tok_op.contiguous().view(-1, tok_output_dim)\r\n",
        "src_tok_types = src_tok_types[:,1:].contiguous().view(-1)\r\n",
        "    \r\n",
        "#output = [batch size * trg len - 1, output dim]\r\n",
        "#trg = [batch size * trg len - 1]\r\n",
        "\r\n",
        "#loss = criterion(output, trg)\r\n",
        "#print(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKqoz_GQBkWE"
      },
      "source": [
        "output.shape, trg.shape, tok_op.shape, src_tok_types.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBG82-UVaCab"
      },
      "source": [
        "loss = criterion(output, trg, tok_op, src_tok_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBiqn6yYvgs7"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hrlBV-kAM4h"
      },
      "source": [
        "import time\r\n",
        "import math\r\n",
        "\r\n",
        "def run_train_eval_loop(model, \r\n",
        "                        train_dataloader,\r\n",
        "                        val_dataloader,\r\n",
        "                        optimizer,\r\n",
        "                        criterion,\r\n",
        "                        device,\r\n",
        "                        epochs=20,\r\n",
        "                        clip=1,\r\n",
        "                        best_valid_loss=float('inf'),\r\n",
        "                        file_path='end_capstone_baseline_128.pt',\r\n",
        "                        double_loss=False,\r\n",
        "                        scheduler=None,\r\n",
        "                        mix_ratio=0.5):\r\n",
        "    \r\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\r\n",
        "\r\n",
        "    if double_loss == True:    \r\n",
        "        criterion = WeightedCrossEntropy(code_ignore_idx=TRG_PAD_IDX, \r\n",
        "                                        tok_type_ignore_idx=TRG_PAD_IDX,\r\n",
        "                                        mix_ratio=mix_ratio)            \r\n",
        "    \r\n",
        "    for epoch in range(epochs):\r\n",
        "    \r\n",
        "        start_time = time.time()\r\n",
        "        \r\n",
        "        train_loss = train(model, train_dataloader, optimizer, criterion, clip, device,double_loss=double_loss)\r\n",
        "        valid_loss = evaluate(model, val_dataloader, criterion, device,double_loss=double_loss)\r\n",
        "        \r\n",
        "        if(scheduler is not None):\r\n",
        "            scheduler.step(valid_loss)\r\n",
        "        end_time = time.time()\r\n",
        "        \r\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "        \r\n",
        "        if valid_loss < best_valid_loss:\r\n",
        "            best_valid_loss = valid_loss\r\n",
        "            torch.save({\"model\":model.state_dict(),\r\n",
        "                \"optimizer\":optimizer.state_dict(),\r\n",
        "                \"loss\":valid_loss,\r\n",
        "                },file_path)\r\n",
        "        \r\n",
        "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE1Xa6EJwk2F"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\r\n",
        "    \r\n",
        "    assert n_rows * n_cols == n_heads\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(15,25))\r\n",
        "    \r\n",
        "    for i in range(n_heads):\r\n",
        "        \r\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\r\n",
        "        \r\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\r\n",
        "\r\n",
        "        cax = ax.matshow(_attention, cmap='bone')\r\n",
        "\r\n",
        "        ax.tick_params(labelsize=12)\r\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                           rotation=45)\r\n",
        "        ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiwj5jwOA_Lf"
      },
      "source": [
        "file_path='end_capstone_self_encode_sizeCor_seq512.pt'\r\n",
        "LEARNING_RATE = 0.0005\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\r\n",
        "run_train_eval_loop(model,\r\n",
        "                    train_dataloader,\r\n",
        "                    val_dataloader,\r\n",
        "                    optimizer,\r\n",
        "                    criterion,\r\n",
        "                    device,\r\n",
        "                    epochs=30,\r\n",
        "                    clip=1,\r\n",
        "                    best_valid_loss=float('inf'),\r\n",
        "                    file_path=file_path,\r\n",
        "                    double_loss=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yra9NwY-vEL-"
      },
      "source": [
        "torch.save({\"model\":model.state_dict(),\r\n",
        "    \"optimizer\":optimizer.state_dict(),\r\n",
        "    \"loss\":1.037 ,\r\n",
        "    },'end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt')"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP8TCASrKRB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0dd1cb-ea24-4d77-ece8-d46ac00c88c2"
      },
      "source": [
        "file_path='/content/end_capstone_self_encode_sizeCor_seq128.pt'\r\n",
        "\r\n",
        "chkpt = torch.load(file_path)\r\n",
        "print(chkpt['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2910448792907927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H35YKslnmSWT",
        "outputId": "27c63235-01f8-4d96-9653-94334ea02bc3"
      },
      "source": [
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Ze2nKrvj1-"
      },
      "source": [
        "!cp /content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt /content/drive/MyDrive/EVA4/END_Capstone/"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xbt0QojKy6M"
      },
      "source": [
        "LEARNING_RATE = 0.0005\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\r\n",
        "optimizer.load_state_dict(chkpt['optimizer'])\r\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-8,verbose=True)\r\n",
        "run_train_eval_loop(model,\r\n",
        "                    train_dataloader,\r\n",
        "                    val_dataloader,\r\n",
        "                    optimizer,\r\n",
        "                    criterion,\r\n",
        "                    device,\r\n",
        "                    epochs=50,\r\n",
        "                    clip=1,\r\n",
        "                    best_valid_loss=chkpt['loss'],\r\n",
        "                    file_path=file_path,\r\n",
        "                    double_loss=True,\r\n",
        "                    scheduler=scheduler,\r\n",
        "                    mix_ratio=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBh5A2DmwfLI"
      },
      "source": [
        "!cp /content/end_capstone_self_encode_sizeCor.pt /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_mixed2.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wv7Bi-17EsJ",
        "outputId": "28e351e4-0552-4abd-b821-44eea067b2a2"
      },
      "source": [
        "file_path='/content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn3.pt'\r\n",
        "\r\n",
        "chkpt = torch.load(file_path)\r\n",
        "print(chkpt['loss'])\r\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.932535447990117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSKGPMshKnYF",
        "outputId": "de815772-946e-4cc2-d65e-eaee0f09babc"
      },
      "source": [
        "\r\n",
        "\r\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt'\r\n",
        "\r\n",
        "chkpt = torch.load(file_path)\r\n",
        "print(chkpt['loss'])\r\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KrWgIHbvMVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "936533ad-0ddb-4512-afb8-ee5dbf64a6e0"
      },
      "source": [
        "LEARNING_RATE = 0.00005\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\r\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt'\r\n",
        "\r\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-9,verbose=True)\r\n",
        "run_train_eval_loop(model,\r\n",
        "                    train_dataloader,\r\n",
        "                    val_dataloader,\r\n",
        "                    optimizer,\r\n",
        "                    criterion,\r\n",
        "                    device,\r\n",
        "                    epochs=100,\r\n",
        "                    clip=1.4,\r\n",
        "                    best_valid_loss=float('inf'),\r\n",
        "                    file_path=file_path,\r\n",
        "                    double_loss=True,\r\n",
        "                    scheduler=scheduler,\r\n",
        "                    mix_ratio=0.9) "
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\tCrit Loss: 0.247 | Token Loss: 0.140\n",
            "Val\tCrit Loss: 1.171 | Token Loss: 0.222\n",
            "Epoch: 01 | Time: 0m 27s\n",
            "\tTrain Loss: 0.236 | Train PPL:   1.266\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.933\n",
            "Train\tCrit Loss: 0.241 | Token Loss: 0.136\n",
            "Val\tCrit Loss: 1.137 | Token Loss: 0.220\n",
            "Epoch: 02 | Time: 0m 27s\n",
            "\tTrain Loss: 0.230 | Train PPL:   1.259\n",
            "\t Val. Loss: 1.045 |  Val. PPL:   2.843\n",
            "Train\tCrit Loss: 0.236 | Token Loss: 0.136\n",
            "Val\tCrit Loss: 1.128 | Token Loss: 0.217\n",
            "Epoch: 03 | Time: 0m 27s\n",
            "\tTrain Loss: 0.226 | Train PPL:   1.254\n",
            "\t Val. Loss: 1.037 |  Val. PPL:   2.821\n",
            "Train\tCrit Loss: 0.235 | Token Loss: 0.134\n",
            "Val\tCrit Loss: 1.183 | Token Loss: 0.225\n",
            "Epoch: 04 | Time: 0m 27s\n",
            "\tTrain Loss: 0.225 | Train PPL:   1.253\n",
            "\t Val. Loss: 1.087 |  Val. PPL:   2.966\n",
            "Train\tCrit Loss: 0.230 | Token Loss: 0.133\n",
            "Val\tCrit Loss: 1.152 | Token Loss: 0.221\n",
            "Epoch: 05 | Time: 0m 27s\n",
            "\tTrain Loss: 0.220 | Train PPL:   1.246\n",
            "\t Val. Loss: 1.059 |  Val. PPL:   2.882\n",
            "Train\tCrit Loss: 0.224 | Token Loss: 0.133\n",
            "Val\tCrit Loss: 1.159 | Token Loss: 0.220\n",
            "Epoch: 06 | Time: 0m 27s\n",
            "\tTrain Loss: 0.215 | Train PPL:   1.240\n",
            "\t Val. Loss: 1.065 |  Val. PPL:   2.901\n",
            "Train\tCrit Loss: 0.219 | Token Loss: 0.130\n",
            "Val\tCrit Loss: 1.180 | Token Loss: 0.227\n",
            "Epoch: 07 | Time: 0m 27s\n",
            "\tTrain Loss: 0.210 | Train PPL:   1.234\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.957\n",
            "Train\tCrit Loss: 0.216 | Token Loss: 0.129\n",
            "Val\tCrit Loss: 1.197 | Token Loss: 0.226\n",
            "Epoch: 08 | Time: 0m 27s\n",
            "\tTrain Loss: 0.207 | Train PPL:   1.231\n",
            "\t Val. Loss: 1.100 |  Val. PPL:   3.003\n",
            "Train\tCrit Loss: 0.214 | Token Loss: 0.127\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.221\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-06.\n",
            "Epoch: 09 | Time: 0m 27s\n",
            "\tTrain Loss: 0.206 | Train PPL:   1.228\n",
            "\t Val. Loss: 1.093 |  Val. PPL:   2.982\n",
            "Train\tCrit Loss: 0.206 | Token Loss: 0.124\n",
            "Val\tCrit Loss: 1.158 | Token Loss: 0.221\n",
            "Epoch: 10 | Time: 0m 27s\n",
            "\tTrain Loss: 0.198 | Train PPL:   1.219\n",
            "\t Val. Loss: 1.064 |  Val. PPL:   2.898\n",
            "Train\tCrit Loss: 0.205 | Token Loss: 0.124\n",
            "Val\tCrit Loss: 1.168 | Token Loss: 0.223\n",
            "Epoch: 11 | Time: 0m 27s\n",
            "\tTrain Loss: 0.197 | Train PPL:   1.217\n",
            "\t Val. Loss: 1.073 |  Val. PPL:   2.925\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.124\n",
            "Val\tCrit Loss: 1.199 | Token Loss: 0.232\n",
            "Epoch: 12 | Time: 0m 27s\n",
            "\tTrain Loss: 0.193 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.102 |  Val. PPL:   3.010\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.194 | Token Loss: 0.230\n",
            "Epoch: 13 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.998\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.157 | Token Loss: 0.221\n",
            "Epoch: 14 | Time: 0m 27s\n",
            "\tTrain Loss: 0.193 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.063 |  Val. PPL:   2.895\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.186 | Token Loss: 0.225\n",
            "Epoch    15: reducing learning rate of group 0 to 5.0000e-07.\n",
            "Epoch: 15 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.973\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.154 | Token Loss: 0.223\n",
            "Epoch: 16 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.060 |  Val. PPL:   2.888\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.227\n",
            "Epoch: 17 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.179 | Token Loss: 0.225\n",
            "Epoch: 18 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.956\n",
            "Train\tCrit Loss: 0.195 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.206 | Token Loss: 0.223\n",
            "Epoch: 19 | Time: 0m 27s\n",
            "\tTrain Loss: 0.188 | Train PPL:   1.207\n",
            "\t Val. Loss: 1.108 |  Val. PPL:   3.027\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.154 | Token Loss: 0.219\n",
            "Epoch: 20 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.061 |  Val. PPL:   2.888\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.164 | Token Loss: 0.220\n",
            "Epoch    21: reducing learning rate of group 0 to 5.0000e-08.\n",
            "Epoch: 21 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.164 | Token Loss: 0.220\n",
            "Epoch: 22 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.177 | Token Loss: 0.220\n",
            "Epoch: 23 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.082 |  Val. PPL:   2.949\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.180 | Token Loss: 0.224\n",
            "Epoch: 24 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.956\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.170 | Token Loss: 0.225\n",
            "Epoch: 25 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.932\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.229\n",
            "Epoch: 26 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.196 | Token Loss: 0.222\n",
            "Epoch    27: reducing learning rate of group 0 to 5.0000e-09.\n",
            "Epoch: 27 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.999\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.185 | Token Loss: 0.228\n",
            "Epoch: 28 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.090 |  Val. PPL:   2.973\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.170 | Token Loss: 0.224\n",
            "Epoch: 29 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.932\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.177 | Token Loss: 0.224\n",
            "Epoch: 30 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.082 |  Val. PPL:   2.950\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.144 | Token Loss: 0.219\n",
            "Epoch: 31 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.051 |  Val. PPL:   2.861\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.173 | Token Loss: 0.222\n",
            "Epoch: 32 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.078 |  Val. PPL:   2.938\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.182 | Token Loss: 0.226\n",
            "Epoch: 33 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.963\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.166 | Token Loss: 0.226\n",
            "Epoch: 34 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.072 |  Val. PPL:   2.922\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.173 | Token Loss: 0.222\n",
            "Epoch: 35 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.078 |  Val. PPL:   2.939\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.152 | Token Loss: 0.222\n",
            "Epoch: 36 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.059 |  Val. PPL:   2.884\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.192 | Token Loss: 0.226\n",
            "Epoch: 37 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.096 |  Val. PPL:   2.991\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.228\n",
            "Epoch: 38 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.169 | Token Loss: 0.223\n",
            "Epoch: 39 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.075 |  Val. PPL:   2.929\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.150 | Token Loss: 0.220\n",
            "Epoch: 40 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.057 |  Val. PPL:   2.878\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.172 | Token Loss: 0.224\n",
            "Epoch: 41 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.077 |  Val. PPL:   2.935\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.176 | Token Loss: 0.224\n",
            "Epoch: 42 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.081 |  Val. PPL:   2.947\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.194 | Token Loss: 0.231\n",
            "Epoch: 43 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.997\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.227\n",
            "Epoch: 44 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.094 |  Val. PPL:   2.986\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.226\n",
            "Epoch: 45 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.093 |  Val. PPL:   2.984\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.172 | Token Loss: 0.228\n",
            "Epoch: 46 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.077 |  Val. PPL:   2.937\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.155 | Token Loss: 0.220\n",
            "Epoch: 47 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.062 |  Val. PPL:   2.891\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.181 | Token Loss: 0.226\n",
            "Epoch: 48 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.962\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.163 | Token Loss: 0.223\n",
            "Epoch: 49 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.177 | Token Loss: 0.224\n",
            "Epoch: 50 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.081 |  Val. PPL:   2.948\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.156 | Token Loss: 0.219\n",
            "Epoch: 51 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.063 |  Val. PPL:   2.894\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.182 | Token Loss: 0.224\n",
            "Epoch: 52 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-11a8bfa0e890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mdouble_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     mix_ratio=0.9)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-e4ce168cb8c0>\u001b[0m in \u001b[0;36mrun_train_eval_loop\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, criterion, device, epochs, clip, best_valid_loss, file_path, double_loss, scheduler, mix_ratio)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-6a49ac91852e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, device, double_loss)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_tok_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#output = [batch size, trg len - 1, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-0b31b460a3d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, trg, trg_mask, src_tok_types)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                          \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                          \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                          src_tok_types)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#output = [batch size, trg len, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-168090165279>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg, enc_src, trg_mask, src_mask, src_tok_types)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#trg = [batch size, trg len, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-5257014854e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg, enc_src, trg_mask, src_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#positionwise feedforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0m_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositionwise_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#dropout, residual and layer norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-279165f31071>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#x = [batch size, seq len, pf dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#x = [batch size, seq len, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZO2dHwDSKQT",
        "outputId": "cd1928b9-20f6-4cfd-eeab-5ada5cc4b569"
      },
      "source": [
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt'\r\n",
        "\r\n",
        "chkpt = torch.load(file_path)\r\n",
        "print(chkpt['loss'])\r\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2759180499447718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRBviYJnKOUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1312b9ec-7f30-4145-8f08-0022e2ed863b"
      },
      "source": [
        "LEARNING_RATE = 0.00001\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\r\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn6.pt'\r\n",
        "\r\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-9,verbose=True)\r\n",
        "run_train_eval_loop(model,\r\n",
        "                    train_dataloader,\r\n",
        "                    val_dataloader,\r\n",
        "                    optimizer,\r\n",
        "                    criterion,\r\n",
        "                    device,\r\n",
        "                    epochs=100,\r\n",
        "                    clip=1.4,\r\n",
        "                    best_valid_loss=float('inf'),\r\n",
        "                    file_path=file_path,\r\n",
        "                    double_loss=True,\r\n",
        "                    scheduler=scheduler,\r\n",
        "                    mix_ratio=0.9) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\tCrit Loss: 0.198 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.164 | Token Loss: 0.220\n",
            "Epoch: 01 | Time: 0m 26s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.174 | Token Loss: 0.221\n",
            "Epoch: 02 | Time: 0m 26s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.079 |  Val. PPL:   2.942\n",
            "Train\tCrit Loss: 0.195 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.172 | Token Loss: 0.222\n",
            "Epoch: 03 | Time: 0m 26s\n",
            "\tTrain Loss: 0.188 | Train PPL:   1.207\n",
            "\t Val. Loss: 1.077 |  Val. PPL:   2.935\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.161 | Token Loss: 0.221\n",
            "Epoch: 04 | Time: 0m 26s\n",
            "\tTrain Loss: 0.188 | Train PPL:   1.207\n",
            "\t Val. Loss: 1.067 |  Val. PPL:   2.907\n",
            "Train\tCrit Loss: 0.194 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.162 | Token Loss: 0.223\n",
            "Epoch: 05 | Time: 0m 26s\n",
            "\tTrain Loss: 0.186 | Train PPL:   1.205\n",
            "\t Val. Loss: 1.068 |  Val. PPL:   2.910\n",
            "Train\tCrit Loss: 0.194 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.226\n",
            "Epoch: 06 | Time: 0m 26s\n",
            "\tTrain Loss: 0.187 | Train PPL:   1.205\n",
            "\t Val. Loss: 1.094 |  Val. PPL:   2.985\n",
            "Train\tCrit Loss: 0.190 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.162 | Token Loss: 0.221\n",
            "Epoch: 07 | Time: 0m 26s\n",
            "\tTrain Loss: 0.183 | Train PPL:   1.201\n",
            "\t Val. Loss: 1.067 |  Val. PPL:   2.908\n",
            "Train\tCrit Loss: 0.191 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.164 | Token Loss: 0.222\n",
            "Epoch: 08 | Time: 0m 26s\n",
            "\tTrain Loss: 0.184 | Train PPL:   1.202\n",
            "\t Val. Loss: 1.070 |  Val. PPL:   2.916\n",
            "Train\tCrit Loss: 0.191 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.174 | Token Loss: 0.225\n",
            "Epoch: 09 | Time: 0m 26s\n",
            "\tTrain Loss: 0.184 | Train PPL:   1.202\n",
            "\t Val. Loss: 1.079 |  Val. PPL:   2.941\n",
            "Train\tCrit Loss: 0.189 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.203 | Token Loss: 0.227\n",
            "Epoch    10: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 10 | Time: 0m 26s\n",
            "\tTrain Loss: 0.182 | Train PPL:   1.200\n",
            "\t Val. Loss: 1.105 |  Val. PPL:   3.020\n",
            "Train\tCrit Loss: 0.188 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.185 | Token Loss: 0.224\n",
            "Epoch: 11 | Time: 0m 26s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.199\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.195 | Token Loss: 0.226\n",
            "Epoch: 12 | Time: 0m 26s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.998\n",
            "Train\tCrit Loss: 0.189 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.180 | Token Loss: 0.223\n",
            "Epoch: 13 | Time: 0m 26s\n",
            "\tTrain Loss: 0.182 | Train PPL:   1.199\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.957\n",
            "Train\tCrit Loss: 0.188 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.175 | Token Loss: 0.223\n",
            "Epoch: 14 | Time: 0m 26s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.199\n",
            "\t Val. Loss: 1.080 |  Val. PPL:   2.945\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.199 | Token Loss: 0.228\n",
            "Epoch: 15 | Time: 0m 26s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.102 |  Val. PPL:   3.009\n",
            "Train\tCrit Loss: 0.188 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.191 | Token Loss: 0.226\n",
            "Epoch    16: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 16 | Time: 0m 26s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.199\n",
            "\t Val. Loss: 1.094 |  Val. PPL:   2.987\n",
            "Train\tCrit Loss: 0.189 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.180 | Token Loss: 0.225\n",
            "Epoch: 17 | Time: 0m 26s\n",
            "\tTrain Loss: 0.182 | Train PPL:   1.199\n",
            "\t Val. Loss: 1.085 |  Val. PPL:   2.958\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.178 | Token Loss: 0.223\n",
            "Epoch: 18 | Time: 0m 26s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.083 |  Val. PPL:   2.953\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.161 | Token Loss: 0.222\n",
            "Epoch: 19 | Time: 0m 26s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.067 |  Val. PPL:   2.906\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.192 | Token Loss: 0.224\n",
            "Epoch: 20 | Time: 0m 26s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.095 |  Val. PPL:   2.989\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.232 | Token Loss: 0.228\n",
            "Epoch: 21 | Time: 0m 26s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.132 |  Val. PPL:   3.101\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.151 | Token Loss: 0.220\n",
            "Epoch: 22 | Time: 0m 27s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.058 |  Val. PPL:   2.880\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.191 | Token Loss: 0.226\n",
            "Epoch: 23 | Time: 0m 26s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.095 |  Val. PPL:   2.988\n",
            "Train\tCrit Loss: 0.188 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.189 | Token Loss: 0.226\n",
            "Epoch: 24 | Time: 0m 27s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.093 |  Val. PPL:   2.983\n",
            "Train\tCrit Loss: 0.188 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.192 | Token Loss: 0.225\n",
            "Epoch: 25 | Time: 0m 27s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.096 |  Val. PPL:   2.991\n",
            "Train\tCrit Loss: 0.185 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.183 | Token Loss: 0.219\n",
            "Epoch: 26 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.087 |  Val. PPL:   2.964\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.221 | Token Loss: 0.234\n",
            "Epoch: 27 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.122 |  Val. PPL:   3.072\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.199 | Token Loss: 0.226\n",
            "Epoch    28: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch: 28 | Time: 0m 27s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.101 |  Val. PPL:   3.008\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.197 | Token Loss: 0.226\n",
            "Epoch: 29 | Time: 0m 27s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.100 |  Val. PPL:   3.003\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.225\n",
            "Epoch: 30 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.088 |  Val. PPL:   2.968\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.182 | Token Loss: 0.224\n",
            "Epoch: 31 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.963\n",
            "Train\tCrit Loss: 0.189 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.181 | Token Loss: 0.225\n",
            "Epoch: 32 | Time: 0m 27s\n",
            "\tTrain Loss: 0.182 | Train PPL:   1.200\n",
            "\t Val. Loss: 1.085 |  Val. PPL:   2.960\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.188 | Token Loss: 0.229\n",
            "Epoch: 33 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.092 |  Val. PPL:   2.981\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.195 | Token Loss: 0.224\n",
            "Epoch: 34 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.997\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.171 | Token Loss: 0.222\n",
            "Epoch: 35 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.933\n",
            "Train\tCrit Loss: 0.185 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.183 | Token Loss: 0.221\n",
            "Epoch: 36 | Time: 0m 27s\n",
            "\tTrain Loss: 0.178 | Train PPL:   1.195\n",
            "\t Val. Loss: 1.087 |  Val. PPL:   2.964\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.172 | Token Loss: 0.222\n",
            "Epoch: 37 | Time: 0m 27s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.077 |  Val. PPL:   2.937\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.117\n",
            "Val\tCrit Loss: 1.186 | Token Loss: 0.225\n",
            "Epoch: 38 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.090 |  Val. PPL:   2.975\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.161 | Token Loss: 0.220\n",
            "Epoch: 39 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.197\n",
            "\t Val. Loss: 1.067 |  Val. PPL:   2.906\n",
            "Train\tCrit Loss: 0.186 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.186 | Token Loss: 0.223\n",
            "Epoch: 40 | Time: 0m 27s\n",
            "\tTrain Loss: 0.179 | Train PPL:   1.196\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.972\n",
            "Train\tCrit Loss: 0.189 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.192 | Token Loss: 0.226\n",
            "Epoch: 41 | Time: 0m 27s\n",
            "\tTrain Loss: 0.182 | Train PPL:   1.200\n",
            "\t Val. Loss: 1.095 |  Val. PPL:   2.991\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.118\n",
            "Val\tCrit Loss: 1.183 | Token Loss: 0.222\n",
            "Epoch: 42 | Time: 0m 27s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.087 |  Val. PPL:   2.966\n",
            "Train\tCrit Loss: 0.187 | Token Loss: 0.119\n",
            "Val\tCrit Loss: 1.194 | Token Loss: 0.230\n",
            "Epoch: 43 | Time: 0m 27s\n",
            "\tTrain Loss: 0.180 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.997\n",
            "Train\tCrit Loss: 0.188 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.185 | Token Loss: 0.225\n",
            "Epoch: 44 | Time: 0m 27s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.198\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2husK3UdJv5"
      },
      "source": [
        "run_train_eval_loop(model,\r\n",
        "                    train_dataloader,\r\n",
        "                    val_dataloader,\r\n",
        "                    optimizer,\r\n",
        "                    criterion,\r\n",
        "                    device,\r\n",
        "                    epochs=20,\r\n",
        "                    clip=1,\r\n",
        "                    best_valid_loss=chkpt['loss'],\r\n",
        "                    file_path=file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imWxpZVvhqAD"
      },
      "source": [
        "def get_code(sentence,\r\n",
        "             tokenizer,\r\n",
        "             model, \r\n",
        "             device, \r\n",
        "             max_len = 100):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    dataset_handler = NLPLDataSet(tokenizer, tokenizer)\r\n",
        "    src_indexes, src_mask =  dataset_handler.prepare_tokens(sentence, dataset_handler.doc_tokenizer)\r\n",
        "    # if isinstance(sentence, str):\r\n",
        "    #     nlp = spacy.load('de')\r\n",
        "    #     tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    # else:\r\n",
        "    #     tokens = [token.lower() for token in sentence]\r\n",
        "    #dataset_handler.prepare_tokens()\r\n",
        "\r\n",
        "    #tokens = [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\r\n",
        "        \r\n",
        "    #src_indexes = [tokenizer.convert_tokens_to_ids[token] for token in tokens]\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    src_mask = torch.LongTensor(src_mask).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    src_mask = model.make_src_mask(src_mask)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
        "\r\n",
        "    trg_indexes = [tokenizer.cls_token_id]\r\n",
        "    #trg_mask = [1]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        base_mask = torch.LongTensor([1]*(i+1)).unsqueeze(0).to(device)\r\n",
        "        trg_mask = model.make_trg_mask(trg_tensor, base_mask)\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == tokenizer.sep_token_id:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [tokenizer.convert_ids_to_tokens(i) for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDo3e4HVKMxI"
      },
      "source": [
        "def get_code(sentence,\r\n",
        "             doc_tokenizer,\r\n",
        "             code_tokenizer,\r\n",
        "             code_tok_vectorizer,\r\n",
        "             model, \r\n",
        "             device, \r\n",
        "             max_len = 100):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    dataset_handler = NLPLDataSet(doc_tokenizer, code_tokenizer, code_tok_vectorizer)\r\n",
        "    src_indexes, src_mask =  dataset_handler.prepare_tokens(sentence, dataset_handler.doc_tokenizer)\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    src_mask = torch.LongTensor(src_mask).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    src_mask = model.make_src_mask(src_mask)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
        "\r\n",
        "    trg_indexes = [code_tok_vectorizer.ID_SOS_FOR_CODEPIECE]\r\n",
        "    trg_tok_indexes = [code_tok_vectorizer.ID_SOS_FOR_TOKEN_TYPE]\r\n",
        "    #trg_mask = [1]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "        trg_tok_tensor = torch.LongTensor(trg_tok_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        base_mask = torch.LongTensor([1]*(i+1)).unsqueeze(0).to(device)\r\n",
        "        trg_mask = model.make_trg_mask(trg_tensor, base_mask)\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            output, tok_output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask, trg_tok_tensor)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        pred_tok_type = tok_output.argmax(2)[:,-1].item()\r\n",
        "        trg_tok_indexes.append(pred_tok_type)\r\n",
        "\r\n",
        "        if (pred_token == code_tok_vectorizer.ID_EOS_FOR_CODEPIECE or \r\n",
        "            pred_token == code_tok_vectorizer.code_word2idx['___EOS___']):\r\n",
        "            break\r\n",
        "\r\n",
        "    trg_tokens = [code_tok_vectorizer.convert_id_to_codepiece(i) for i in trg_indexes]\r\n",
        "    trg_token_types = [code_tok_vectorizer.convert_id_to_toktype(i) for i in trg_tok_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], trg_token_types[1:], attention"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ammem8M7qAL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e70007d-d8e2-412f-a5e8-e10d113f562e"
      },
      "source": [
        "input_text = \"write a program generate an array whose all elements are 0.\"\r\n",
        "splitted_text = auto_tokenizer.tokenize(input_text)\r\n",
        "mycode, mytoks, attention_val = get_code(input_text,\r\n",
        "                                 auto_tokenizer, \r\n",
        "                                 init_tokenizer,\r\n",
        "                                 code_tok_vectorizer,\r\n",
        "                                 model, \r\n",
        "                                 device,\r\n",
        "                                 max_len=512)\r\n",
        "\r\n",
        "print(init_tokenizer.untokenize(mycode))\r\n",
        "#output = auto_tokenizer.convert_tokens_to_string(mycode[:-1])\r\n",
        "#print(output)"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import random \n",
            "print (random .choice ([i for i in range (11 )if i %5 ==0 ]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1jk-tl8LFYX",
        "outputId": "7b572e6d-5523-4d9f-cfa8-e2e8da8cace7"
      },
      "source": [
        "import random \r\n",
        "print (random .choice ([i for i in range (11 )if i %5 ==0 ]))"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hGdF_mLk164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c58e65-caba-4c3c-a854-4bcad62ae10a"
      },
      "source": [
        "data"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['5', ('Apples', 5, 5, '20'), ('Pears', 1, 1, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayl995l96d6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "205fa9d8-879a-4ef4-ab52-d65600faee56"
      },
      "source": [
        "import matplotlib.ticker as ticker\r\n",
        "\r\n",
        "#display_attention(splitted_text, mycode, attention_val[:,2,:,:].unsqueeze(1), n_heads=1, n_rows=1, n_cols=1)\r\n",
        "n_heads=4\r\n",
        "n_rows=2\r\n",
        "n_cols=n_heads/n_rows\r\n",
        "display_attention(splitted_text, \r\n",
        "                  mycode, \r\n",
        "                  attention_val[:,:8,:,:], \r\n",
        "                  n_heads=n_heads, \r\n",
        "                  n_rows=n_rows, \r\n",
        "                  n_cols=n_cols)\r\n"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1800 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oo7rjqO83t6"
      },
      "source": [
        "!cp /content/end_capstone_self_encode_sizeCor.pt /content/drive/MyDrive/EVA4/END_Capstone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv3NMuAJKCkK",
        "outputId": "500b9444-051e-40db-a0dd-c021108fa4a5"
      },
      "source": [
        "str1 ='It is a glorious day'\r\n",
        "\r\n",
        "res =len (str1 .split ())\r\n",
        "\r\n",
        "print (\"The number of words in string are : \"+str (res ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of words in string are : 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG4hZFi4L-HT",
        "outputId": "4e5d08c2-5ea4-4071-befc-7a711202c767"
      },
      "source": [
        "nl_to_pl_df[(nl_to_pl_df['cleaned_code_len'] <= 128) & (nl_to_pl_df['docstring_len'] <= 256)].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "docstring           2675\n",
              "code                2675\n",
              "docstring_len       2675\n",
              "code_len            2675\n",
              "cleaned_code        2675\n",
              "cleaned_code_len    2675\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiW4fEDsaTGC"
      },
      "source": [
        "all_strings = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= 128]['cleaned_code'].values\r\n",
        "\r\n",
        "for one_string in all_strings[2700:2750]:\r\n",
        "    print(one_string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Arp5Z30Hds"
      },
      "source": [
        "#all_strings = nl_to_pl_df[(nl_to_pl_df['cleaned_code_len'] <= 128) & (nl_to_pl_df['docstring_len'] <= 256)]['docstring'].values\r\n",
        "all_strings = nl_to_pl_df[(nl_to_pl_df['cleaned_code_len'] <= 256) ]['docstring'].values\r\n",
        "\r\n",
        "gen_code_arr = []\r\n",
        "for one_string in all_strings:\r\n",
        "    #splitted_text = auto_tokenizer.tokenize(input_text)\r\n",
        "    gen_code = \"NoCode\"\r\n",
        "    cleaned_string = one_string.rstrip('\\n').lstrip('#')\r\n",
        "    try:\r\n",
        "        mycode, my_tok, attention_val = get_code(cleaned_string,\r\n",
        "                                        auto_tokenizer, \r\n",
        "                                        init_tokenizer,\r\n",
        "                                        code_tok_vectorizer,\r\n",
        "                                        model, \r\n",
        "                                        device,\r\n",
        "                                        max_len=200)\r\n",
        "        gen_code = init_tokenizer.untokenize(mycode)\r\n",
        "        gen_code_arr.append(gen_code)\r\n",
        "    except:\r\n",
        "        print(\"Error\")        \r\n",
        "        print(cleaned_string)\r\n",
        "        gen_code_arr.append(gen_code)\r\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL6OAWoma4Tj"
      },
      "source": [
        "nl_to_pl_df.loc[(nl_to_pl_df['cleaned_code_len'] <= 256), 'gen_code'] = gen_code_arr"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLXQhfXohAnM"
      },
      "source": [
        "nl_to_pl_df.to_csv(\"end_capstone_gen_code.csv\", index=False)"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbsDAfE8hN4V"
      },
      "source": [
        "all_strings = nl_to_pl_df[(nl_to_pl_df['cleaned_code_len'] <= 256) ][['docstring','cleaned_code', 'gen_code']]"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afz7IwWVhZ-U",
        "outputId": "723c5b7c-e5b0-44b4-fba5-9eecfab9ef55"
      },
      "source": [
        "for row in all_strings[-50:].itertuples():\r\n",
        "    print(\"*****************START****************************\")\r\n",
        "    print(row.docstring)\r\n",
        "    print(row.cleaned_code)\r\n",
        "    print(\"*********************************************\")\r\n",
        "    print(row.gen_code)\r\n",
        "    print(\"*******************END**************************\")\r\n",
        "    #print(row.gen_code)"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****************START****************************\n",
            "# By using list comprehension, write a program to print the list after removing the 0th, 2nd, 4th,6th numbers in [12,24,35,70,88,120,155].\n",
            "\n",
            "li = [12,24,35,70,88,120,155]\n",
            "li = [x for (i,x) in enumerate(li) if i%2!=0]\n",
            "print li\n",
            "*********************************************\n",
            "li =[12 ,24 ,35 ,70 ,88 ,120 ,155 ]\n",
            "li =[x for (i ,x )in enumerate (li )if i %2 !=0 ]\n",
            "print li \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# By using list comprehension, write a program generate a 3*5*8 3D array whose each element is 0.\n",
            "\n",
            "array = [[ [0 for col in range(8)] for col in range(5)] for row in range(3)]\n",
            "print array\n",
            "*********************************************\n",
            "array =[[[0 for col in range (8 )]for col in range (8 )]for row in range (3 )]\n",
            "print array \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# By using list comprehension, write a program to print the list after removing the 0th,4th,5th numbers in [12,24,35,70,88,120,155].\n",
            "\n",
            "li = [12,24,35,70,88,120,155]\n",
            "li = [x for (i,x) in enumerate(li) if i not in (0,4,5)]\n",
            "print li\n",
            "*********************************************\n",
            "li =[12 ,24 ,35 ,70 ,88 ,120 ,155 ]\n",
            "li =[x for (i ,x )in enumerate (li )if i not in (0 ,4 ,5 )]\n",
            "print (li )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# By using list comprehension, write a program to print the list after removing the value 24 in [12,24,35,24,88,120,155].\n",
            "\n",
            "li = [12,24,35,24,88,120,155]\n",
            "li = [x for x in li if x!=24]\n",
            "print li\n",
            "*********************************************\n",
            "li =[12 ,24 ,35 ,24 ,88 ,120 ,155 ]\n",
            "li =[x for x in li if x !=24 ]\n",
            "print li \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# With two given lists [1,3,6,78,35,55] and [12,24,35,24,88,120,155], write a program to make a list whose elements are intersection of the above given lists.\n",
            "\n",
            "set1=set([1,3,6,78,35,55])\n",
            "set2=set([12,24,35,24,88,120,155])\n",
            "set1 &= set2\n",
            "li=list(set1)\n",
            "print li\n",
            "*********************************************\n",
            "set1 =set ([1 ,3 ,6 ,78 ,35 ,55 ])\n",
            "set2 =set ([12 ,24 ,35 ,24 ,88 ,120 ,155 ])\n",
            "set1 &=set2 \n",
            "li =list (set1 )\n",
            "print li \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# With a given list [12,24,35,24,88,120,155,88,120,155], write a program to print this list after removing all duplicate values with original order reserved.\n",
            "\n",
            "def removeDuplicate( li ):\n",
            "    newli=[]\n",
            "    seen = set()\n",
            "    for item in li:\n",
            "        if item not in seen:\n",
            "            seen.add( item )\n",
            "            newli.append(item)\n",
            "    return newli\n",
            "li=[12,24,35,24,88,120,155,88,120,155]\n",
            "print removeDuplicate(li)\n",
            "*********************************************\n",
            "def removeDuplicate (li ):\n",
            "    newli =[]\n",
            "    seen =set ()\n",
            "    for item in li :\n",
            "        if item not in seen :\n",
            "            seen .add (item )\n",
            "            newli .append (item )\n",
            "            newli .append (item )\n",
            "    return newli \n",
            "li =[12 ,24 ,35 ,24 ,88 ,120 ,155 ]\n",
            "print removeDuplicate (li )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program which count and print the numbers of each character in a string input by console.\n",
            "\n",
            "dic = {}\n",
            "s=raw_input()\n",
            "for s in s:\n",
            "    dic[s] = dic.get(s,0)+1\n",
            "print '\\n'.join(['%s,%s' % (k, v) for k, v in dic.items()])\n",
            "*********************************************\n",
            "dic ={}\n",
            "s =raw_input ()\n",
            "for s in s :\n",
            "    dic [s ]=dic .get (s ,0 )+1 \n",
            "print '\\n'.join (['%s,%s'%(k ,v )for k ,v in dic .items ()])\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program which accepts a string from console and print it in reverse order.\n",
            "\n",
            "s=raw_input()\n",
            "s = s[::-1]\n",
            "print s\n",
            "*********************************************\n",
            "s =input ()\n",
            "s =s [::-1 ]\n",
            "print (s )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program which accepts a string from console and print the characters that have even indexes.\n",
            "\n",
            "s=raw_input()\n",
            "s = s[::2]\n",
            "print s\n",
            "*********************************************\n",
            "s =input ()\n",
            "s =s [::2 ]\n",
            "print (s )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program which prints all permutations of [1,2,3]\n",
            "\n",
            "import itertools\n",
            "print list(itertools.permutations([1,2,3]))\n",
            "*********************************************\n",
            "import itertools \n",
            "print list (itertools .permutations ([1 ,2 ,3 ]))\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a program to solve a classic ancient Chinese puzzle:  We count 35 heads and 94 legs among the chickens and rabbits in a farm. How many rabbits and how many chickens do we have?\n",
            "\n",
            "def solve(numheads,numlegs):\n",
            "    ns='No solutions!'\n",
            "    for i in range(numheads+1):\n",
            "        j=numheads-i\n",
            "        if 2*i+4*j==numlegs:\n",
            "            return i,j\n",
            "    return ns,ns\n",
            "*********************************************\n",
            "def solve (numheads ,numlegs ):\n",
            "    ns ='No solutions!'\n",
            "    for i in range (numheads +1 ):\n",
            "        j =numheads -i \n",
            "        if 2 *i +4 *j ==numlegs :\n",
            "            return i ,j \n",
            "    return ns ,ns \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to count characters in a string\n",
            "\n",
            "st = \"AmmarAdil\"\n",
            "count = {}\n",
            "for a in st:\n",
            "    if a in count:\n",
            "        count[a]+=1\n",
            "    else:\n",
            "        count[a] = 1\n",
            "print('Count', count)\n",
            "*********************************************\n",
            "st =\"AmmarAdil\"\n",
            "count ={}\n",
            "for a in st :\n",
            "    if a in count :\n",
            "        count [a ]+=1 \n",
            "    else :\n",
            "        count [a ]=1 \n",
            "print ('Count',count )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to print count of vowels in a string\n",
            "\n",
            "st = \"ammaradil\"\n",
            "vowle = ['a', 'e', 'i', 'o', 'u']\n",
            "count = 0\n",
            "\n",
            "for s in st:\n",
            "    if s in vowle:\n",
            "        count = count+1\n",
            "\n",
            "print(\"Count\", count)\n",
            "*********************************************\n",
            "\n",
            "str1 =\"ammaradil\"\n",
            "vowle =['a','e','i','o','u']\n",
            "count =0 \n",
            "\n",
            "for s in str1 :\n",
            "    if s in count :\n",
            "        count =count +1 \n",
            "print (\"Count\",count )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write program to convert string to upper case\n",
            "\n",
            "st = \"ammar adil\"\n",
            "\n",
            "upper_st = st.upper()\n",
            "print(\"Upper Case\", upper_st)\n",
            "*********************************************\n",
            "word =\"Hello World\"\n",
            "print (f\"String contains upper case?:{check}\")\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write program to convert string to lower case\n",
            "\n",
            "st = \"AMMAR ADIL\"\n",
            "\n",
            "lower_st = st.lower()\n",
            "print(\"Lower Case\", lower_st)\n",
            "*********************************************\n",
            "\n",
            "string =\"AMMAR ADIL\"\n",
            "\n",
            "lower_st =st .lower ()\n",
            "print (\"Lower Case\",lower_st )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find union of 2 arrays\n",
            "\n",
            "a = {1, 2, 3, 4}\n",
            "b = {3, 4, 5, 6}\n",
            "\n",
            "union_both = a.union(b)\n",
            "print(\"Union\", union_both)\n",
            "*********************************************\n",
            "a ={\"a\",\"b\",\"c\"}\n",
            "b ={\"d\",\"d\"}\n",
            "a .update (b )\n",
            "print (b )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find intersection\n",
            "\n",
            "a = {1, 2, 3, 4}\n",
            "b = {3, 4, 5, 6}\n",
            "\n",
            "intersection_both = a.intersection(b)\n",
            "print(\"Intersection\", intersection_both)\n",
            "*********************************************\n",
            "\n",
            "intersection =lambda a ,b :list (set (a )&set (b ))\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to create print array in beautiful format\n",
            "\n",
            "a = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]\n",
            "\n",
            "for i in a:\n",
            "    row = '|'\n",
            "    for b in i:\n",
            "        row = row + ' ' + str(b)\n",
            "    print(row + ' ' + '|')\n",
            "*********************************************\n",
            "a =[[1 ,2 ,3 ,4 ,5 ,6 ],[7 ,8 ,9 ],[9 ,12 ,13 ,14 ,15 ]\n",
            "\n",
            "for i in range (0 ,11 ):\n",
            "    row =row +' '+'___NEWLINE___ for row in range (row +' '+' '+'|'):\n",
            "        row +str (row +' '+str (row +' '+str (row +' '))\n",
            "print (row +'|')\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to join all items in a tuple into a string, using a hash character as separator\n",
            "\n",
            "myTuple = (\"John\", \"Peter\", \"Vicky\")\n",
            "x = \"#\".join(myTuple)\n",
            "print(x)\n",
            "*********************************************\n",
            "myTuple =(\"John\",\"Peter\",\"Vicky\")\n",
            "x =\"#\".join (myTuple )\n",
            "print (x )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to remove spaces at the beginning and at the end of the string\n",
            "\n",
            "txt = \"     banana     \"\n",
            "x = txt.strip()\n",
            "print(\"of all fruits\", x, \"is my favorite\")\n",
            "*********************************************\n",
            "txt =\"     banana     \"\n",
            "x =txt .strip ()\n",
            "print (\"of all fruits\",x ,\"is my favorite\")\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to remove the leading and trailing characters\n",
            "\n",
            "txt = \",,,,,rrttgg.....banana....rrr\"\n",
            "x = txt.strip(\",.grt\")\n",
            "print(x)\n",
            "*********************************************\n",
            "txt =\",,,,,rrttgg.....banana....rrr\"\n",
            "x =txt .strip (\",.grt\")\n",
            "print (x )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to split a string into a list where each line is a list item\n",
            "\n",
            "txt = \"Thank you for the music\\nWelcome to the jungle\"\n",
            "x = txt.splitlines()\n",
            "print(x)\n",
            "*********************************************\n",
            "txt =\"Thank you for the music\\nWelcome to the jungle\"\n",
            "x =txt .splitlines ()\n",
            "print (x )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find index of a word in given string\n",
            "\n",
            "txt = \"Hello, welcome to my world.\"\n",
            "x = txt.index(\"welcome\")\n",
            "print(x)\n",
            "*********************************************\n",
            "txt =\"Hello, welcome to my world.\"\n",
            "x =txt .index (\"welcome\")\n",
            "print (x )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find ceil of a number\n",
            "\n",
            "import math\n",
            "\n",
            "number = 34.564\n",
            "ce = math.ceil(number)\n",
            "print('Ceil', ce)\n",
            "*********************************************\n",
            "import math \n",
            "\n",
            "number =34.564 \n",
            "fa =math .fabs (number )\n",
            "print ('Fabs',fa )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find absoluute number of a given number\n",
            "\n",
            "import math\n",
            "\n",
            "number = 34.564\n",
            "fa = math.fabs(number)\n",
            "print('Fabs', fa)\n",
            "*********************************************\n",
            "import math \n",
            "\n",
            "number =34.564 \n",
            "fa =math .fabs (number )\n",
            "print ('Fabs',fa )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find factorinal of a number\n",
            "\n",
            "import math\n",
            "\n",
            "number = 8\n",
            "fa = math.factorial(number)\n",
            "print('Factorial', fa)\n",
            "*********************************************\n",
            "import math \n",
            "\n",
            "number =8 \n",
            "fa =math .factorial (number )\n",
            "print ('Factorial',fa )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find exponential of a number\n",
            "\n",
            "import math\n",
            "\n",
            "number = 3\n",
            "\n",
            "print('Exponential', math.exp(number))\n",
            "*********************************************\n",
            "import math \n",
            "\n",
            "number =3 \n",
            "\n",
            "print ('Exponential',math .exp (number ))\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find log of a number\n",
            "\n",
            "import math\n",
            "\n",
            "num = 5\n",
            "base = 7\n",
            "\n",
            "print(\"Log_x_b\", math.log(num, base))\n",
            "*********************************************\n",
            "\n",
            "import math \n",
            "\n",
            "num =5 \n",
            "\n",
            "print (\"Log_x_x_x_math .log (num ,base ))\n",
            "print (\"y =\",math .log (num ))\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find cosine of a number\n",
            "\n",
            "import math\n",
            "\n",
            "num = 45\n",
            "print(\"Cosine\", math.cos(num))\n",
            "*********************************************\n",
            "import math \n",
            "\n",
            "num =45 \n",
            "print (\"Cosine\",math .cos (num ))\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find sin of a number\n",
            "\n",
            "import math\n",
            "\n",
            "num = 45\n",
            "print(\"Sin\", math.sin(num))\n",
            "*********************************************\n",
            "import math \n",
            "\n",
            "num =45 \n",
            "print (\"Cosine\",math .cos (num ))\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to find tangent of a number\n",
            "\n",
            "import math\n",
            "\n",
            "num = 45\n",
            "print(\"Tangent\", math.tan(num))\n",
            "*********************************************\n",
            "def randomto_type (a :float ,b :float )->float :\n",
            "\n",
            "    return math .cos (a )**2 )\n",
            "\n",
            "a =5 \n",
            "\n",
            "print (\"Input the power of is \",x )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a program to print bit wise AND of two numbers\n",
            "\n",
            "a = 60            ##\n",
            "b = 13            ##\n",
            "\n",
            "c = a & b        ##\n",
            "print(\"AND\", c)\n",
            "*********************************************\n",
            "a =60 \n",
            "b =13 \n",
            "\n",
            "c =a ^b \n",
            "print (\"XOR\",c )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a program to print bit wise OR of two numbers\n",
            "\n",
            "a = 60\n",
            "b = 13\n",
            "\n",
            "c = a | b\n",
            "print(\"OR\", c)\n",
            "*********************************************\n",
            "a =60 \n",
            "b =13 \n",
            "\n",
            "c =a |b \n",
            "print (\"OR\",c )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a program to print bit wise XOR of two numbers\n",
            "\n",
            "a = 60\n",
            "b = 13\n",
            "\n",
            "c = a ^ b\n",
            "print(\"XOR\", c)\n",
            "*********************************************\n",
            "a =60 \n",
            "b =13 \n",
            "\n",
            "c =a ^b \n",
            "print (\"XOR\",c )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a program to calculate Binary Ones Complement of a number\n",
            "\n",
            "a = 60\n",
            "\n",
            "c = ~a\n",
            "print(\"Binary Ones Complement\", c)\n",
            "*********************************************\n",
            "a =60 \n",
            "\n",
            "c =~a \n",
            "print (\"Binary Ones Complement\",c )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to Binary Left Shift a number\n",
            "\n",
            "c = a << 2\n",
            "print(\"Binary Left Shift\", c)\n",
            "*********************************************\n",
            "c =a <<2 \n",
            "print (\"Binary Left Shift\",c )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# write a program to Binary Right Shift a number\n",
            "\n",
            "c = a >> 2\n",
            "print(\"Binary Right Shift\", c)\n",
            "*********************************************\n",
            "c =a >>2 \n",
            "print (\"Binary Right Shift\",c )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program, which will find all such numbers between 1000 and 3000 (both included) such that each digit of the number is an even number.The numbers obtained should be printed in a comma-separated sequence on a single line.\n",
            "\n",
            "values = []\n",
            "for i in range(1000, 3001):\n",
            "    s = str(i)\n",
            "    if (int(s[0])%2==0) and (int(s[1])%2==0) and (int(s[2])%2==0) and (int(s[3])%2==0):\n",
            "        values.append(s)\n",
            "        print (\",\".join(values))\n",
            "*********************************************\n",
            "values =[]\n",
            "for i in range (1000 ,3001 ):\n",
            "    s =str (i )\n",
            "    if (int (s [0 ])%2 ==0 )and (int (s [1 ])%2 ==0 )and (int (s [2 ])%2 ==0 )and (int (s [3 ])%2 ==0 )and (int (s [2 ==0 )%2 ==0 )and (s [3 ])%2 ==0 )and (int (s [3 ])%2 ==0 ):\n",
            "        values .append (s )\n",
            "        print (\",\".append (s )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program that accepts a sentence and calculate the number of letters and digits.\n",
            "\n",
            "s = raw_input()\n",
            "d={\"DIGITS\":0, \"LETTERS\":0}\n",
            "for c in s:\n",
            "    if c.isdigit():\n",
            "        d[\"DIGITS\"]+=1\n",
            "    elif c.isalpha():\n",
            "        d[\"LETTERS\"]+=1\n",
            "    else:\n",
            "        pass\n",
            "print (\"LETTERS\", d[\"LETTERS\"])\n",
            "print (\"DIGITS\", d[\"DIGITS\"])\n",
            "*********************************************\n",
            "s =input ()\n",
            "d ={\"DIGITS\":0 ,\"LETTERS\":0 }\n",
            "for c in s :\n",
            "    if c .isdigit ():\n",
            "        d [\"DIGITS\"]+=1 \n",
            "    elif c .isalpha ():\n",
            "        d [\"LETTERS\"]+=1 \n",
            "    else :\n",
            "        pass \n",
            "print (\"LETTERS\",d [\"DIGITS\"])\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program using a list comprehension to square each odd number in a list. The list is input by a sequence of comma-separated numbers.\n",
            "\n",
            "values = raw_input()\n",
            "numbers = [x for x in values.split(\",\") if int(x)%2!=0]\n",
            "print (\",\".join(numbers))\n",
            "*********************************************\n",
            "values =raw_input ()\n",
            "numbers =[x for x in values .split (\",\")if int (x )%2 !=0 ]\n",
            "print \",\".join (numbers )\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Define a class with a generator which can iterate the numbers, which are divisible by 7, between a given range 0 and n.\n",
            "\n",
            "def putNumbers(n):\n",
            "    i = 0\n",
            "    while i<n:\n",
            "        j=i\n",
            "        i=i+1\n",
            "        if j%7==0:\n",
            "            yield j\n",
            "\n",
            "    for i in reverse(100):\n",
            "        print (i)\n",
            "*********************************************\n",
            "def putNumbers (n ):\n",
            "    i =0 \n",
            "    while i <n :\n",
            "        j =i \n",
            "        i =i +1 \n",
            "        if j %7 ==0 :\n",
            "            yield j \n",
            "\n",
            "    for i in reverse (100 ):\n",
            "        print i \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program using a function which can print a dictionary where the keys are numbers between 1 and 3 (both included) and the values are square of keys.\n",
            "\n",
            "def printDict():\n",
            "    d=dict()\n",
            "    d[1]=1\n",
            "    d[2]=2**2\n",
            "    d[3]=3**2\n",
            "    print (d)\n",
            "printDict()\n",
            "*********************************************\n",
            "def printDict ():\n",
            "    d =dict ()\n",
            "    d [1 ]=1 \n",
            "    d [2 ]=2 **2 \n",
            "    d [3 ]=3 **2 \n",
            "    print d \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Define a class named American which has a static method called printNationality.\n",
            "\n",
            "class American(object):\n",
            "    @staticmethod\n",
            "    def printNationality():\n",
            "        print(\"America\")\n",
            "\n",
            "anAmerican = American()\n",
            "anAmerican.printNationality()\n",
            "American.printNationality()\n",
            "*********************************************\n",
            "class American (object ):\n",
            "    @staticmethod \n",
            "    def printNationality ():\n",
            "        print \"America\"\n",
            "anAmerican =American ()\n",
            "anAmerican .printNationality ()\n",
            "American .printNationality ()\n",
            "American .printNationality ()\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a function to compute 5/0 and use try/except to catch the exceptions.\n",
            "\n",
            "\n",
            "\n",
            "def throws():\n",
            "    return 5/0\n",
            "\n",
            "try:\n",
            "    throws()\n",
            "except ZeroDivisionError:\n",
            "    print (\"division by zero!\")\n",
            "except Exception, err:\n",
            "    print ('Caught an exception')\n",
            "finally:\n",
            "    print ('In finally block for cleanup')\n",
            "*********************************************\n",
            "def throws ():\n",
            "    return 5 /0 \n",
            "\n",
            "try :\n",
            "    throws ()\n",
            "except ZeroDivisionError :\n",
            "    print \"division by zero!\"\n",
            "except Exception :\n",
            "    print ('Caught an exception')\n",
            "finally :\n",
            "    print ('In finally block for cleanup')\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program to print the list after removing the 0th, 2nd, 4th,6th numbers in [12,24,35,70,88,120,155].\n",
            "\n",
            "li = [12,24,35,70,88,120,155]\n",
            "li = [x for (i,x) in enumerate(li) if i%2!=0]\n",
            "print(li)\n",
            "*********************************************\n",
            "li =[12 ,24 ,35 ,70 ,88 ,120 ,155 ]\n",
            "li =[x for (i ,x )in enumerate (li )if i %2 !=0 ]\n",
            "print li \n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program for selection sort\n",
            "\n",
            "for i in range(len(A)):\n",
            "    min_idx = i\n",
            "    for j in range(i+1, len(A)):\n",
            "        if A[min_idx] > A[j]:\n",
            "            min_idx = j\n",
            "\n",
            "A[i], A[min_idx] = A[min_idx], A[i]\n",
            "*********************************************\n",
            "\n",
            "test_list =[4 ,5 ,6 ,7 ,8 ]\n",
            "\n",
            "\n",
            "count =0 \n",
            "\n",
            "for i in range (len (X )):\n",
            "    for j in range (len (X )):\n",
            "        if j %2 ==0 :\n",
            "            count +=1 \n",
            "\n",
            "print (f'count of elements {count}')\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program for implementation of Bubble Sort\n",
            "\n",
            "def bubbleSort(arr):\n",
            "    n = len(arr)\n",
            "    for i in range(n-1):\n",
            "        for j in range(0, n-i-1):\n",
            "            if arr[j] > arr[j+1] :\n",
            "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
            "\n",
            "arr = [64, 34, 25, 12, 22, 11, 90]\n",
            "bubbleSort(arr)\n",
            "*********************************************\n",
            "\n",
            "def bubbleSort (arr ):\n",
            "    n =len (arr )\n",
            "    for i in range (0 ,n -1 ):\n",
            "        for j in range (0 ,n -i -i -i -i -1 ):\n",
            "            if arr [j ]>arr [j +1 ]:\n",
            "                arr [j +1 ],arr [j ],arr [j ]=arr [j +1 ]\n",
            "\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python program to check if a number is an Armstrong number.\n",
            "\n",
            "n=int(input(\"Enter any number: \"))\n",
            "a=list(map(int,str(n)))\n",
            "b=list(map(lambda x:x**3,a))\n",
            "\n",
            "if(sum(b)==n):\n",
            "    print(\"The number is an armstrong number. \")\n",
            "else:\n",
            "    print(\"The number isn't an arsmtrong number. \")\n",
            "*********************************************\n",
            "NoCode\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "# Write a python to find LCM of two numbers\n",
            "\n",
            "a=int(input(\"Enter the first number:\"))\n",
            "b=int(input(\"Enter the second number:\"))\n",
            "if(a>b):\n",
            "    min1=a\n",
            "else:\n",
            "    min1=b\n",
            "while(1):\n",
            "    if(min1%a==0 and min1%b==0):\n",
            "        print(\"LCM is:\",min1)\n",
            "        break\n",
            "        min1=min1+1\n",
            "*********************************************\n",
            "\n",
            "limit =0 \n",
            "\n",
            "while (c >0 ):\n",
            "    a =b \n",
            "    c =b =b \n",
            "    c =a +c \n",
            "    if (b >a else b %c ==0 ):\n",
            "        if (a ==0 ):\n",
            "            break \n",
            "    if (a ==0 ):\n",
            "        break \n",
            "    else :\n",
            "        print (\"LCM is:\",min1 )\n",
            "\n",
            "*******************END**************************\n",
            "*****************START****************************\n",
            "#Write a python program to find length of list using recursion\n",
            "\n",
            "def length(lst):\n",
            "    if not lst:\n",
            "        return 0\n",
            "    return 1 + length(lst[1::2]) + length(lst[2::2])\n",
            "a=[1,2,3]\n",
            "print(\"Length of the string is: \")\n",
            "print(a)\n",
            "*********************************************\n",
            "def add_two_numbers (num1 ,num2 ):\n",
            "    sum =num1 +num2 \n",
            "    return sum \n",
            "*******************END**************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEeqtSb8OGIr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "844cf3fe-d368-4527-84ac-97a8d14a118a"
      },
      "source": [
        "limit =0 \r\n",
        "\r\n",
        "while (c >0 ):\r\n",
        "    a =b \r\n",
        "    c =b =b \r\n",
        "    c =a +c \r\n",
        "    if (b >a else b %c ==0 ):\r\n",
        "        if (a ==0 ):\r\n",
        "            break \r\n",
        "    if (a ==0 ):\r\n",
        "        break \r\n",
        "    else :\r\n",
        "        print (\"LCM is:\",min1 )"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-225-d7923ff36823>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if (b >a else b %c ==0 ):\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aww8H4mEj7Zb",
        "outputId": "5e6b9fb5-81ab-4fa7-b17d-e906b569b05e"
      },
      "source": [
        "mean_key_val_diff({1:2, 3:4})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-bc08ed9439ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_key_val_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-96-2dfdc366ffca>\u001b[0m in \u001b[0;36mmean_key_val_diff\u001b[0;34m(input_dict)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msum_diff\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_dict\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msum_diff\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mabs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum_diff\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAVE6pwqdNxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a325eff9-e285-495f-82c1-5f19b25d337f"
      },
      "source": [
        "all_strings = nl_to_pl_df['docstring'].values\r\n",
        "for one_string in all_strings[100:149]:\r\n",
        "    cleaned_string = one_string.rstrip('\\n').lstrip('#')\r\n",
        "    mycode, attention_val = get_code(cleaned_string,auto_tokenizer, model, device, max_len=512)\r\n",
        "    print(cleaned_string)\r\n",
        "    print(auto_tokenizer.convert_tokens_to_string(mycode[:-1]))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-6951cadf7289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_strings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m149\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcleaned_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmycode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_string\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauto_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmycode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_code() missing 2 required positional arguments: 'model' and 'device'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWgi6c5dyPC"
      },
      "source": [
        "def even_odd_num(num):\r\n",
        "    max = 0\r\n",
        "    for num in num:\r\n",
        "         if num % 10 == 0:\r\n",
        "                 maxnum = num\r\n",
        "         return maxnum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G7TU847WEVV"
      },
      "source": [
        "even_odd_num(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzNkBY3S7owj"
      },
      "source": [
        "torch.save({\"model\":model.state_dict(),\r\n",
        "            \"optimizer\":optimizer.state_dict(),\r\n",
        "            \"loss\":1.373\r\n",
        "            },'end_capstone_baseline_128.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLGgHyMv8CTy"
      },
      "source": [
        "n = int(input(\"How many terms? \"))\r\n",
        "\r\n",
        "n1 = 0\r\n",
        "\r\n",
        "for i in range(n+1):\r\n",
        "    result = 0\r\n",
        "    for i in range(n2, n+1):\r\n",
        "        result = result + result*n2\r\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT1a37CF7tD4"
      },
      "source": [
        "!cp /content/end_capstone_baseline_128.pt /content/drive/MyDrive/EVA4/END_Capstone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fGMACkcqByC"
      },
      "source": [
        "a = [1, 2, 3, 4, 5]\r\n",
        "b = [5, 6, 7, 8]\r\n",
        "a.update(b)\r\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTPUPBz4qJki"
      },
      "source": [
        "a = {1, 2, 3}\r\n",
        "b = {3, 4, 5, 6}\r\n",
        "a = {1, 2, 2, 3, 4}\r\n",
        "x = a[i]*b for (a, b) in zip(a, b) )\r\n",
        "print(f\"{a}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUiEo5VBx1K6"
      },
      "source": [
        "def printSubArrays(arr, start, end):\r\n",
        "    if end == len(arr):\r\n",
        "        return\r\n",
        "    elif start > end:\r\n",
        "        return printSubArrays(arr, 0, end + 1)\r\n",
        "    else:\r\n",
        "            print(arr[start:end + 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6swZArv2CvL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}