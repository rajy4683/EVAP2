{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENDS7.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tp5IzBGsPGHs",
        "XJ6o_79ISSVb",
        "AKdllP3FST4N",
        "1AbsQwqkVyAy",
        "eXajorf5Xz7t",
        "LZgzB0ZkHVTI",
        "a5aeKuNCRGip",
        "pgSSIb9UCfE6"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/EVAP2/blob/master/ENDS7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYiRsFGD6iUC"
      },
      "source": [
        "# 0 TorchText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset Preview\n",
        "\n",
        "Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. \n",
        "\n",
        "We will be using previous session tweet dataset. Let's just preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f37f94d0-8e73-47f0-f302-eb9b65fb8728"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f680139-7946-4ef8-a71a-e4046281bea9"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511f0287-ee44-42ce-9f27-7714687648ce"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fc138a-0116-4575-f503-9a9917e3eddd"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, pickle\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f11cc59fb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxFPgAwR1SO4",
        "outputId": "4daf84cd-ea2b-4d09-d28e-f3b0e73c7d81"
      },
      "source": [
        "df.tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Obama has called the GOP budget social Darwini...\n",
              "1       In his teen years, Obama has been known to use...\n",
              "2       IPA Congratulates President Barack Obama for L...\n",
              "3       RT @Professor_Why: #WhatsRomneyHiding - his co...\n",
              "4       RT @wardollarshome: Obama has approved more ta...\n",
              "                              ...                        \n",
              "1359    @liberalminds Its trending idiot.. Did you loo...\n",
              "1360    RT @AstoldByBass: #KimKardashiansNextBoyfriend...\n",
              "1361    RT @GatorNation41: gas was $1.92 when Obama to...\n",
              "1362    @xShwag haha i know im just so smart, i mean y...\n",
              "1363    #OBAMA:  DICTATOR IN TRAINING.  If he passes t...\n",
              "Name: tweets, Length: 1364, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLs-uYGC2Znc"
      },
      "source": [
        "myexample = example[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpz4Camv2h26",
        "outputId": "9eccc04a-b4d7-4a0f-b19d-355d2b2ee646"
      },
      "source": [
        "myexample.tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Obama',\n",
              " 'has',\n",
              " 'called',\n",
              " 'the',\n",
              " 'GOP',\n",
              " 'budget',\n",
              " 'social',\n",
              " 'Darwinism',\n",
              " '.',\n",
              " 'Nice',\n",
              " 'try',\n",
              " ',',\n",
              " 'but',\n",
              " 'they',\n",
              " 'believe',\n",
              " 'in',\n",
              " 'social',\n",
              " 'creationism',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "#twitterDataset = data.TabularDataset(path=\"tweets.csv\", format=\"CSV\", fields=fields, skip_header=True)\n",
        "\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8hcS2lt2pIq",
        "outputId": "3008a6d2-79ae-4cd7-fdbf-f7c75af8643e"
      },
      "source": [
        "twitterDataset.fields"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': <torchtext.data.field.LabelField at 0x7fe776fc30b8>,\n",
              " 'tweets': <torchtext.data.field.Field at 0x7fe776fb0978>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training, testing, and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd4ce85-4983-4a9e-d7db-33ed980ba0d0"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kix8P2IKSBaV"
      },
      "source": [
        "An example from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51df0686-2d5e-4ca1-ff1a-db8e249b194d"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabu‐ lary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. \n",
        "\n",
        "Let’s limit the vocabulary to a maximum of 5000 words in our training set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyEeEjXTGhX"
      },
      "source": [
        "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a9800d-bfd8-43de-ba70-9eab64ad970a"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(<function _default_unk_index at 0x7fe776fd97b8>, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwjD2-ebTeUX"
      },
      "source": [
        "**Lots of stopwords!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PED4HJWH4t"
      },
      "source": [
        "We use the Embedding and LSTM modules in PyTorch to build a simple model for classifying tweets.\n",
        "\n",
        "In this model we create three layers. \n",
        "1. First, the words in our tweets are pushed into an Embedding layer, which we have established as a 300-dimensional vector embedding. \n",
        "2. That’s then fed into a 2 stacked-LSTMs with 100 hidden features (again, we’re compressing down from the 300-dimensional input like we did with images). We are using 2 LSTMs for using the dropout.\n",
        "3. Finally, the output of the LSTM (the final hidden state after processing the incoming tweet) is pushed through a standard fully connected layer with three outputs to correspond to our three possible classes (negative, positive, or neutral)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43pVRccMT0bT"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwBoGE_X_Fl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "933b9736-0fc0-4be3-cb57-810547c2c53f"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Tweet.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6053d15f1fab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msize_of_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_hidden_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_output_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tweet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-pOMqzJ3eTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b67c1b-d6ff-445d-9895-83420ae57a41"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,637,203 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXajorf5Xz7t"
      },
      "source": [
        "## Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrE9RpMtZ1Vs"
      },
      "source": [
        "First define the optimizer and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u86JWdlXvu5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "003fa1ad-7533-4d43-9c4a-54548d4e7fde"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-726bea2e65cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# define optimizer and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VCJtNb3Zt8w"
      },
      "source": [
        "The main thing to be aware of in this new training loop is that we have to reference `batch.tweets` and `batch.labels` to get the particular fields we’re interested in; they don’t fall out quite as nicely from the enumerator as they do in torchvision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WjEPLKsAiS_"
      },
      "source": [
        "**Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWNnGK3Y5oJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.labels)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZcHhkkvAsCt"
      },
      "source": [
        "**Evaluation Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHEe-zSVAriL"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "            acc = binary_accuracy(predictions, batch.labels)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6LJFW7HaJoV"
      },
      "source": [
        "**Let's Train and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq330XlnaEU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd841b2e-8fad-45dd-dae5-e20cc51ed93c"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.065 | Train Acc: 49.98%\n",
            "\t Val. Loss: 1.014 |  Val. Acc: 58.48% \n",
            "\n",
            "\tTrain Loss: 0.993 | Train Acc: 64.06%\n",
            "\t Val. Loss: 0.949 |  Val. Acc: 64.73% \n",
            "\n",
            "\tTrain Loss: 0.927 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.901 |  Val. Acc: 67.86% \n",
            "\n",
            "\tTrain Loss: 0.869 | Train Acc: 69.88%\n",
            "\t Val. Loss: 0.857 |  Val. Acc: 73.21% \n",
            "\n",
            "\tTrain Loss: 0.824 | Train Acc: 74.87%\n",
            "\t Val. Loss: 0.833 |  Val. Acc: 74.55% \n",
            "\n",
            "\tTrain Loss: 0.796 | Train Acc: 77.74%\n",
            "\t Val. Loss: 0.820 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 0.776 | Train Acc: 78.67%\n",
            "\t Val. Loss: 0.807 |  Val. Acc: 75.89% \n",
            "\n",
            "\tTrain Loss: 0.760 | Train Acc: 80.24%\n",
            "\t Val. Loss: 0.802 |  Val. Acc: 76.79% \n",
            "\n",
            "\tTrain Loss: 0.746 | Train Acc: 81.67%\n",
            "\t Val. Loss: 0.797 |  Val. Acc: 77.23% \n",
            "\n",
            "\tTrain Loss: 0.731 | Train Acc: 83.28%\n",
            "\t Val. Loss: 0.791 |  Val. Acc: 77.68% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZgzB0ZkHVTI"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZZfnWo0abRx"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTkHLEipIlM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33dc4632-e45b-4745-b57a-3ed5c80ac787"
      },
      "source": [
        "classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVjCuKK_LVEF"
      },
      "source": [
        "## Discussion on Data Augmentation Techniques \n",
        "\n",
        "You might wonder exactly how you can augment text data. After all, you can’t really flip it horizontally as you can an image! :D \n",
        "\n",
        "In contrast to data augmentation in images, augmentation techniques on data is very specific to final product you are building. As its general usage on any type of textual data doesn't provides a significant performance boost, that's why unlike torchvision, torchtext doesn’t offer a augmentation pipeline. Due to powerful models as transformers, augmentation tecnhiques are not so preferred now-a-days. But its better to know about some techniques with text that will provide your model with a little more information for training. \n",
        "\n",
        "### Synonym Replacement\n",
        "\n",
        "First, you could replace words in the sentence with synonyms, like so:\n",
        "\n",
        "    The dog slept on the mat\n",
        "\n",
        "could become\n",
        "\n",
        "    The dog slept on the rug\n",
        "\n",
        "Aside from the dog's insistence that a rug is much softer than a mat, the meaning of the sentence hasn’t changed. But mat and rug will be mapped to different indices in the vocabulary, so the model will learn that the two sentences map to the same label, and hopefully that there’s a connection between those two words, as everything else in the sentences is the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_uEfWJpL6Nq"
      },
      "source": [
        "### Random Insertion\n",
        "A random insertion technique looks at a sentence and then randomly inserts synonyms of existing non-stopwords into the sentence n times. Assuming you have a way of getting a synonym of a word and a way of eliminating stopwords (common words such as and, it, the, etc.), shown, but not implemented, in this function via get_synonyms() and get_stopwords(), an implementation of this would be as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Alm5D7WIvAC"
      },
      "source": [
        "def random_insertion(sentence, n): \n",
        "    words = remove_stopwords(sentence) \n",
        "    for _ in range(n):\n",
        "        new_synonym = get_synonyms(random.choice(words))\n",
        "        sentence.insert(randrange(len(sentence)+1), new_synonym) \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqLWzwJ3Mm8h"
      },
      "source": [
        "## Random Deletion\n",
        "As the name suggests, random deletion deletes words from a sentence. Given a probability parameter p, it will go through the sentence and decide whether to delete a word or not based on that random probability. Consider of it as pixel dropouts while treating images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Dz7JJfMqyC"
      },
      "source": [
        "def random_deletion(words, p=0.5): \n",
        "    if len(words) == 1: # return if single word\n",
        "        return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)] \n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOIbi5WzO5OU"
      },
      "source": [
        "### Random Swap\n",
        "The random swap augmentation takes a sentence and then swaps words within it n times, with each iteration working on the previously swapped sentence. Here we sample two random numbers based on the length of the sentence, and then just keep swapping until we hit n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnkbG15HO3Yj"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "599NpwfMR5Vm"
      },
      "source": [
        "For more on this please go through this [paper](https://arxiv.org/pdf/1901.11196.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5aeKuNCRGip"
      },
      "source": [
        "### Back Translation\n",
        "\n",
        "Another popular approach for augmenting text datasets is back translation. This involves translating a sentence from our target language into one or more other languages and then translating all of them back to the original language. We can use the Python library googletrans for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exHthzSl7Toc",
        "outputId": "b589b587-1536-449e-df74-0b928f5fbbfb"
      },
      "source": [
        "#!pip install googletrans==4.0.0-rc1\r\n",
        "!pip install googletrans==3.1.0a0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.11.8)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/3c/cdeaf9ab0404853e77c45d9e8021d0d2c01f70a1bb26e460090926fe2a5e/hstspreload-2020.11.21-py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Collecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hCollecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.3MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp36-none-any.whl size=16369 sha256=bac2c4e99d9b4a34af3ffc12c90f7431e9e1831682fc3a56876c8eb7440a6a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=8af25f2d88da725d254f117f253771b806e33808e1ecdd342e0a67c08d271f20\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: immutables, contextvars, sniffio, rfc3986, h11, hpack, hyperframe, h2, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.11.21 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhNBbYrRXNy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7273edc2-a9cb-416f-c273-4a0496c19bde"
      },
      "source": [
        "import random\n",
        "import googletrans\n",
        "#import googletrans.Translator as Translator\n",
        "\n",
        "translator = googletrans.Translator()\n",
        "sentence = ['The dog slept on the rug', 'ran lazily']\n",
        "\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "trans_lang = random.choice(available_langs) \n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")\n",
        "\n",
        "trans_lang"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translating to armenian\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSWT3GfLXQFP",
        "outputId": "19f4f304-9b0e-496a-f7e3-e5a4440ae899"
      },
      "source": [
        "sentence = ['The dog slept on the rug']\r\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \r\n",
        "trans_lang = random.choice(available_langs) \r\n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translating to kurdish (kurmanji)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ-w4wrZXbkv",
        "outputId": "7acc527b-28fe-46b5-ea36-76cafe40a73f"
      },
      "source": [
        "translations = translator.translate(sentence, dest=trans_lang) \r\n",
        "t_text = [t.text for t in translations]\r\n",
        "print(t_text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Kûçik li ser xalîçeyê razaye']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olh1nRRFaXAN",
        "outputId": "9f4f854b-ec43-460a-bfa9-7287c425c782"
      },
      "source": [
        "translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \r\n",
        "en_text = [t.text for t in translations_en_random]\r\n",
        "print(en_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The dog is lying on the carpet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dtTSj-_WdpV",
        "outputId": "a1a1b5ca-a481-49a5-e6f6-d47b4afaba4b"
      },
      "source": [
        "#!pip install google_trans_new\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_trans_new\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/7b/9f136106dc5824dc98185c97991d3cd9b53e70a197154dd49f7b899128f6/google_trans_new-1.1.9-py3-none-any.whl\n",
            "Installing collected packages: google-trans-new\n",
            "Successfully installed google-trans-new-1.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hySEELDSWz-E",
        "outputId": "fb2b9097-02f2-4fd0-85b9-0d244602e690"
      },
      "source": [
        "len(available_langs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgSSIb9UCfE6"
      },
      "source": [
        "### Stanford Sentiment Analysis TreeBank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbAG463onuka"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F9f_foJVovP"
      },
      "source": [
        "datasetSentences_df = pd.read_csv(\"/content/datasetSentences.txt\", sep=\"\\t\")\r\n",
        "dictionary_df = pd.read_csv(\"/content/dictionary.txt\", sep=\"|\", names=[\"Phrase\", \"Phrase_Id\"])\r\n",
        "sentiment_labels_df =  pd.read_csv(\"/content/sentiment_labels.txt\", sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KooNHbPA8Shk"
      },
      "source": [
        "datasetSentences_df[\"Phrase_Id\"] = 0\r\n",
        "datasetSentences_df[\"Sentiment_Score\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YJUA_5D05mQu",
        "outputId": "4ac63975-b926-4d37-c77a-48d35fd31632"
      },
      "source": [
        "common_sentences = datasetSentences_df[datasetSentences_df[\"sentence\"].isin(dictionary_df[\"Phrase\"])]\r\n",
        "common_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>Phrase_Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>11851</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>11852</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>11853</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>11854</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>11855</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>224044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11286 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... Phrase_Id\n",
              "0                   1  ...    224044\n",
              "1                   2  ...    224044\n",
              "2                   3  ...    224044\n",
              "3                   4  ...    224044\n",
              "4                   5  ...    224044\n",
              "...               ...  ...       ...\n",
              "11850           11851  ...    224044\n",
              "11851           11852  ...    224044\n",
              "11852           11853  ...    224044\n",
              "11853           11854  ...    224044\n",
              "11854           11855  ...    224044\n",
              "\n",
              "[11286 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa_kvxGJCsfC"
      },
      "source": [
        "### Create Dataframe to have sentiment scores and Full sentences together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Ce5A511in-"
      },
      "source": [
        "def sentence_exists(input_sentence):\r\n",
        "    #print(input_sentence)\r\n",
        "    matching_phrase = dictionary_df[dictionary_df[\"Phrase\"] == input_sentence][\"Phrase_Id\"].values\r\n",
        "    default_series = pd.Series({\"Phrase_Id\":-1000, \"Sentiment_Score\": -1000}) ## For cases where we dont find a full sentence match\r\n",
        "    if(len(matching_phrase)) > 0:\r\n",
        "        phrase_id = np.int(matching_phrase[0])\r\n",
        "        sentiment_value = sentiment_labels_df[sentiment_labels_df[\"phrase ids\"] == matching_phrase[0]][\"sentiment values\"].values[0]\r\n",
        "        default_series = pd.Series({\"Phrase_Id\":phrase_id, \"Sentiment_Score\": sentiment_value})\r\n",
        "\r\n",
        "    return default_series\r\n",
        "\r\n",
        "\r\n",
        "datasetSentences_df.loc[:, [\"Phrase_Id\", \"Sentiment_Score\"]] =  datasetSentences_df.loc[:,\"sentence\"].apply(sentence_exists)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW-XYN6z_JoR"
      },
      "source": [
        "datasetSentences_df[\"Phrase_Id\"] = datasetSentences_df[\"Phrase_Id\"].astype('int')\r\n",
        "datasetSentences_df = datasetSentences_df[datasetSentences_df[\"Phrase_Id\"] > 0].iloc[:,:-1]\r\n",
        "datasetSentences_df.to_csv(\"StanfordNLP.csv\",index=False, sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oiowfq8qEzut"
      },
      "source": [
        "new_df = pd.read_csv(\"/content/StanfordNLP.csv\",sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gGJm_8A1E7M5",
        "outputId": "8da00d10-65ff-4b59-8ff2-e2ef8ea01e67"
      },
      "source": [
        "new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>Phrase_Id</th>\n",
              "      <th>Sentiment_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166</td>\n",
              "      <td>0.69444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995</td>\n",
              "      <td>0.51389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123</td>\n",
              "      <td>0.73611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11281</th>\n",
              "      <td>11851</td>\n",
              "      <td>A real snooze .</td>\n",
              "      <td>222071</td>\n",
              "      <td>0.11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11282</th>\n",
              "      <td>11852</td>\n",
              "      <td>No surprises .</td>\n",
              "      <td>225165</td>\n",
              "      <td>0.22222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11283</th>\n",
              "      <td>11853</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "      <td>226985</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11284</th>\n",
              "      <td>11854</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "      <td>223632</td>\n",
              "      <td>0.13889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11285</th>\n",
              "      <td>11855</td>\n",
              "      <td>In this case zero .</td>\n",
              "      <td>224044</td>\n",
              "      <td>0.34722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11286 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... Sentiment_Score\n",
              "0                   1  ...         0.69444\n",
              "1                   2  ...         0.83333\n",
              "2                   3  ...         0.51389\n",
              "3                   4  ...         0.73611\n",
              "4                   5  ...         0.86111\n",
              "...               ...  ...             ...\n",
              "11281           11851  ...         0.11111\n",
              "11282           11852  ...         0.22222\n",
              "11283           11853  ...         0.75000\n",
              "11284           11854  ...         0.13889\n",
              "11285           11855  ...         0.34722\n",
              "\n",
              "[11286 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezrr6qPzw_zf"
      },
      "source": [
        "train_df = new_df.sample(frac = 0.8) \r\n",
        "test_df = new_df[~new_df.sentence_index.isin(train_df.sentence_index)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_k53AizE9ve"
      },
      "source": [
        "train_df.to_csv(\"StanTrain.csv\",index=False, sep=\"|\")\r\n",
        "test_df.to_csv(\"StanTest.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BxXNtloJ3sX"
      },
      "source": [
        "simpler_series_df = train_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2cJ5Zn7Ha-t"
      },
      "source": [
        "empty_series = { col:[] for col in train_df.columns.values}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mBCuFQZFh48"
      },
      "source": [
        "from eda import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z5bNdgpHMlg"
      },
      "source": [
        "my_new_df = pd.DataFrame(data=empty_series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NROdrAczHShF"
      },
      "source": [
        "my_new_df.loc[len(my_new_df)] = [1 , \"asdasd\", 111, 0.9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "iV4j_sO2JPmv",
        "outputId": "f60ee84e-b884-4d41-a6c9-5046ccdc17e7"
      },
      "source": [
        "my_new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>Phrase_Id</th>\n",
              "      <th>Sentiment_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [sentence_index, sentence, Phrase_Id, Sentiment_Score]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "kj1osMKRKygM",
        "outputId": "4e57109f-a492-44b5-8c73-47579c89c779"
      },
      "source": [
        "simpler_series_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>Phrase_Id</th>\n",
              "      <th>Sentiment_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6867</th>\n",
              "      <td>7189</td>\n",
              "      <td>` Lovely and Amazing , ' unhappily , is neithe...</td>\n",
              "      <td>151215</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10542</th>\n",
              "      <td>11074</td>\n",
              "      <td>A bland , obnoxious 88-minute infomercial for ...</td>\n",
              "      <td>221946</td>\n",
              "      <td>0.23611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7219</th>\n",
              "      <td>7562</td>\n",
              "      <td>Tries to add some spice to its quirky sentimen...</td>\n",
              "      <td>150502</td>\n",
              "      <td>0.29167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2446</th>\n",
              "      <td>2547</td>\n",
              "      <td>Functions as both a revealing look at the coll...</td>\n",
              "      <td>65700</td>\n",
              "      <td>0.63889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9645</th>\n",
              "      <td>10116</td>\n",
              "      <td>It 's hard to quibble with a flick boasting th...</td>\n",
              "      <td>224187</td>\n",
              "      <td>0.66667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3919</th>\n",
              "      <td>4100</td>\n",
              "      <td>Witty , contemplative , and sublimely beautiful .</td>\n",
              "      <td>71027</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6501</th>\n",
              "      <td>6802</td>\n",
              "      <td>Director Roger Michell does so many of the lit...</td>\n",
              "      <td>144877</td>\n",
              "      <td>0.41667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7141</th>\n",
              "      <td>7479</td>\n",
              "      <td>Made with no discernible craft and monstrously...</td>\n",
              "      <td>147300</td>\n",
              "      <td>0.22222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10484</th>\n",
              "      <td>11014</td>\n",
              "      <td>`` Not really as bad as you might think ! ''</td>\n",
              "      <td>227547</td>\n",
              "      <td>0.54167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7330</th>\n",
              "      <td>7684</td>\n",
              "      <td>If this disposable tissue has one wild card , ...</td>\n",
              "      <td>146206</td>\n",
              "      <td>0.58333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... Sentiment_Score\n",
              "6867             7189  ...         0.44444\n",
              "10542           11074  ...         0.23611\n",
              "7219             7562  ...         0.29167\n",
              "2446             2547  ...         0.63889\n",
              "9645            10116  ...         0.66667\n",
              "...               ...  ...             ...\n",
              "3919             4100  ...         0.83333\n",
              "6501             6802  ...         0.41667\n",
              "7141             7479  ...         0.22222\n",
              "10484           11014  ...         0.54167\n",
              "7330             7684  ...         0.58333\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qq5m2PuJqSC"
      },
      "source": [
        "simpler_series_df = train_df#simpler_series_df[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egdMkVnrGYXc"
      },
      "source": [
        "max_sentence_ids = simpler_series_df.sentence_index.max()\r\n",
        "alpha_sr = 0.0\r\n",
        "alpha_ri=0.0\r\n",
        "alpha_rs=0.2\r\n",
        "alpha_rd=0.2\r\n",
        "num_aug=5\r\n",
        "\r\n",
        "for idx in simpler_series_df.itertuples():\r\n",
        "    #parts = line[:-1].split('\\t')\r\n",
        "    #label = parts[0]\r\n",
        "    sentence = idx.sentence\r\n",
        "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug)\r\n",
        "    for aug_sentence in aug_sentences:\r\n",
        "        max_sentence_ids += 1\r\n",
        "        my_new_df.loc[len(my_new_df)] = [max_sentence_ids,aug_sentence, np.int(idx.Phrase_Id), idx.Sentiment_Score ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "X4O4P3uMLLxu",
        "outputId": "7edd4865-816c-4282-8754-1bfc2dac11f6"
      },
      "source": [
        "my_new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>Phrase_Id</th>\n",
              "      <th>Sentiment_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11855.0</td>\n",
              "      <td>and amazing is excessively strained contrived</td>\n",
              "      <td>151215.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11856.0</td>\n",
              "      <td>amazing and neither unhappily is lovely excess...</td>\n",
              "      <td>151215.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11857.0</td>\n",
              "      <td>neither and amazing contrived is lovely excess...</td>\n",
              "      <td>151215.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11858.0</td>\n",
              "      <td>lovely and unhappily is neither strained and c...</td>\n",
              "      <td>151215.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11859.0</td>\n",
              "      <td>lovely and amazing unhappily is neither excess...</td>\n",
              "      <td>151215.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45140</th>\n",
              "      <td>56995.0</td>\n",
              "      <td>not absolutely mention to refreshed</td>\n",
              "      <td>225210.0</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45141</th>\n",
              "      <td>56996.0</td>\n",
              "      <td>absolutely to mention not refreshed</td>\n",
              "      <td>225210.0</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45142</th>\n",
              "      <td>56997.0</td>\n",
              "      <td>not mention absolutely refreshed</td>\n",
              "      <td>225210.0</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45143</th>\n",
              "      <td>56998.0</td>\n",
              "      <td>not mention absolutely refreshed</td>\n",
              "      <td>225210.0</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45144</th>\n",
              "      <td>56999.0</td>\n",
              "      <td>not to mention absolutely refreshed</td>\n",
              "      <td>225210.0</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45145 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... Sentiment_Score\n",
              "0             11855.0  ...         0.44444\n",
              "1             11856.0  ...         0.44444\n",
              "2             11857.0  ...         0.44444\n",
              "3             11858.0  ...         0.44444\n",
              "4             11859.0  ...         0.44444\n",
              "...               ...  ...             ...\n",
              "45140         56995.0  ...         0.80556\n",
              "45141         56996.0  ...         0.80556\n",
              "45142         56997.0  ...         0.80556\n",
              "45143         56998.0  ...         0.80556\n",
              "45144         56999.0  ...         0.80556\n",
              "\n",
              "[45145 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axiiXzNcLXLc"
      },
      "source": [
        "my_new_df = my_new_df.sample(frac = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiTF2d7lND6X"
      },
      "source": [
        "my_new_df.to_csv(\"StanAugmented.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "B_-jxoBBNfdo",
        "outputId": "bfa84d85-7f02-493a-b821-81f1ff81738c"
      },
      "source": [
        "my_new_df.append(train_df,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>Phrase_Id</th>\n",
              "      <th>Sentiment_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34766.0</td>\n",
              "      <td>s performance confirms her once again</td>\n",
              "      <td>44733.0</td>\n",
              "      <td>0.88889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18024.0</td>\n",
              "      <td>what s the russian word for wow</td>\n",
              "      <td>227385.0</td>\n",
              "      <td>0.77778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23140.0</td>\n",
              "      <td>verve s stylishly directed with it</td>\n",
              "      <td>66669.0</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50084.0</td>\n",
              "      <td>without shakespeare s eloquent language the up...</td>\n",
              "      <td>111221.0</td>\n",
              "      <td>0.15278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28678.0</td>\n",
              "      <td>a de of cinema</td>\n",
              "      <td>103960.0</td>\n",
              "      <td>0.63889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54169</th>\n",
              "      <td>3075.0</td>\n",
              "      <td>This fascinating experiment plays as more of a...</td>\n",
              "      <td>70193.0</td>\n",
              "      <td>0.66667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54170</th>\n",
              "      <td>2645.0</td>\n",
              "      <td>Remove Spider-Man the movie from its red herri...</td>\n",
              "      <td>68393.0</td>\n",
              "      <td>0.66667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54171</th>\n",
              "      <td>1940.0</td>\n",
              "      <td>High Crimes knows the mistakes that bad movies...</td>\n",
              "      <td>45489.0</td>\n",
              "      <td>0.58333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54172</th>\n",
              "      <td>2642.0</td>\n",
              "      <td>The Bourne Identity should n't be half as ente...</td>\n",
              "      <td>69263.0</td>\n",
              "      <td>0.77778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54173</th>\n",
              "      <td>4930.0</td>\n",
              "      <td>Not to mention absolutely refreshed .</td>\n",
              "      <td>225210.0</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54174 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... Sentiment_Score\n",
              "0             34766.0  ...         0.88889\n",
              "1             18024.0  ...         0.77778\n",
              "2             23140.0  ...         0.75000\n",
              "3             50084.0  ...         0.15278\n",
              "4             28678.0  ...         0.63889\n",
              "...               ...  ...             ...\n",
              "54169          3075.0  ...         0.66667\n",
              "54170          2645.0  ...         0.66667\n",
              "54171          1940.0  ...         0.58333\n",
              "54172          2642.0  ...         0.77778\n",
              "54173          4930.0  ...         0.80556\n",
              "\n",
              "[54174 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-22-FX3Nq8X"
      },
      "source": [
        "my_new_df.to_csv(\"StanJoined.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cisw5RndXCX"
      },
      "source": [
        "## Training on Sentiment Tree Bank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOFwnI6UOp_H",
        "outputId": "da1ed85b-8315-4c3b-a2fb-52f50fdeb482"
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa8a4a57b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksdskX85vzOw"
      },
      "source": [
        "my_new_df = pd.read_csv(\"/content/StanJoined.csv\", sep=\"|\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOHPi0fgv74m"
      },
      "source": [
        "my_new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHlEZChnP6m7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2f7408-2fe9-47d9-f257-ac5b01aae4c0"
      },
      "source": [
        "np.floor(0.05 * 25)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ2v-NhkN5Un"
      },
      "source": [
        "my_new_df[\"label\"] = 0\r\n",
        "# def quantize_predictions(score_val):\r\n",
        "#     if(score_val >=0 and score_val <=0.2):\r\n",
        "#         return 0\r\n",
        "#     if(score_val > 0.2 and score_val <=0.4):\r\n",
        "#         return 1\r\n",
        "#     if(score_val > 0.4 and score_val <=0.6):\r\n",
        "#         return 2\r\n",
        "#     if(score_val > 0.6 and score_val <=0.8):\r\n",
        "#         return 3\r\n",
        "#     if(score_val > 0.8 and score_val <=1):\r\n",
        "#         return 4\r\n",
        "def quantize_predictions(score_val):\r\n",
        "    return np.floor(score_val * 24)\r\n",
        "\r\n",
        "\r\n",
        "my_new_df.loc[:,\"label\"] = my_new_df.loc[:,\"Sentiment_Score\"].apply(quantize_predictions)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJW5H6K_kMry",
        "outputId": "758ecaf7-a264-456c-ffec-80fc1d1fa4d1"
      },
      "source": [
        "my_new_df.Sentiment_Score.sort_values(ascending=True).values"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "LriAYlOmim2_",
        "outputId": "73bac21c-4dd9-409a-a1ff-46905917cf08"
      },
      "source": [
        "my_new_df.Sentiment_Score\r\n",
        "num_bins = 25\r\n",
        "   \r\n",
        "# n, bins, patches = plt.hist( my_new_df.Sentiment_Score.sort_values(ascending=True).values,num_bins,\r\n",
        "#                             density = 1,  \r\n",
        "#                             color ='green', \r\n",
        "#                             alpha = 0.7) \r\n",
        "colors = ['green']#, 'blue', 'lime'] \r\n",
        "plt.hist(my_new_df.label, density=False, bins=25,histtype ='bar',color = colors, \r\n",
        "         label = colors)\r\n",
        "#plt.hist(my_new_df.Sentiment_Score, density=False, bins=25,histtype ='bar')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 270.,  960.,  865., 1320., 2980., 1830., 2985., 3475., 1385.,\n",
              "        2095., 2430.,  875., 1990., 2085., 1255., 1815., 3420., 1970.,\n",
              "        3095., 3800., 1220., 1805.,  925.,  165.,  130.]),\n",
              " array([ 0.  ,  0.96,  1.92,  2.88,  3.84,  4.8 ,  5.76,  6.72,  7.68,\n",
              "         8.64,  9.6 , 10.56, 11.52, 12.48, 13.44, 14.4 , 15.36, 16.32,\n",
              "        17.28, 18.24, 19.2 , 20.16, 21.12, 22.08, 23.04, 24.  ]),\n",
              " <a list of 25 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQso6OxKm0f3"
      },
      "source": [
        "my_new_df[\"label\"] = my_new_df[\"label\"].astype(\"int\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1AYCNg5oJ5z",
        "outputId": "b9cc41d4-e435-4f8c-84af-70b2dea3a92b"
      },
      "source": [
        "my_new_df.label.min(),my_new_df.label.max()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 24)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKOVv6XSm-tY",
        "outputId": "c52655d8-3cec-49ac-8edb-f1fbc7a5155e"
      },
      "source": [
        "len(my_new_df.label.unique())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNMObsMAOp_H"
      },
      "source": [
        "Sentence = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkx_qhtSOp_I"
      },
      "source": [
        "fields = [('sentence', Sentence),('label',Label)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYOesmXLOp_I"
      },
      "source": [
        "#example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] \r\n",
        "\r\n",
        "\r\n",
        "example = [data.Example.fromlist([my_new_df.sentence[i],my_new_df.label[i]], fields) for i in range(my_new_df.shape[0])] \r\n",
        "# Creating dataset\r\n",
        "#twitterDataset = data.TabularDataset(path=\"tweets.csv\", format=\"CSV\", fields=fields, skip_header=True)\r\n",
        "\r\n",
        "stanTreeDataset = data.Dataset(example, fields)\r\n",
        "(train, valid) = stanTreeDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))\r\n",
        "Sentence.build_vocab(train)\r\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62b7mQk8nGEl",
        "outputId": "37a3723e-4b44-46f4-92f4-c52bf6dddbfe"
      },
      "source": [
        "my_new_df.label.max()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inR16u2oS9GN",
        "outputId": "b727aa94-496c-414a-8684-bf7ece8d33db"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38373, 6772)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSuQe1SdOp_J",
        "outputId": "c2cfdd71-1937-40e5-9f64-89aab34b5470"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  15467\n",
            "Size of label vocab :  25\n",
            "Top 10 words appreared repeatedly : [('the', 30132), ('a', 21887), ('and', 18213), ('of', 18037), ('to', 12704), ('is', 10626), ('s', 10595), ('it', 10241), ('in', 8033), ('that', 7840)]\n",
            "Labels :  defaultdict(<function _default_unk_index at 0x7fa8567d41e0>, {19: 0, 7: 1, 16: 2, 18: 3, 6: 4, 4: 5, 10: 6, 9: 7, 13: 8, 12: 9, 17: 10, 15: 11, 5: 12, 21: 13, 8: 14, 3: 15, 14: 16, 20: 17, 1: 18, 22: 19, 11: 20, 2: 21, 0: 22, 23: 23, 24: 24})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90pG8UVeOp_K"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0jhdBaPOp_K"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhFphxXlVpOA",
        "outputId": "f7665803-0ddd-4285-9355-b04f38fc9228"
      },
      "source": [
        "next(iter(train_iterator))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 32]\n",
              "\t[.sentence]:('[torch.cuda.LongTensor of size 32x16 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
              "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c329Bb1Op_K"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUuCywRNUSKv"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhvHOeOcUSK3"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Sentence.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = len(my_new_df.label.unique())\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXLJjEfyUSK3",
        "outputId": "2c96122e-4557-4b7b-e78d-03b995c24d90"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(15467, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=25, bias=True)\n",
            ")\n",
            "The model has 4,884,225 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdsJdHVUSK4"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzcEdCXdUSK4"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        sentence, sentence_lengths = batch.sentence\n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()  \n",
        "        #print(predictions)\n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL-t0228USK5"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sentence, sentence_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sentence, sentence_lengths).squeeze()\n",
        "            #print(predictions)\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7mISoENeRXU"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "     \r\n",
        "    # train the model\r\n",
        "    #train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion)\r\n",
        "\r\n",
        "\r\n",
        "    # evaluate the model\r\n",
        "    #valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    # save the best model\r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "    \r\n",
        "\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} %')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}  \\n')\r\n",
        "    #print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    #print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1dU0zfgUSK5",
        "outputId": "25bdbc2f-a455-4782-f868-edca4f46a703"
      },
      "source": [
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    #train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "\n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 2.848 | Train Acc: 44.65%\n",
            "\t Val. Loss: 2.904 |  Val. Acc: 39.61% \n",
            "\n",
            "\tTrain Loss: 2.827 | Train Acc: 46.99%\n",
            "\t Val. Loss: 2.889 |  Val. Acc: 41.07% \n",
            "\n",
            "\tTrain Loss: 2.806 | Train Acc: 49.00%\n",
            "\t Val. Loss: 2.875 |  Val. Acc: 42.77% \n",
            "\n",
            "\tTrain Loss: 2.789 | Train Acc: 50.51%\n",
            "\t Val. Loss: 2.871 |  Val. Acc: 42.87% \n",
            "\n",
            "\tTrain Loss: 2.777 | Train Acc: 51.52%\n",
            "\t Val. Loss: 2.852 |  Val. Acc: 44.81% \n",
            "\n",
            "\tTrain Loss: 2.764 | Train Acc: 52.70%\n",
            "\t Val. Loss: 2.842 |  Val. Acc: 45.60% \n",
            "\n",
            "\tTrain Loss: 2.749 | Train Acc: 54.38%\n",
            "\t Val. Loss: 2.835 |  Val. Acc: 46.71% \n",
            "\n",
            "\tTrain Loss: 2.734 | Train Acc: 55.84%\n",
            "\t Val. Loss: 2.818 |  Val. Acc: 48.12% \n",
            "\n",
            "\tTrain Loss: 2.722 | Train Acc: 56.79%\n",
            "\t Val. Loss: 2.810 |  Val. Acc: 48.67% \n",
            "\n",
            "\tTrain Loss: 2.712 | Train Acc: 57.69%\n",
            "\t Val. Loss: 2.799 |  Val. Acc: 49.89% \n",
            "\n",
            "\tTrain Loss: 2.698 | Train Acc: 59.20%\n",
            "\t Val. Loss: 2.786 |  Val. Acc: 51.13% \n",
            "\n",
            "\tTrain Loss: 2.684 | Train Acc: 60.55%\n",
            "\t Val. Loss: 2.783 |  Val. Acc: 51.67% \n",
            "\n",
            "\tTrain Loss: 2.673 | Train Acc: 61.51%\n",
            "\t Val. Loss: 2.777 |  Val. Acc: 51.96% \n",
            "\n",
            "\tTrain Loss: 2.662 | Train Acc: 62.65%\n",
            "\t Val. Loss: 2.760 |  Val. Acc: 53.97% \n",
            "\n",
            "\tTrain Loss: 2.646 | Train Acc: 64.65%\n",
            "\t Val. Loss: 2.744 |  Val. Acc: 55.83% \n",
            "\n",
            "\tTrain Loss: 2.626 | Train Acc: 66.74%\n",
            "\t Val. Loss: 2.732 |  Val. Acc: 57.17% \n",
            "\n",
            "\tTrain Loss: 2.608 | Train Acc: 68.53%\n",
            "\t Val. Loss: 2.720 |  Val. Acc: 58.60% \n",
            "\n",
            "\tTrain Loss: 2.591 | Train Acc: 70.34%\n",
            "\t Val. Loss: 2.708 |  Val. Acc: 59.43% \n",
            "\n",
            "\tTrain Loss: 2.577 | Train Acc: 71.67%\n",
            "\t Val. Loss: 2.696 |  Val. Acc: 60.60% \n",
            "\n",
            "\tTrain Loss: 2.563 | Train Acc: 72.90%\n",
            "\t Val. Loss: 2.682 |  Val. Acc: 62.20% \n",
            "\n",
            "\tTrain Loss: 2.554 | Train Acc: 73.70%\n",
            "\t Val. Loss: 2.674 |  Val. Acc: 62.79% \n",
            "\n",
            "\tTrain Loss: 2.544 | Train Acc: 74.52%\n",
            "\t Val. Loss: 2.668 |  Val. Acc: 63.13% \n",
            "\n",
            "\tTrain Loss: 2.537 | Train Acc: 75.07%\n",
            "\t Val. Loss: 2.658 |  Val. Acc: 64.04% \n",
            "\n",
            "\tTrain Loss: 2.530 | Train Acc: 75.81%\n",
            "\t Val. Loss: 2.653 |  Val. Acc: 64.78% \n",
            "\n",
            "\tTrain Loss: 2.524 | Train Acc: 76.41%\n",
            "\t Val. Loss: 2.646 |  Val. Acc: 65.28% \n",
            "\n",
            "\tTrain Loss: 2.517 | Train Acc: 76.98%\n",
            "\t Val. Loss: 2.644 |  Val. Acc: 65.51% \n",
            "\n",
            "\tTrain Loss: 2.511 | Train Acc: 77.56%\n",
            "\t Val. Loss: 2.635 |  Val. Acc: 66.40% \n",
            "\n",
            "\tTrain Loss: 2.503 | Train Acc: 78.45%\n",
            "\t Val. Loss: 2.629 |  Val. Acc: 66.95% \n",
            "\n",
            "\tTrain Loss: 2.493 | Train Acc: 79.54%\n",
            "\t Val. Loss: 2.617 |  Val. Acc: 68.44% \n",
            "\n",
            "\tTrain Loss: 2.482 | Train Acc: 80.65%\n",
            "\t Val. Loss: 2.612 |  Val. Acc: 68.80% \n",
            "\n",
            "\tTrain Loss: 2.472 | Train Acc: 81.69%\n",
            "\t Val. Loss: 2.602 |  Val. Acc: 69.84% \n",
            "\n",
            "\tTrain Loss: 2.463 | Train Acc: 82.54%\n",
            "\t Val. Loss: 2.598 |  Val. Acc: 70.20% \n",
            "\n",
            "\tTrain Loss: 2.457 | Train Acc: 83.12%\n",
            "\t Val. Loss: 2.592 |  Val. Acc: 71.06% \n",
            "\n",
            "\tTrain Loss: 2.449 | Train Acc: 83.84%\n",
            "\t Val. Loss: 2.586 |  Val. Acc: 71.63% \n",
            "\n",
            "\tTrain Loss: 2.441 | Train Acc: 84.77%\n",
            "\t Val. Loss: 2.582 |  Val. Acc: 72.17% \n",
            "\n",
            "\tTrain Loss: 2.432 | Train Acc: 85.76%\n",
            "\t Val. Loss: 2.569 |  Val. Acc: 73.38% \n",
            "\n",
            "\tTrain Loss: 2.422 | Train Acc: 86.78%\n",
            "\t Val. Loss: 2.561 |  Val. Acc: 73.99% \n",
            "\n",
            "\tTrain Loss: 2.412 | Train Acc: 87.69%\n",
            "\t Val. Loss: 2.552 |  Val. Acc: 75.04% \n",
            "\n",
            "\tTrain Loss: 2.403 | Train Acc: 88.57%\n",
            "\t Val. Loss: 2.544 |  Val. Acc: 75.82% \n",
            "\n",
            "\tTrain Loss: 2.395 | Train Acc: 89.36%\n",
            "\t Val. Loss: 2.538 |  Val. Acc: 76.79% \n",
            "\n",
            "\tTrain Loss: 2.388 | Train Acc: 90.03%\n",
            "\t Val. Loss: 2.532 |  Val. Acc: 77.10% \n",
            "\n",
            "\tTrain Loss: 2.382 | Train Acc: 90.62%\n",
            "\t Val. Loss: 2.530 |  Val. Acc: 77.47% \n",
            "\n",
            "\tTrain Loss: 2.377 | Train Acc: 91.10%\n",
            "\t Val. Loss: 2.521 |  Val. Acc: 78.20% \n",
            "\n",
            "\tTrain Loss: 2.373 | Train Acc: 91.50%\n",
            "\t Val. Loss: 2.529 |  Val. Acc: 77.44% \n",
            "\n",
            "\tTrain Loss: 2.368 | Train Acc: 91.98%\n",
            "\t Val. Loss: 2.510 |  Val. Acc: 79.25% \n",
            "\n",
            "\tTrain Loss: 2.364 | Train Acc: 92.29%\n",
            "\t Val. Loss: 2.504 |  Val. Acc: 79.85% \n",
            "\n",
            "\tTrain Loss: 2.361 | Train Acc: 92.52%\n",
            "\t Val. Loss: 2.500 |  Val. Acc: 79.95% \n",
            "\n",
            "\tTrain Loss: 2.359 | Train Acc: 92.74%\n",
            "\t Val. Loss: 2.501 |  Val. Acc: 80.00% \n",
            "\n",
            "\tTrain Loss: 2.357 | Train Acc: 92.93%\n",
            "\t Val. Loss: 2.503 |  Val. Acc: 79.61% \n",
            "\n",
            "\tTrain Loss: 2.354 | Train Acc: 93.20%\n",
            "\t Val. Loss: 2.497 |  Val. Acc: 80.21% \n",
            "\n",
            "\tTrain Loss: 2.353 | Train Acc: 93.34%\n",
            "\t Val. Loss: 2.490 |  Val. Acc: 80.78% \n",
            "\n",
            "\tTrain Loss: 2.350 | Train Acc: 93.55%\n",
            "\t Val. Loss: 2.485 |  Val. Acc: 81.36% \n",
            "\n",
            "\tTrain Loss: 2.349 | Train Acc: 93.69%\n",
            "\t Val. Loss: 2.484 |  Val. Acc: 81.30% \n",
            "\n",
            "\tTrain Loss: 2.347 | Train Acc: 93.89%\n",
            "\t Val. Loss: 2.478 |  Val. Acc: 81.98% \n",
            "\n",
            "\tTrain Loss: 2.345 | Train Acc: 94.02%\n",
            "\t Val. Loss: 2.478 |  Val. Acc: 81.95% \n",
            "\n",
            "\tTrain Loss: 2.344 | Train Acc: 94.16%\n",
            "\t Val. Loss: 2.473 |  Val. Acc: 82.50% \n",
            "\n",
            "\tTrain Loss: 2.343 | Train Acc: 94.29%\n",
            "\t Val. Loss: 2.491 |  Val. Acc: 80.87% \n",
            "\n",
            "\tTrain Loss: 2.341 | Train Acc: 94.46%\n",
            "\t Val. Loss: 2.469 |  Val. Acc: 82.83% \n",
            "\n",
            "\tTrain Loss: 2.339 | Train Acc: 94.60%\n",
            "\t Val. Loss: 2.466 |  Val. Acc: 83.19% \n",
            "\n",
            "\tTrain Loss: 2.338 | Train Acc: 94.71%\n",
            "\t Val. Loss: 2.464 |  Val. Acc: 83.27% \n",
            "\n",
            "\tTrain Loss: 2.337 | Train Acc: 94.81%\n",
            "\t Val. Loss: 2.470 |  Val. Acc: 82.55% \n",
            "\n",
            "\tTrain Loss: 2.337 | Train Acc: 94.87%\n",
            "\t Val. Loss: 2.463 |  Val. Acc: 83.25% \n",
            "\n",
            "\tTrain Loss: 2.336 | Train Acc: 94.99%\n",
            "\t Val. Loss: 2.463 |  Val. Acc: 83.33% \n",
            "\n",
            "\tTrain Loss: 2.335 | Train Acc: 95.09%\n",
            "\t Val. Loss: 2.457 |  Val. Acc: 84.14% \n",
            "\n",
            "\tTrain Loss: 2.333 | Train Acc: 95.20%\n",
            "\t Val. Loss: 2.454 |  Val. Acc: 84.22% \n",
            "\n",
            "\tTrain Loss: 2.332 | Train Acc: 95.29%\n",
            "\t Val. Loss: 2.452 |  Val. Acc: 84.45% \n",
            "\n",
            "\tTrain Loss: 2.331 | Train Acc: 95.44%\n",
            "\t Val. Loss: 2.450 |  Val. Acc: 84.50% \n",
            "\n",
            "\tTrain Loss: 2.331 | Train Acc: 95.49%\n",
            "\t Val. Loss: 2.455 |  Val. Acc: 84.09% \n",
            "\n",
            "\tTrain Loss: 2.330 | Train Acc: 95.57%\n",
            "\t Val. Loss: 2.447 |  Val. Acc: 84.76% \n",
            "\n",
            "\tTrain Loss: 2.329 | Train Acc: 95.62%\n",
            "\t Val. Loss: 2.446 |  Val. Acc: 84.87% \n",
            "\n",
            "\tTrain Loss: 2.328 | Train Acc: 95.66%\n",
            "\t Val. Loss: 2.444 |  Val. Acc: 85.34% \n",
            "\n",
            "\tTrain Loss: 2.328 | Train Acc: 95.69%\n",
            "\t Val. Loss: 2.453 |  Val. Acc: 84.15% \n",
            "\n",
            "\tTrain Loss: 2.328 | Train Acc: 95.72%\n",
            "\t Val. Loss: 2.441 |  Val. Acc: 85.58% \n",
            "\n",
            "\tTrain Loss: 2.327 | Train Acc: 95.79%\n",
            "\t Val. Loss: 2.438 |  Val. Acc: 85.71% \n",
            "\n",
            "\tTrain Loss: 2.327 | Train Acc: 95.80%\n",
            "\t Val. Loss: 2.439 |  Val. Acc: 85.75% \n",
            "\n",
            "\tTrain Loss: 2.327 | Train Acc: 95.83%\n",
            "\t Val. Loss: 2.452 |  Val. Acc: 84.36% \n",
            "\n",
            "\tTrain Loss: 2.327 | Train Acc: 95.82%\n",
            "\t Val. Loss: 2.441 |  Val. Acc: 85.45% \n",
            "\n",
            "\tTrain Loss: 2.326 | Train Acc: 95.88%\n",
            "\t Val. Loss: 2.436 |  Val. Acc: 85.88% \n",
            "\n",
            "\tTrain Loss: 2.326 | Train Acc: 95.90%\n",
            "\t Val. Loss: 2.430 |  Val. Acc: 86.35% \n",
            "\n",
            "\tTrain Loss: 2.326 | Train Acc: 95.93%\n",
            "\t Val. Loss: 2.430 |  Val. Acc: 86.52% \n",
            "\n",
            "\tTrain Loss: 2.325 | Train Acc: 95.95%\n",
            "\t Val. Loss: 2.431 |  Val. Acc: 86.24% \n",
            "\n",
            "\tTrain Loss: 2.325 | Train Acc: 95.99%\n",
            "\t Val. Loss: 2.437 |  Val. Acc: 85.94% \n",
            "\n",
            "\tTrain Loss: 2.325 | Train Acc: 96.03%\n",
            "\t Val. Loss: 2.435 |  Val. Acc: 86.04% \n",
            "\n",
            "\tTrain Loss: 2.324 | Train Acc: 96.09%\n",
            "\t Val. Loss: 2.431 |  Val. Acc: 86.39% \n",
            "\n",
            "\tTrain Loss: 2.324 | Train Acc: 96.08%\n",
            "\t Val. Loss: 2.431 |  Val. Acc: 86.23% \n",
            "\n",
            "\tTrain Loss: 2.323 | Train Acc: 96.14%\n",
            "\t Val. Loss: 2.427 |  Val. Acc: 86.61% \n",
            "\n",
            "\tTrain Loss: 2.323 | Train Acc: 96.18%\n",
            "\t Val. Loss: 2.435 |  Val. Acc: 85.92% \n",
            "\n",
            "\tTrain Loss: 2.323 | Train Acc: 96.17%\n",
            "\t Val. Loss: 2.428 |  Val. Acc: 86.72% \n",
            "\n",
            "\tTrain Loss: 2.323 | Train Acc: 96.23%\n",
            "\t Val. Loss: 2.423 |  Val. Acc: 87.10% \n",
            "\n",
            "\tTrain Loss: 2.322 | Train Acc: 96.28%\n",
            "\t Val. Loss: 2.424 |  Val. Acc: 86.95% \n",
            "\n",
            "\tTrain Loss: 2.322 | Train Acc: 96.29%\n",
            "\t Val. Loss: 2.428 |  Val. Acc: 86.79% \n",
            "\n",
            "\tTrain Loss: 2.321 | Train Acc: 96.36%\n",
            "\t Val. Loss: 2.426 |  Val. Acc: 86.75% \n",
            "\n",
            "\tTrain Loss: 2.321 | Train Acc: 96.40%\n",
            "\t Val. Loss: 2.421 |  Val. Acc: 87.26% \n",
            "\n",
            "\tTrain Loss: 2.321 | Train Acc: 96.43%\n",
            "\t Val. Loss: 2.417 |  Val. Acc: 87.49% \n",
            "\n",
            "\tTrain Loss: 2.320 | Train Acc: 96.46%\n",
            "\t Val. Loss: 2.416 |  Val. Acc: 87.77% \n",
            "\n",
            "\tTrain Loss: 2.320 | Train Acc: 96.49%\n",
            "\t Val. Loss: 2.419 |  Val. Acc: 87.51% \n",
            "\n",
            "\tTrain Loss: 2.321 | Train Acc: 96.46%\n",
            "\t Val. Loss: 2.422 |  Val. Acc: 87.14% \n",
            "\n",
            "\tTrain Loss: 2.320 | Train Acc: 96.50%\n",
            "\t Val. Loss: 2.421 |  Val. Acc: 87.09% \n",
            "\n",
            "\tTrain Loss: 2.320 | Train Acc: 96.53%\n",
            "\t Val. Loss: 2.418 |  Val. Acc: 87.39% \n",
            "\n",
            "\tTrain Loss: 2.319 | Train Acc: 96.55%\n",
            "\t Val. Loss: 2.421 |  Val. Acc: 87.20% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr_GawnZUSK5"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}