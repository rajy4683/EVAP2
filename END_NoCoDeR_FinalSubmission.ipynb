{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "END_NoCoDeR_FinalSubmission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/EVAP2/blob/master/END_NoCoDeR_FinalSubmission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOdNYOq_V5C3",
        "outputId": "06e8de38-f82a-4a53-aacc-bd29c00b6a76"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar 21 16:29:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4uN4sSQlA7w"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fileinput\n",
        "import re\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML\n",
        "#import seaborn as sns\n",
        "import dateutil.parser\n",
        "import datetime\n",
        "#from ipyfilechooser import FileChooser\n",
        "import numpy as np\n",
        "import os\n",
        "import gzip\n",
        "import dateutil.parser\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import glob\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import timedelta\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import json\n",
        "import random\n",
        "import spacy\n",
        "from pprint import pprint\n",
        "import six\n",
        "import sys, token, tokenize\n",
        "import ast\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "#from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm, trange\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzTyfBvwcT50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a003bcae-c32c-42f4-e151-be9a3dddeced"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRNwGADTvOuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c66425-a56f-47ab-bb6b-b7dab2eabc76"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install rouge-score"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.10.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6XDZbeWK6u_"
      },
      "source": [
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
        "import tokenize"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqKpFyhplfvZ"
      },
      "source": [
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/english_python_data.txt .\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/english_python_cleaned.txt .\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone.csv ."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGoF0UiKmLg-"
      },
      "source": [
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "auto_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "# spacy_en = spacy.load('en')\n",
        "# def tokenize_en(text):\n",
        "#     \"\"\"\n",
        "#     Tokenizes English text from a string into a list of strings\n",
        "#     \"\"\"\n",
        "#     return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "# #model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "# #model.to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdKei8f1klw8"
      },
      "source": [
        "#### Function to remove docstrings and comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NPC5Tjn-eHe"
      },
      "source": [
        "\"\"\"\n",
        "    Removes docstrings and comments\n",
        "\"\"\"\n",
        "def remove_docstrings_comments(src_string, doc_string=None, debug=False):\n",
        "    mod = []\n",
        "\n",
        "    prev_toktype = token.INDENT\n",
        "    first_line = None\n",
        "    last_lineno = -1\n",
        "    last_col = 0\n",
        "    try:\n",
        "        #tokgen = tokenize.generate_tokens(source.readline)\n",
        "        tokgen = tokenize.generate_tokens(six.StringIO(src_string.rstrip()).readline)\n",
        "        for toktype, ttext, (slineno, scol), (elineno, ecol), ltext in tokgen:\n",
        "            if 0:   # Change to if 1 to see the tokens fly by.\n",
        "                print(\"%10s %-14s %-20r %r\" % (\n",
        "                    tokenize.tok_name.get(toktype, toktype),\n",
        "                    \"%d.%d-%d.%d\" % (slineno, scol, elineno, ecol),\n",
        "                    ttext, ltext\n",
        "                    ))\n",
        "            if slineno > last_lineno:\n",
        "                last_col = 0\n",
        "            if scol > last_col:\n",
        "                mod.append(\" \" * (scol - last_col))\n",
        "            if toktype == token.STRING and prev_toktype == token.INDENT:\n",
        "                # Docstring\n",
        "                mod.append(\"#--\")\n",
        "            elif toktype == tokenize.COMMENT:\n",
        "                # Comment\n",
        "                mod.append(\"##\")\n",
        "            else:\n",
        "                mod.append(ttext)\n",
        "            prev_toktype = toktype\n",
        "            last_col = ecol\n",
        "            last_lineno = elineno\n",
        "        return \"\".join(mod)\n",
        "    except:\n",
        "        print(doc_string)\n",
        "        print(src_string )\n",
        "        print(sys.exc_info())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c35HYbYxWBk7"
      },
      "source": [
        "We load the data from CSV file which contains the docstring, code, docstring_len, code_len, cleaned_code and cleaned_code_len"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nobKWg_DJ5Xp"
      },
      "source": [
        "nl_to_pl_df = pd.read_csv('/content/end_capstone.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prv7EIAX5aOj"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR7nruWfNQNB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "998f0587-da8a-411e-ad09-2abb124136ef"
      },
      "source": [
        "print(nl_to_pl_df['code_len'].max(),nl_to_pl_df['code_len'].min())\n",
        "print(nl_to_pl_df['docstring_len'].max(),nl_to_pl_df['docstring_len'].min())\n",
        "nl_to_pl_df[nl_to_pl_df['code_len'] ==0]\n",
        "nl_to_pl_df[(nl_to_pl_df['code_len'] > 256) & (nl_to_pl_df['code_len'] < 512)] "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2443 11\n",
            "313 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docstring</th>\n",
              "      <th>code</th>\n",
              "      <th>docstring_len</th>\n",
              "      <th>code_len</th>\n",
              "      <th>cleaned_code</th>\n",
              "      <th>cleaned_code_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td># Write a program to check whether a number is...</td>\n",
              "      <td>num = 337\\n\\nif num &gt; 1:\\n    for i in range(2...</td>\n",
              "      <td>60</td>\n",
              "      <td>311</td>\n",
              "      <td>num = 337\\n\\nif num &gt; 1:\\n    for i in range(2...</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td># Write a program to find the factorial of a n...</td>\n",
              "      <td>num = 13\\nfactorial = 1\\n\\nif num &lt; 0:\\n    pr...</td>\n",
              "      <td>52</td>\n",
              "      <td>265</td>\n",
              "      <td>num = 13\\nfactorial = 1\\n\\nif num &lt; 0:\\n    pr...</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td># Write a function that takes in height(m) and...</td>\n",
              "      <td>\\ndef bmi(height: \"Meters\", weight: \"Kgs\"):\\n ...</td>\n",
              "      <td>98</td>\n",
              "      <td>450</td>\n",
              "      <td>\\ndef bmi(height: \"Meters\", weight: \"Kgs\"):\\n ...</td>\n",
              "      <td>447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td># write a python program to sort dictionary it...</td>\n",
              "      <td>dict1 = {'car': [7, 6, 3],  \\n        'bike': ...</td>\n",
              "      <td>50</td>\n",
              "      <td>262</td>\n",
              "      <td>dict1 = {'car': [7, 6, 3],  \\n        'bike': ...</td>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td># write a python program to Get the maximum an...</td>\n",
              "      <td>\\nmy_dict = {'x':500, 'y':5874, 'z': 560}\\n\\nk...</td>\n",
              "      <td>78</td>\n",
              "      <td>276</td>\n",
              "      <td>\\nmy_dict = {'x':500, 'y':5874, 'z': 560}\\n\\nk...</td>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4352</th>\n",
              "      <td># Define a class named Shape and its subclass ...</td>\n",
              "      <td>\\n\\nclass Shape(object):\\n    def __init__(sel...</td>\n",
              "      <td>234</td>\n",
              "      <td>314</td>\n",
              "      <td>\\n\\nclass Shape(object):\\n    def __init__(sel...</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4354</th>\n",
              "      <td># Write a python program for a binary search f...</td>\n",
              "      <td>import math\\ndef bin_search(li, element):\\n   ...</td>\n",
              "      <td>171</td>\n",
              "      <td>390</td>\n",
              "      <td>import math\\ndef bin_search(li, element):\\n   ...</td>\n",
              "      <td>388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4359</th>\n",
              "      <td># Write a python program to check if a number ...</td>\n",
              "      <td>n = int(input(\"Enter any number: \"))\\nsum1 = 0...</td>\n",
              "      <td>67</td>\n",
              "      <td>261</td>\n",
              "      <td>n = int(input(\"Enter any number: \"))\\nsum1 = 0...</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4360</th>\n",
              "      <td># Write a python program to Check if a Number ...</td>\n",
              "      <td>sum1 = 0\\nnum = int(input(\"Enter a number:\"))\\...</td>\n",
              "      <td>65</td>\n",
              "      <td>347</td>\n",
              "      <td>sum1 = 0\\nnum = int(input(\"Enter a number:\"))\\...</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4362</th>\n",
              "      <td># Write python program to find whether-number-...</td>\n",
              "      <td>def is_power_of_two(n):\\n    \"\"\"Return True if...</td>\n",
              "      <td>56</td>\n",
              "      <td>310</td>\n",
              "      <td>def is_power_of_two(n):\\n    #--\\n    if n &lt;= ...</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>613 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              docstring  ... cleaned_code_len\n",
              "5     # Write a program to check whether a number is...  ...              308\n",
              "7     # Write a program to find the factorial of a n...  ...              262\n",
              "53    # Write a function that takes in height(m) and...  ...              447\n",
              "62    # write a python program to sort dictionary it...  ...              260\n",
              "74    # write a python program to Get the maximum an...  ...              274\n",
              "...                                                 ...  ...              ...\n",
              "4352  # Define a class named Shape and its subclass ...  ...              312\n",
              "4354  # Write a python program for a binary search f...  ...              388\n",
              "4359  # Write a python program to check if a number ...  ...              259\n",
              "4360  # Write a python program to Check if a Number ...  ...              345\n",
              "4362  # Write python program to find whether-number-...  ...              270\n",
              "\n",
              "[613 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJUyE3S39KWy"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # if n_gpu > 0:\n",
        "    #     torch.cuda.manual_seed_all(seed)\n",
        "set_seed(0x1112233)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBDY67cXevhg"
      },
      "source": [
        "!cp -rf /content/drive/MyDrive/EVA4/END_Capstone/cubert .\n",
        "!pip install -r /content/cubert/requirements.txt\n",
        "sys.path.append(\"/content/cubert/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-xKQk6kXhU7"
      },
      "source": [
        "### CuBert Tokenizer\n",
        "\n",
        "PythonTokenizer2 is a subclass of [CuBertTokenizer](https://github.com/google-research/google-research/tree/master/cubert). It is capable of tokenizing both Python2.x and Python3.x snippets.\n",
        "\n",
        "It implements two basic methods:\n",
        "\n",
        "\n",
        "*   tokenize_and_abstract: Converts a code snippet to relevant tokens with special tokens marked accordingly\n",
        "*   untokenize_abstract: Useful for forming actual code from an array/list of tokens. Throws Exception if there are no proper EOS/ENDMARKER.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3k4UAjKgagA"
      },
      "source": [
        "\"\"\"A Python tokenizer subclass of CuBertTokenizer.\"\"\"\n",
        "import keyword\n",
        "import re\n",
        "import tokenize\n",
        "import typing\n",
        "from typing import Any\n",
        "from typing import List\n",
        "from typing import Sequence\n",
        "from typing import Tuple\n",
        "from absl import logging\n",
        "from cubert import cubert_tokenizer\n",
        "from cubert import unified_tokenizer\n",
        "\n",
        "\n",
        "class PythonTokenizer2(cubert_tokenizer.CuBertTokenizer):\n",
        "  \"\"\"Tokenizer that extracts Python's lexical elements preserving strings.\"\"\"\n",
        "  _TOKEN_TYPE_MAP = {\n",
        "      tokenize.COMMENT: unified_tokenizer.TokenKind.COMMENT,\n",
        "      tokenize.DEDENT: unified_tokenizer.TokenKind.KEYWORD,\n",
        "      tokenize.ENDMARKER: unified_tokenizer.TokenKind.EOS,\n",
        "      tokenize.ERRORTOKEN: unified_tokenizer.TokenKind.ERROR,\n",
        "      tokenize.INDENT: unified_tokenizer.TokenKind.KEYWORD,\n",
        "      tokenize.NEWLINE: unified_tokenizer.TokenKind.NEWLINE,\n",
        "      tokenize.NL: unified_tokenizer.TokenKind.PUNCTUATION,\n",
        "      tokenize.NUMBER: unified_tokenizer.TokenKind.NUMBER,\n",
        "      tokenize.OP: unified_tokenizer.TokenKind.PUNCTUATION,\n",
        "      tokenize.STRING: unified_tokenizer.TokenKind.STRING,\n",
        "  }\n",
        "  _REVERSE_TOKEN_MAP = {\n",
        "      cubert_tokenizer.token_from_token_type(tokenize.INDENT):\n",
        "          tokenize.INDENT,\n",
        "      cubert_tokenizer.token_from_token_type(tokenize.DEDENT):\n",
        "          tokenize.DEDENT,\n",
        "      unified_tokenizer.quote_special(unified_tokenizer.TokenKind.EOS.name):\n",
        "          tokenize.ENDMARKER,\n",
        "      unified_tokenizer.quote_special(unified_tokenizer.TokenKind.ERROR.name):\n",
        "          tokenize.ERRORTOKEN,\n",
        "      unified_tokenizer.quote_special(unified_tokenizer.TokenKind.NEWLINE.name):\n",
        "          tokenize.NEWLINE,\n",
        "      cubert_tokenizer.token_from_token_type(tokenize.NL):\n",
        "          tokenize.NL,\n",
        "  }\n",
        "  # Adding the end-of-string anchor \\Z below, since re.fullmatch wasn't\n",
        "  # available in Python2.\n",
        "  _NUMBERS = re.compile('(' + tokenize.Number + r')\\Z')  # pytype: disable=module-attr\n",
        "  _SINGLE_STRINGS = re.compile('(' + tokenize.String + r')\\Z')  # pytype: disable=module-attr\n",
        "  _TRIPLE_STRING_BEGINNINGS = re.compile(tokenize.Triple)  # pytype: disable=module-attr\n",
        "  _COMMENTS = re.compile('(' + tokenize.Comment + r')\\Z')  # pytype: disable=module-attr\n",
        "\n",
        "  _EXACT_TOKEN_TYPES = tokenize.EXACT_TOKEN_TYPES.keys()  # pytype: disable=module-attr\n",
        "\n",
        "  # Token types that CubertTokenizer will tokenize by their type and not\n",
        "  # content.\n",
        "  _TOKEN_TYPES_TO_TOKENIZE_BY_TYPE = [\n",
        "      tokenize.NEWLINE, tokenize.DEDENT, tokenize.NL\n",
        "  ]\n",
        "\n",
        "  def tokenize_and_abstract(\n",
        "      self,\n",
        "      source_code):\n",
        "    \"\"\"Produces a language-agnostic tokenization of the input code.\"\"\"\n",
        "    agnostic_tokens: List[unified_tokenizer.AbstractToken] = []\n",
        "\n",
        "    try:\n",
        "      token_tuples = unified_tokenizer.code_to_tokens(source_code)\n",
        "    except (tokenize.TokenError, IndentationError) as e:\n",
        "      logging.warning('The tokenizer raised exception `%s` while parsing %s', e,\n",
        "                      source_code)\n",
        "\n",
        "      # We don't try to do recovery from errors quite yet. Emit just an\n",
        "      # error and end-of-sequence and return.\n",
        "      agnostic_tokens.append(\n",
        "          unified_tokenizer.AbstractToken(\n",
        "              unified_tokenizer.quote_special(\n",
        "                  unified_tokenizer.TokenKind.ERROR.name),\n",
        "              unified_tokenizer.TokenKind.ERROR,\n",
        "              unified_tokenizer.TokenMetadata(\n",
        "                  start=unified_tokenizer.Position(\n",
        "                      line=0, column=0),\n",
        "                  end=unified_tokenizer.Position(\n",
        "                      line=0, column=0))))\n",
        "      agnostic_tokens.append(\n",
        "          unified_tokenizer.AbstractToken(\n",
        "              unified_tokenizer.quote_special(\n",
        "                  unified_tokenizer.TokenKind.EOS.name),\n",
        "              unified_tokenizer.TokenKind.EOS,\n",
        "              unified_tokenizer.TokenMetadata(\n",
        "                  start=unified_tokenizer.Position(\n",
        "                      line=0, column=0),\n",
        "                  end=unified_tokenizer.Position(\n",
        "                      line=0, column=0))))\n",
        "      return agnostic_tokens\n",
        "\n",
        "    for token_tuple in token_tuples:\n",
        "      spelling = token_tuple.string\n",
        "      kind = token_tuple.type\n",
        "\n",
        "      # We'll adjust the spelling of some tokens, e.g., those that we\n",
        "      # tokenize by their type rather than their original spelling. Indentation\n",
        "      # and dedentation tokens are like that.\n",
        "      adjusted_spelling = spelling\n",
        "      token_kind = unified_tokenizer.TokenKind.NONE\n",
        "      if kind == tokenize.NAME:\n",
        "        # Disambiguate identifiers from keywords.\n",
        "        if keyword.iskeyword(spelling):\n",
        "          token_kind = unified_tokenizer.TokenKind.KEYWORD\n",
        "        else:\n",
        "          token_kind = unified_tokenizer.TokenKind.IDENTIFIER\n",
        "      else:\n",
        "        if kind in PythonTokenizer2._TOKEN_TYPES_TO_TOKENIZE_BY_TYPE:\n",
        "          # Replace spelling with type.\n",
        "          adjusted_spelling = cubert_tokenizer.token_from_token_type(kind)\n",
        "        elif kind is tokenize.INDENT:\n",
        "          # For INDENT, in particular, we also record the actual spelling too.\n",
        "          adjusted_spelling = '{indent}{spelling}'.format(\n",
        "              indent=cubert_tokenizer.token_from_token_type(kind),\n",
        "              spelling=spelling)\n",
        "          #print(adjusted_spelling)\n",
        "        elif kind == tokenize.ENDMARKER:\n",
        "          adjusted_spelling = unified_tokenizer.quote_special(\n",
        "              unified_tokenizer.TokenKind.EOS.name)\n",
        "\n",
        "        # Map everything according to table.\n",
        "        try:\n",
        "          token_kind = PythonTokenizer2._TOKEN_TYPE_MAP[kind]\n",
        "        except KeyError as ke:\n",
        "          # It's possible we're here because of async/await. Those kept being\n",
        "          # turned into keywords and then removed from keywords, so we can't\n",
        "          # rely on knowing which they are. We'll check by spelling.\n",
        "          # See: https://bugs.python.org/issue30406\n",
        "          # and https://bugs.python.org/issue33260\n",
        "          # and https://bugs.python.org/issue35975\n",
        "          if spelling in ('async', 'await'):\n",
        "            token_kind = unified_tokenizer.TokenKind.KEYWORD\n",
        "          else:\n",
        "            raise ValueError('While trying to turn Python token %r into an '\n",
        "                             'agnostic one, raised %r.' %\n",
        "                             ((spelling, kind), ke))\n",
        "\n",
        "      start_line, start_column = token_tuple.start\n",
        "      end_line, end_column = token_tuple.end\n",
        "      # Unlike other languages, NEWLINE tokens are reported as ending on the\n",
        "      # same line as where they started. We adjust that here, to stick to the\n",
        "      # same convention as other tokenizers.\n",
        "      if ((token_kind == unified_tokenizer.TokenKind.NEWLINE) or\n",
        "          (kind == tokenize.NL)):\n",
        "        end_line = start_line + 1\n",
        "        end_column = 0\n",
        "\n",
        "      agnostic_tokens.append(\n",
        "          unified_tokenizer.AbstractToken(\n",
        "              spelling=adjusted_spelling, kind=token_kind,\n",
        "              metadata=unified_tokenizer.TokenMetadata(\n",
        "                  # Python's tokenizer counts lines starting from 1, so we\n",
        "                  # have to offset what we read from the `TokenInfo` tuple.\n",
        "                  start=unified_tokenizer.Position(\n",
        "                      line=start_line - 1, column=start_column),\n",
        "                  end=unified_tokenizer.Position(\n",
        "                      line=end_line - 1, column=end_column))))\n",
        "    #print(agnostic_tokens)\n",
        "    return agnostic_tokens\n",
        "\n",
        "  def untokenize_abstract(self, whole_tokens):\n",
        "    # Reconstruct Python tokenizer tuples, so that Python's untokenize can be\n",
        "    # invoked.\n",
        "    token_tuples: List[Tuple[int, str]] = []\n",
        "\n",
        "    for whole_token in whole_tokens:\n",
        "      if whole_token in PythonTokenizer2._EXACT_TOKEN_TYPES:\n",
        "        token_tuples.append((tokenize.OP, whole_token))\n",
        "      elif cubert_tokenizer.token_from_token_type(\n",
        "          tokenize.INDENT) in whole_token:\n",
        "        # We baked the type and spelling into one token. Break them up.\n",
        "        spelling = whole_token.replace(\n",
        "            cubert_tokenizer.token_from_token_type(tokenize.INDENT), '')\n",
        "        token_tuples.append((tokenize.INDENT, spelling))\n",
        "      elif whole_token in PythonTokenizer2._REVERSE_TOKEN_MAP:\n",
        "        python_kind = PythonTokenizer2._REVERSE_TOKEN_MAP[whole_token]\n",
        "        if python_kind in (tokenize.DEDENT, tokenize.ENDMARKER,\n",
        "                           tokenize.ERRORTOKEN):\n",
        "          spelling = ''\n",
        "        else:  # python_kind in (tokenize.NEWLINE, tokenize.NL)\n",
        "          spelling = '\\n'\n",
        "        token_tuples.append((python_kind, spelling))\n",
        "      elif keyword.iskeyword(whole_token):\n",
        "        token_tuples.append((tokenize.NAME, whole_token))\n",
        "      elif PythonTokenizer2._NUMBERS.match(whole_token):\n",
        "        token_tuples.append((tokenize.NUMBER, whole_token))\n",
        "      elif PythonTokenizer2._SINGLE_STRINGS.match(whole_token):\n",
        "        token_tuples.append((tokenize.STRING, whole_token))\n",
        "      elif PythonTokenizer2._TRIPLE_STRING_BEGINNINGS.match(whole_token):\n",
        "        token_tuples.append((tokenize.STRING, whole_token))\n",
        "      elif PythonTokenizer2._COMMENTS.match(whole_token):\n",
        "        token_tuples.append((tokenize.COMMENT, whole_token))\n",
        "      else:\n",
        "        # Everything else we map back to NAME.\n",
        "        token_tuples.append((tokenize.NAME, whole_token))\n",
        "\n",
        "    reconstructed = tokenize.untokenize(typing.cast(Any, token_tuples))\n",
        "    return reconstructed\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uREaG4vQlFWO"
      },
      "source": [
        "Below function will extract both tokens and the token types from the code. With original CuBert tokenizer, every camel-cased variable name was split into multiple tokens (E.g: named_func = [named_^, ^func]) however the token type returned was just one leading to mismatch between lengths. As a workaround we copy the token type for each split of the variable name and make the lengths of token array and token_type array consistent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOS_mSj8hIOK"
      },
      "source": [
        "def get_lang_specific_tokens(init_tokenizer, code_snip):\n",
        "    #tokens_complete = init_tokenizer.tokenize(source_code=code_snip)\n",
        "    tokens = init_tokenizer.tokenize_and_abstract(source_code=code_snip )\n",
        "    conditioned = init_tokenizer.condition_full_tokens(tokens)\n",
        "    agnostic_token_lists = unified_tokenizer._agnostic_tokens_to_lists_of_token_lists(conditioned)\n",
        "    with_identifiers_heuristically_split = unified_tokenizer._subtokenize_identifiers_heuristically(\n",
        "        agnostic_token_lists)\n",
        "    with_string_tokens_heuristically_split = unified_tokenizer._subtokenize_strings_heuristically(\n",
        "        with_identifiers_heuristically_split)\n",
        "    shortened_subtokens = unified_tokenizer._shorten_subtokens(with_string_tokens_heuristically_split, 20)\n",
        "    sanitization_mapping = init_tokenizer.get_mappings()\n",
        "    subtoken_lists = unified_tokenizer.sanitize_subtoken_lists(shortened_subtokens,\n",
        "                                            sanitization_mapping,\n",
        "                                            unified_tokenizer.SENTINEL)\n",
        "    #flat_toks =unified_tokenizer.flatten_subtoken_lists(subtoken_lists)\n",
        "    test_spellings = []\n",
        "    test_tok_types = []\n",
        "    for t in subtoken_lists:\n",
        "        #if(len(t.spelling) == 1):\n",
        "        #print(len(t.spellings))\n",
        "        test_spellings.extend(t.spellings)\n",
        "        match=False\n",
        "        for cubert_token in set(init_tokenizer._REVERSE_TOKEN_MAP.keys()):\n",
        "            #print(\"Checking for:\",cubert_token)\n",
        "            if cubert_token in t.spellings[0]:\n",
        "                #print(t.spellings)\n",
        "                selected_token = tokenize.tok_name[init_tokenizer._REVERSE_TOKEN_MAP[cubert_token]]\n",
        "                test_tok_types.extend([selected_token]*len(t.spellings))\n",
        "                match=True          \n",
        "        if match == False:\n",
        "            test_tok_types.extend([t.kind.name]*len(t.spellings))\n",
        "    return test_spellings, test_tok_types\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smcxrHeel_BC"
      },
      "source": [
        "The main Vectorizer class that contains the vocab and the dictionary for Code tokens and token types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h03QcbEIhLeg"
      },
      "source": [
        "class NewVectorizer():\n",
        "    \"\"\"\n",
        "        The main Vectorizer class that contains the vocab and the dictionary \n",
        "        for Code tokens and token types.\n",
        "    \"\"\"\n",
        "    def __init__(self, code_piece, tok_type_counter):\n",
        "        self.code_piece = code_piece\n",
        "        self.tok_type_counter = tok_type_counter\n",
        "        self.code_word2idx = {'<s>':0,'</s>':1,'<pad>':2, '<unk>':3}\n",
        "        self.code_idx2word = {v:k for k,v in self.code_word2idx.items()}\n",
        "        self.toktype_word2idx = {'<s>':0,'</s>':1,'<pad>':2, '<unk>':3}\n",
        "        self.toktype_idx2word = {v:k for k,v in self.toktype_word2idx.items()}\n",
        "        self.max_tok_length = len(self.toktype_word2idx)\n",
        "        self.max_code_length = len(self.code_word2idx)\n",
        "        self.UNK_FOR_TOKEN_TYPE = '<unk>'\n",
        "        self.UNK_FOR_CODEPIECE = '<unk>'\n",
        "        self.ID_UNK_TOKEN_TYPE = self.toktype_word2idx[self.UNK_FOR_TOKEN_TYPE]\n",
        "        self.ID_UNK_CODEPIECE = self.code_word2idx[self.UNK_FOR_CODEPIECE]\n",
        "\n",
        "        self.PAD_FOR_CODEPIECE = '<pad>'\n",
        "        self.PAD_FOR_TOKEN_TYPE = '<pad>'\n",
        "        self.ID_PAD_FOR_CODEPIECE = self.code_word2idx['<pad>']\n",
        "        self.ID_PAD_FOR_TOKEN_TYPE = self.toktype_word2idx['<pad>']\n",
        "        \n",
        "        self.SOS_FOR_CODEPIECE = '<s>'\n",
        "        self.SOS_FOR_TOKEN_TYPE = '<s>'\n",
        "        self.ID_SOS_FOR_CODEPIECE = self.code_word2idx['<s>']\n",
        "        self.ID_SOS_FOR_TOKEN_TYPE = self.toktype_word2idx['<s>']\n",
        "\n",
        "        self.EOS_FOR_CODEPIECE = '</s>'\n",
        "        self.EOS_FOR_TOKEN_TYPE = '</s>'\n",
        "        self.ID_EOS_FOR_CODEPIECE = self.code_word2idx['</s>']\n",
        "        self.ID_EOS_FOR_TOKEN_TYPE = self.toktype_word2idx['</s>']\n",
        "        self.build_vocab()\n",
        "\n",
        "    def build_vocab(self):\n",
        "        idx=len(self.code_word2idx.keys())\n",
        "        for k in self.code_piece.keys():\n",
        "            self.code_word2idx[k]=idx\n",
        "            self.code_idx2word[idx]=k\n",
        "            idx += 1\n",
        "        \n",
        "        idx=len(self.toktype_word2idx.keys())\n",
        "        for k in self.tok_type_counter.keys():\n",
        "            self.toktype_word2idx[k]=idx\n",
        "            self.toktype_idx2word[idx]=k\n",
        "            idx += 1\n",
        "\n",
        "        self.max_tok_length = len(self.toktype_word2idx.keys())\n",
        "        self.max_code_length = len(self.code_word2idx.keys())\n",
        "    ### Returns the code piece for a given ID\n",
        "    def convert_id_to_codepiece(self, id_for_code):\n",
        "        if(id_for_code not in list(self.code_idx2word.keys())):\n",
        "            return self.UNK_FOR_CODEPIECE\n",
        "        return self.code_idx2word[id_for_code]\n",
        "    ### Returns the ID for a given code piece\n",
        "    def convert_codepiece_to_id(self, code_piece):\n",
        "        if(code_piece not in list(self.code_word2idx.keys())):\n",
        "            return self.ID_UNK_CODEPIECE\n",
        "        return self.code_word2idx[code_piece]\n",
        "    ### Returns the TOKEN ID for a given TOKEN type\n",
        "    def convert_toktype_to_id(self, tok_piece):\n",
        "        if(tok_piece not in list(self.toktype_word2idx.keys())):\n",
        "            print(\"No match for\",tok_piece)\n",
        "            return self.ID_UNK_TOKEN_TYPE\n",
        "        return self.toktype_word2idx[tok_piece]\n",
        "    ### Returns the TOKEN type for a given TOKEN ID\n",
        "    def convert_id_to_toktype(self, id_for_toktype):\n",
        "        if(id_for_toktype not in list(self.toktype_idx2word.keys())):\n",
        "            return self.UNK_FOR_TOKEN_TYPE\n",
        "        return self.toktype_idx2word[id_for_toktype]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPlJ9DwNd4G1"
      },
      "source": [
        "sys.path.append(\"/content/cubert\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYzMGFIngltr"
      },
      "source": [
        "import cubert\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from tensor2tensor.data_generators import text_encoder\n",
        "import enum\n",
        "import cubert_tokenizer\n",
        "from cubert import code_to_subtokenized_sentences\n",
        "#from cubert import tokenizer_registry\n",
        "from cubert import python_tokenizer\n",
        "import python_tokenizer\n",
        "from tensor2tensor.data_generators import text_encoder_build_subword\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "@enum.unique\n",
        "class TokenizerEnum(enum.Enum):\n",
        "  \"\"\"Enum for Tokenizers.\"\"\"\n",
        "  #PYTHON = python_tokenizer.PythonTokenizer\n",
        "  PYTHON = PythonTokenizer2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7auIaOthNj6"
      },
      "source": [
        "#### Generate and create the Vectorizer instance\n",
        "word_counter=Counter()\n",
        "init_tokenizer=PythonTokenizer2()\n",
        "tok_type_counter = Counter()\n",
        "for code_snip in nl_to_pl_df['cleaned_code']:\n",
        "    toks, tok_types = get_lang_specific_tokens(init_tokenizer, code_snip)\n",
        "    word_counter.update(Counter(toks))\n",
        "    tok_type_counter.update(Counter(tok_types))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-QqlOuhd3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6cb922-5084-446d-b800-f6cbde9bed03"
      },
      "source": [
        "code_tok_vectorizer = NewVectorizer(word_counter, tok_type_counter)\n",
        "print(code_tok_vectorizer.max_code_length,code_tok_vectorizer.max_tok_length)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5813 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpXc50E_kmUx",
        "outputId": "cc252ac6-1a6f-409e-e4cc-da3920b343e0"
      },
      "source": [
        "nl_to_pl_df['docstring_len'].quantile([.5, .7, .8, .9, .95])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.50     71.0\n",
              "0.70     85.0\n",
              "0.80     96.0\n",
              "0.90    115.0\n",
              "0.95    134.0\n",
              "Name: docstring_len, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTR0cQhHhmWC"
      },
      "source": [
        "### Dataset generator class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVD-3TjxY1SD"
      },
      "source": [
        "tok_ids_list=[]\n",
        "class NLPLSingleEntry(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, \n",
        "                 code_ids,\n",
        "                 tok_ids,\n",
        "                 code_mask, \n",
        "                 doc_ids,\n",
        "                 doc_mask,\n",
        "                 ):\n",
        "        self.code_ids = code_ids\n",
        "        self.code_mask = code_mask\n",
        "        self.tok_ids = tok_ids\n",
        "        self.doc_ids = doc_ids\n",
        "        self.doc_mask = doc_mask\n",
        "        #self.segment_ids = segment_ids\n",
        "        #self.label_id = label_id\n",
        "class NLPLDataSet():\n",
        "    def __init__(self, \n",
        "                 doc_tokenizer, \n",
        "                 code_tokenizer,\n",
        "                 code_tok_vectorizer):\n",
        "        self.doc_tokenizer = doc_tokenizer\n",
        "        self.code_tokenizer = code_tokenizer\n",
        "        self.code_tok_vectorizer = code_tok_vectorizer\n",
        "\n",
        "    def prepare_tokens(self, \n",
        "                       samples, \n",
        "                       tokenizer, \n",
        "                       max_seq_length=0,\n",
        "                       data_type=None):\n",
        "        \"\"\"\n",
        "            Tokenizes an input NL/docstring text, adds padding and SOS+EOS \n",
        "        \"\"\"\n",
        "        toks = tokenizer.tokenize(samples)\n",
        "        # print(data_type)\n",
        "        # print(toks)\n",
        "        if max_seq_length > 2 and len(toks) > max_seq_length - 2:\n",
        "            toks = toks[:max_seq_length -2]\n",
        "        tok_ids =  tokenizer.convert_tokens_to_ids(toks)\n",
        "        ### We use pseudo-BERT process so we will add both CLS and SEP tokens for\n",
        "        ### src and target inputs\n",
        "        tok_ids = [tokenizer.cls_token_id] + tok_ids + [tokenizer.sep_token_id]\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [ 1 ] * len(tok_ids)\n",
        "\n",
        "        if len(tok_ids) < max_seq_length:\n",
        "            padding_length = max_seq_length - len(tok_ids)\n",
        "            tok_ids = tok_ids + ([tokenizer.pad_token_id] * padding_length)\n",
        "            input_mask = input_mask + ([ 0 ] * padding_length) ### Padded tokens are zero-masked\n",
        "        \n",
        "        # print(tok_ids)\n",
        "        return tok_ids, input_mask\n",
        "    def prepare_code_tokens(self, \n",
        "                       samples, \n",
        "                       tokenizer, \n",
        "                       max_seq_length=0,\n",
        "                       data_type=None):\n",
        "        \"\"\"\n",
        "            Tokenizes an input code sequence, adds padding and SOS+EOS \n",
        "        \"\"\"\n",
        "        _toks, _tok_types = get_lang_specific_tokens(self.code_tokenizer, samples)\n",
        "        #print(_tok_types)\n",
        "        # print(data_type)\n",
        "        # print(toks)\n",
        "        if max_seq_length > 2 and len(_toks) > max_seq_length - 2:\n",
        "            _toks = _toks[:max_seq_length -2]\n",
        "            _tok_types = _tok_types[:max_seq_length -2]\n",
        "        #tok_ids =  tokenizer.convert_tokens_to_ids(toks)\n",
        "        tok_ids = [ self.code_tok_vectorizer.convert_codepiece_to_id(code) for code in _toks]\n",
        "        tok_types = [ self.code_tok_vectorizer.convert_toktype_to_id(toktype) for toktype in _tok_types]\n",
        "        \n",
        "        ### We use pseudo-BERT process so we will add both CLS and SEP tokens for\n",
        "        ### src and target inputs\n",
        "        tok_ids = [self.code_tok_vectorizer.ID_SOS_FOR_CODEPIECE] + tok_ids + [self.code_tok_vectorizer.ID_EOS_FOR_CODEPIECE]\n",
        "        tok_types = [self.code_tok_vectorizer.ID_SOS_FOR_TOKEN_TYPE] + tok_types + [self.code_tok_vectorizer.ID_EOS_FOR_TOKEN_TYPE]\n",
        "        #print(len(tok_ids), len(tok_types))\n",
        "        assert(len(tok_ids) == len(tok_types))\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [ 1 ] * len(tok_ids)\n",
        "\n",
        "        if len(tok_ids) < max_seq_length:\n",
        "            padding_length = max_seq_length - len(tok_ids)\n",
        "            tok_ids = tok_ids + ([self.code_tok_vectorizer.ID_PAD_FOR_CODEPIECE] * padding_length)\n",
        "            tok_types = tok_types + ([self.code_tok_vectorizer.ID_PAD_FOR_TOKEN_TYPE] * padding_length)\n",
        "            input_mask = input_mask + ([ 0 ] * padding_length) ### Padded tokens are zero-masked\n",
        "        \n",
        "        # print(tok_ids)\n",
        "        return tok_ids, tok_types, input_mask\n",
        "\n",
        "    def create_dataset(self,\n",
        "                    nl_to_pl_df,\n",
        "                    final_ds,\n",
        "                    sample_count=10000,\n",
        "                    max_doc_len=50,\n",
        "                    max_code_len=0,\n",
        "                    lower_case=False):\n",
        "        \"\"\"\n",
        "            Reads from a dataframe, tokenizes and numericalizes both docstrings \n",
        "            and code. \n",
        "\n",
        "        \"\"\"\n",
        "        #final_ds = []\n",
        "        for idx in nl_to_pl_df.itertuples():\n",
        "            ## For SOS and EOS tokens 2 positions are left\n",
        "            if not idx.cleaned_code:\n",
        "                print(\"Invalid entry, No code found for:\", idx.docstring)\n",
        "            \n",
        "            elem_docstring = idx.docstring\n",
        "            if lower_case:\n",
        "                elem_docstring = elem_docstring.lower()\n",
        "            \n",
        "            doc_toks, doc_mask = self.prepare_tokens(elem_docstring,\n",
        "                                                      self.doc_tokenizer,\n",
        "                                                      max_doc_len,\n",
        "                                                      \"docs\")\n",
        "            code_ids, tok_ids, code_mask = self.prepare_code_tokens(idx.cleaned_code,\n",
        "                                                      self.code_tokenizer,\n",
        "                                                      max_code_len,\n",
        "                                                      \"code\")\n",
        "            #code_toks = None\n",
        "            ### Skip over current iteration if no valid code found\n",
        "\n",
        "            # print(code_toks)\n",
        "            # print(code_mask)\n",
        "            # print(doc_toks)\n",
        "            # print(doc_mask)\n",
        "            final_entry = NLPLSingleEntry(code_ids,\n",
        "                                          tok_ids,\n",
        "                                          code_mask, \n",
        "                                          doc_toks, \n",
        "                                          doc_mask)\n",
        "            # print(final_entry.code_ids)\n",
        "            # print(final_entry.code_mask)\n",
        "            # print(final_entry.doc_ids)\n",
        "            # print(final_entry.doc_mask)\n",
        "            final_ds.append(final_entry)\n",
        "        #print(len(final_ds))\n",
        "        return final_ds\n",
        "        "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V71S9kbEyhv8"
      },
      "source": [
        "### We will use the same tokenizer for both docstrings and code\n",
        "final_ds = []\n",
        "MAX_LENGTH=512\n",
        "#selected_elems = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= MAX_LENGTH]\n",
        "#selected_elems = my_df_copy[my_df_copy['code_len'] <= MAX_LENGTH]\n",
        "MAX_VOCAB_LENGTH=512\n",
        "assert(MAX_VOCAB_LENGTH <= MAX_LENGTH)\n",
        "#selected_elems = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= MAX_LENGTH]\n",
        "#selected_elems = my_df_copy[my_df_copy['code_len'] <= MAX_LENGTH]\n",
        "init_tokenizer=PythonTokenizer2()\n",
        "#selected_elems = nl_to_pl_df[nl_to_pl_df['cleaned_code_len'] <= MAX_VOCAB_LENGTH]\n",
        "\n",
        "selected_elems = nl_to_pl_df[(nl_to_pl_df['cleaned_code_len'] <= MAX_VOCAB_LENGTH) & (nl_to_pl_df['docstring_len'] <= MAX_VOCAB_LENGTH*2)]\n",
        "my_nlpl_ds = NLPLDataSet(auto_tokenizer, init_tokenizer, code_tok_vectorizer).create_dataset(selected_elems, \n",
        "                                                                        final_ds, \n",
        "                                                                        max_doc_len=MAX_VOCAB_LENGTH, \n",
        "                                                                        max_code_len=MAX_VOCAB_LENGTH)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShA8ITXD9wfe"
      },
      "source": [
        "all_code_ids = torch.tensor([f.code_ids for f in my_nlpl_ds], dtype=torch.long)\n",
        "all_code_mask = torch.tensor([f.code_mask for f in my_nlpl_ds], dtype=torch.long)\n",
        "all_doc_ids = torch.tensor([f.doc_ids for f in my_nlpl_ds], dtype=torch.long)\n",
        "all_doc_mask = torch.tensor([f.doc_mask for f in my_nlpl_ds], dtype=torch.long)\n",
        "all_tok_ids = torch.tensor([f.tok_ids for f in my_nlpl_ds], dtype=torch.long)\n",
        "# if output_mode == \"classification\":\n",
        "#     all_label_ids = torch.tensor([f.label_id for f in my_nlpl_ds], dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(all_code_ids,\n",
        "                              all_code_mask, \n",
        "                              all_doc_ids, \n",
        "                              all_doc_mask,\n",
        "                              all_tok_ids)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noufC7M9oTgA"
      },
      "source": [
        "### Dataset Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKJG-nAJl3i9"
      },
      "source": [
        "dataset_size = len(train_dataset)\n",
        "dataset_indices = list(range(dataset_size))\n",
        "np.random.shuffle(dataset_indices)\n",
        "val_split_index = int(np.floor(0.2 * dataset_size))\n",
        "\n",
        "train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRIIkyMl4fY"
      },
      "source": [
        "BATCH_SIZE=8\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "\n",
        "#train_sampler = RandomSampler(train_dataset,) #if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_dataloader = DataLoader(train_dataset, sampler=val_sampler, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "#train_sampler = RandomSampler(train_dataset) #if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scH0xbQHKvS3"
      },
      "source": [
        "### Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2wiHHFBuXxi"
      },
      "source": [
        "class TransEncoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([TransEncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_PH9wz_KzuM"
      },
      "source": [
        "class TransEncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OodBNJ46LCQo"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK2KNXZSLEAz"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luxM15QssA00"
      },
      "source": [
        "We add a specific embedding layer for token types of same dimension as regular tokens as well.\n",
        "```\n",
        "self.tok_type_embedding \n",
        "```\n",
        "Similarly, in the output, we add another FC layer that outputs the predicted sequence of token types\n",
        "```\n",
        "self.fc_out_tok\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH18KwEnLFhF"
      },
      "source": [
        "class TransDecoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 1000,\n",
        "                 tok_type_dim=62):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.tok_type_embedding = nn.Embedding(tok_type_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([TransDecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.fc_out_tok = nn.Linear(hid_dim, tok_type_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask, src_tok_types):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + \n",
        "                           self.pos_embedding(pos) + \n",
        "                           self.tok_type_embedding(src_tok_types))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        output_tok = self.fc_out_tok(trg)\n",
        "        #output =F.softmax(output, dim=2)  \n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, output_tok, attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IChtMK8QLHOP"
      },
      "source": [
        "class TransDecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swxv3Y0SLJmE"
      },
      "source": [
        "class TransSeq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = src_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg, trg_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        trg_pad_mask = trg_mask.unsqueeze(1).unsqueeze(2) \n",
        "        \"\"\"\n",
        "            A boolean tensor of shape [batch size, 1, 1, trg len]\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, src_mask, trg, trg_mask, src_tok_types):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src_mask)\n",
        "        trg_mask = self.make_trg_mask(trg, trg_mask)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, tok_output, attention = self.decoder(trg, \n",
        "                                         enc_src, \n",
        "                                         trg_mask, \n",
        "                                         src_mask, \n",
        "                                         src_tok_types)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, tok_output, attention"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KM6w7s5sqHk"
      },
      "source": [
        "Input to encoder is the question prompt/docstring vocab ~56K\n",
        "Decoder has 2 outputs:\n",
        "1. Code token sequence: Vocab Size = ~5.8k\n",
        "2. Token Type sequence: Vocab Size = 16\n",
        "\n",
        "After multiple experiments, it was found that maintaining 1:4 ratio between d_model(HID_DIM) and d_ffn(ENC_PF_DIM/DEC_PF_DIM) gives better result\n",
        "Here we choose 256 and 1024 respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJUUj5QLvbw"
      },
      "source": [
        "INPUT_DIM = auto_tokenizer.vocab_size\n",
        "OUTPUT_DIM = code_tok_vectorizer.max_code_length\n",
        "TOK_TYPE_OUTPUT_DIM = code_tok_vectorizer.max_tok_length\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 1024\n",
        "DEC_PF_DIM = 1024\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = TransEncoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device,\n",
        "              max_length=MAX_LENGTH)\n",
        "\n",
        "dec = TransDecoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device,\n",
        "              max_length=MAX_LENGTH,\n",
        "              tok_type_dim=TOK_TYPE_OUTPUT_DIM)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lexhxG9rL8pQ"
      },
      "source": [
        "SRC_PAD_IDX = auto_tokenizer.pad_token_id #SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = code_tok_vectorizer.ID_PAD_FOR_TOKEN_TYPE #TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = TransSeq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQy4DgdKzAsB"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw9b7bQ-MIWM"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-yLC9A_Mmuo",
        "outputId": "aeb47be0-ad2e-455e-ecf6-08efe8cab82b"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 21,649,861 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhrFXeouMQEb"
      },
      "source": [
        "model.apply(initialize_weights);\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cWIuwNUMQXs"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip, device,double_loss=False):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_crit_loss = 0\n",
        "    epoch_tok_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        trg = batch[0].to(device)\n",
        "        trg_mask = batch[1].to(device)\n",
        "        src = batch[2].to(device)\n",
        "        src_mask = batch[3].to(device)\n",
        "        src_tok_type = batch[4].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, tok_op, _ = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1], src_tok_type[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "        if(double_loss == True):            \n",
        "            tok_op_output_dim = tok_op.shape[-1]            \n",
        "            tok_op = tok_op.contiguous().view(-1, tok_op_output_dim)\n",
        "            src_tok_type = src_tok_type[:,1:].contiguous().view(-1)\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]            \n",
        "            loss,crit_loss, tok_loss = criterion(output, \n",
        "                                                 trg,\n",
        "                                                 tok_op,\n",
        "                                                 src_tok_type)\n",
        "            epoch_crit_loss += crit_loss.item()\n",
        "            epoch_tok_loss += tok_loss.item()\n",
        "        else:\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "        loss.backward()        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()        \n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    if(double_loss == True):  \n",
        "        print(f'Train\\tCrit Loss: {epoch_crit_loss/(len(iterator)):.3f} | Token Loss: {epoch_tok_loss/(len(iterator)):.3f}')\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26yD4gOnMr9U"
      },
      "source": [
        "def evaluate(model, iterator, criterion, device,double_loss=False):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_crit_loss = 0\n",
        "    epoch_tok_loss = 0\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            trg = batch[0].to(device)\n",
        "            trg_mask = batch[1].to(device)\n",
        "            src = batch[2].to(device)\n",
        "            src_mask = batch[3].to(device)\n",
        "            src_tok_type = batch[4].to(device)\n",
        "\n",
        "            #output, _ = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1])\n",
        "            output, tok_op, _ = model(src, src_mask, trg[:,:-1], trg_mask[:,:-1], src_tok_type[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            if(double_loss == True):            \n",
        "                tok_op_output_dim = tok_op.shape[-1]            \n",
        "                tok_op = tok_op.contiguous().view(-1, tok_op_output_dim)\n",
        "                src_tok_type = src_tok_type[:,1:].contiguous().view(-1)\n",
        "                #output = [batch size * trg len - 1, output dim]\n",
        "                #trg = [batch size * trg len - 1]            \n",
        "                loss,crit_loss, tok_loss = criterion(output, \n",
        "                                                     trg,\n",
        "                                                     tok_op,\n",
        "                                                     src_tok_type)\n",
        "                epoch_crit_loss += crit_loss.item()\n",
        "                epoch_tok_loss += tok_loss.item()\n",
        "            else:\n",
        "                loss = criterion(output, trg)\n",
        "            \n",
        "\n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            # loss = criterion(output, \n",
        "            #                  trg,\n",
        "            #                  tok_op,\n",
        "            #                  src_tok_type)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    if(double_loss == True):  \n",
        "        print(f'Val\\tCrit Loss: {epoch_crit_loss/(len(iterator)):.3f} | Token Loss: {epoch_tok_loss/(len(iterator)):.3f}')  \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGz-LB82MvFT"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L3MNDCood2P"
      },
      "source": [
        "WeightedCrossEntropy is a custom loss function that combines the loss from code tokens and token types as per \"mix_ratio\" parameter(default = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHcNK9jmPC7U"
      },
      "source": [
        "# my_torch_weights = torch.ones(auto_tokenizer.vocab_size)\n",
        "# my_torch_weights[1437] = 2\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX, weight=my_torch_weights.to(device) )\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "class WeightedCrossEntropy(nn.Module):\n",
        "    def __init__(self,\n",
        "                 code_weights=None,\n",
        "                 code_ignore_idx=None,\n",
        "                 tok_type_weights=None,\n",
        "                 tok_type_ignore_idx=None,\n",
        "                 mix_ratio=0.5):\n",
        "        \n",
        "        super(WeightedCrossEntropy, self).__init__()\n",
        "        self.code_weights=code_weights\n",
        "        self.code_ignore_idx=code_ignore_idx\n",
        "        self.tok_type_weights=tok_type_weights\n",
        "        self.tok_type_ignore_idx=tok_type_ignore_idx\n",
        "        self.mix_ratio = mix_ratio\n",
        "    \n",
        "    def forward(self, \n",
        "                code_output, \n",
        "                code_trg,\n",
        "                tok_type_output,\n",
        "                tok_type_trg):\n",
        "        \n",
        "        # code_criterion = nn.CrossEntropyLoss(ignore_index = self.code_ignore_idx,\n",
        "        #                                      weight=self.code_weights)\n",
        "        # toktype_criterion = nn.CrossEntropyLoss(ignore_index = self.tok_type_ignore_idx,\n",
        "        #                                 weight=self.tok_type_weights)\n",
        "\n",
        "        code_criterion = F.cross_entropy(code_output, \n",
        "                                         code_trg, \n",
        "                                         weight=self.code_weights,\n",
        "                                         ignore_index = self.code_ignore_idx)\n",
        "        toktype_criterion = F.cross_entropy(tok_type_output, \n",
        "                                         tok_type_trg, \n",
        "                                         weight=self.tok_type_weights,\n",
        "                                         ignore_index = self.tok_type_ignore_idx)\n",
        "        \n",
        "        total_loss = self.mix_ratio * code_criterion + (1-self.mix_ratio )*toktype_criterion\n",
        "        #total_loss = code_criterion + toktype_criterion\n",
        "        return total_loss, code_criterion, toktype_criterion\n",
        "\n",
        "criterion = WeightedCrossEntropy(code_ignore_idx=TRG_PAD_IDX, \n",
        "                                 tok_type_ignore_idx=TRG_PAD_IDX,\n",
        "                                 mix_ratio=0.9999)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hrlBV-kAM4h"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def run_train_eval_loop(model, \n",
        "                        train_dataloader,\n",
        "                        val_dataloader,\n",
        "                        optimizer,\n",
        "                        criterion,\n",
        "                        device,\n",
        "                        epochs=20,\n",
        "                        clip=1,\n",
        "                        best_valid_loss=float('inf'),\n",
        "                        file_path='end_capstone_baseline_128.pt',\n",
        "                        double_loss=False,\n",
        "                        scheduler=None,\n",
        "                        mix_ratio=0.5):\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "    if double_loss == True:    \n",
        "        criterion = WeightedCrossEntropy(code_ignore_idx=TRG_PAD_IDX, \n",
        "                                        tok_type_ignore_idx=TRG_PAD_IDX,\n",
        "                                        mix_ratio=mix_ratio)            \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "    \n",
        "        start_time = time.time()\n",
        "        \n",
        "        train_loss = train(model, train_dataloader, optimizer, criterion, clip, device,double_loss=double_loss)\n",
        "        valid_loss = evaluate(model, val_dataloader, criterion, device,double_loss=double_loss)\n",
        "        \n",
        "        if(scheduler is not None):\n",
        "            scheduler.step(valid_loss)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save({\"model\":model.state_dict(),\n",
        "                \"optimizer\":optimizer.state_dict(),\n",
        "                \"loss\":valid_loss,\n",
        "                },file_path)\n",
        "        \n",
        "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE1Xa6EJwk2F"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,25))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiwj5jwOA_Lf"
      },
      "source": [
        "file_path='end_capstone_self_encode_sizeCor_seq512.pt'\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "run_train_eval_loop(model,\n",
        "                    train_dataloader,\n",
        "                    val_dataloader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    device,\n",
        "                    epochs=30,\n",
        "                    clip=1,\n",
        "                    best_valid_loss=float('inf'),\n",
        "                    file_path=file_path,\n",
        "                    double_loss=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xbt0QojKy6M"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "optimizer.load_state_dict(chkpt['optimizer'])\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-8,verbose=True)\n",
        "run_train_eval_loop(model,\n",
        "                    train_dataloader,\n",
        "                    val_dataloader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    device,\n",
        "                    epochs=50,\n",
        "                    clip=1,\n",
        "                    best_valid_loss=chkpt['loss'],\n",
        "                    file_path=file_path,\n",
        "                    double_loss=True,\n",
        "                    scheduler=scheduler,\n",
        "                    mix_ratio=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wv7Bi-17EsJ",
        "outputId": "28e351e4-0552-4abd-b821-44eea067b2a2"
      },
      "source": [
        "file_path='/content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn3.pt'\n",
        "\n",
        "chkpt = torch.load(file_path)\n",
        "print(chkpt['loss'])\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.932535447990117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSKGPMshKnYF",
        "outputId": "de815772-946e-4cc2-d65e-eaee0f09babc"
      },
      "source": [
        "\n",
        "\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt'\n",
        "\n",
        "chkpt = torch.load(file_path)\n",
        "print(chkpt['loss'])\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KrWgIHbvMVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "936533ad-0ddb-4512-afb8-ee5dbf64a6e0"
      },
      "source": [
        "LEARNING_RATE = 0.00005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt'\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-9,verbose=True)\n",
        "run_train_eval_loop(model,\n",
        "                    train_dataloader,\n",
        "                    val_dataloader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    device,\n",
        "                    epochs=100,\n",
        "                    clip=1.4,\n",
        "                    best_valid_loss=float('inf'),\n",
        "                    file_path=file_path,\n",
        "                    double_loss=True,\n",
        "                    scheduler=scheduler,\n",
        "                    mix_ratio=0.9) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\tCrit Loss: 0.247 | Token Loss: 0.140\n",
            "Val\tCrit Loss: 1.171 | Token Loss: 0.222\n",
            "Epoch: 01 | Time: 0m 27s\n",
            "\tTrain Loss: 0.236 | Train PPL:   1.266\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.933\n",
            "Train\tCrit Loss: 0.241 | Token Loss: 0.136\n",
            "Val\tCrit Loss: 1.137 | Token Loss: 0.220\n",
            "Epoch: 02 | Time: 0m 27s\n",
            "\tTrain Loss: 0.230 | Train PPL:   1.259\n",
            "\t Val. Loss: 1.045 |  Val. PPL:   2.843\n",
            "Train\tCrit Loss: 0.236 | Token Loss: 0.136\n",
            "Val\tCrit Loss: 1.128 | Token Loss: 0.217\n",
            "Epoch: 03 | Time: 0m 27s\n",
            "\tTrain Loss: 0.226 | Train PPL:   1.254\n",
            "\t Val. Loss: 1.037 |  Val. PPL:   2.821\n",
            "Train\tCrit Loss: 0.235 | Token Loss: 0.134\n",
            "Val\tCrit Loss: 1.183 | Token Loss: 0.225\n",
            "Epoch: 04 | Time: 0m 27s\n",
            "\tTrain Loss: 0.225 | Train PPL:   1.253\n",
            "\t Val. Loss: 1.087 |  Val. PPL:   2.966\n",
            "Train\tCrit Loss: 0.230 | Token Loss: 0.133\n",
            "Val\tCrit Loss: 1.152 | Token Loss: 0.221\n",
            "Epoch: 05 | Time: 0m 27s\n",
            "\tTrain Loss: 0.220 | Train PPL:   1.246\n",
            "\t Val. Loss: 1.059 |  Val. PPL:   2.882\n",
            "Train\tCrit Loss: 0.224 | Token Loss: 0.133\n",
            "Val\tCrit Loss: 1.159 | Token Loss: 0.220\n",
            "Epoch: 06 | Time: 0m 27s\n",
            "\tTrain Loss: 0.215 | Train PPL:   1.240\n",
            "\t Val. Loss: 1.065 |  Val. PPL:   2.901\n",
            "Train\tCrit Loss: 0.219 | Token Loss: 0.130\n",
            "Val\tCrit Loss: 1.180 | Token Loss: 0.227\n",
            "Epoch: 07 | Time: 0m 27s\n",
            "\tTrain Loss: 0.210 | Train PPL:   1.234\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.957\n",
            "Train\tCrit Loss: 0.216 | Token Loss: 0.129\n",
            "Val\tCrit Loss: 1.197 | Token Loss: 0.226\n",
            "Epoch: 08 | Time: 0m 27s\n",
            "\tTrain Loss: 0.207 | Train PPL:   1.231\n",
            "\t Val. Loss: 1.100 |  Val. PPL:   3.003\n",
            "Train\tCrit Loss: 0.214 | Token Loss: 0.127\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.221\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-06.\n",
            "Epoch: 09 | Time: 0m 27s\n",
            "\tTrain Loss: 0.206 | Train PPL:   1.228\n",
            "\t Val. Loss: 1.093 |  Val. PPL:   2.982\n",
            "Train\tCrit Loss: 0.206 | Token Loss: 0.124\n",
            "Val\tCrit Loss: 1.158 | Token Loss: 0.221\n",
            "Epoch: 10 | Time: 0m 27s\n",
            "\tTrain Loss: 0.198 | Train PPL:   1.219\n",
            "\t Val. Loss: 1.064 |  Val. PPL:   2.898\n",
            "Train\tCrit Loss: 0.205 | Token Loss: 0.124\n",
            "Val\tCrit Loss: 1.168 | Token Loss: 0.223\n",
            "Epoch: 11 | Time: 0m 27s\n",
            "\tTrain Loss: 0.197 | Train PPL:   1.217\n",
            "\t Val. Loss: 1.073 |  Val. PPL:   2.925\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.124\n",
            "Val\tCrit Loss: 1.199 | Token Loss: 0.232\n",
            "Epoch: 12 | Time: 0m 27s\n",
            "\tTrain Loss: 0.193 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.102 |  Val. PPL:   3.010\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.194 | Token Loss: 0.230\n",
            "Epoch: 13 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.998\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.157 | Token Loss: 0.221\n",
            "Epoch: 14 | Time: 0m 27s\n",
            "\tTrain Loss: 0.193 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.063 |  Val. PPL:   2.895\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.186 | Token Loss: 0.225\n",
            "Epoch    15: reducing learning rate of group 0 to 5.0000e-07.\n",
            "Epoch: 15 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.973\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.154 | Token Loss: 0.223\n",
            "Epoch: 16 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.060 |  Val. PPL:   2.888\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.227\n",
            "Epoch: 17 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.179 | Token Loss: 0.225\n",
            "Epoch: 18 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.956\n",
            "Train\tCrit Loss: 0.195 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.206 | Token Loss: 0.223\n",
            "Epoch: 19 | Time: 0m 27s\n",
            "\tTrain Loss: 0.188 | Train PPL:   1.207\n",
            "\t Val. Loss: 1.108 |  Val. PPL:   3.027\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.154 | Token Loss: 0.219\n",
            "Epoch: 20 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.061 |  Val. PPL:   2.888\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.164 | Token Loss: 0.220\n",
            "Epoch    21: reducing learning rate of group 0 to 5.0000e-08.\n",
            "Epoch: 21 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.164 | Token Loss: 0.220\n",
            "Epoch: 22 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.177 | Token Loss: 0.220\n",
            "Epoch: 23 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.082 |  Val. PPL:   2.949\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.180 | Token Loss: 0.224\n",
            "Epoch: 24 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.084 |  Val. PPL:   2.956\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.170 | Token Loss: 0.225\n",
            "Epoch: 25 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.932\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.229\n",
            "Epoch: 26 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.196 | Token Loss: 0.222\n",
            "Epoch    27: reducing learning rate of group 0 to 5.0000e-09.\n",
            "Epoch: 27 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.999\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.185 | Token Loss: 0.228\n",
            "Epoch: 28 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.090 |  Val. PPL:   2.973\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.170 | Token Loss: 0.224\n",
            "Epoch: 29 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.076 |  Val. PPL:   2.932\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.177 | Token Loss: 0.224\n",
            "Epoch: 30 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.082 |  Val. PPL:   2.950\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.144 | Token Loss: 0.219\n",
            "Epoch: 31 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.051 |  Val. PPL:   2.861\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.173 | Token Loss: 0.222\n",
            "Epoch: 32 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.078 |  Val. PPL:   2.938\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.182 | Token Loss: 0.226\n",
            "Epoch: 33 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.963\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.166 | Token Loss: 0.226\n",
            "Epoch: 34 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.072 |  Val. PPL:   2.922\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.173 | Token Loss: 0.222\n",
            "Epoch: 35 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.078 |  Val. PPL:   2.939\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.152 | Token Loss: 0.222\n",
            "Epoch: 36 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.059 |  Val. PPL:   2.884\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.192 | Token Loss: 0.226\n",
            "Epoch: 37 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.096 |  Val. PPL:   2.991\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.184 | Token Loss: 0.228\n",
            "Epoch: 38 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.089 |  Val. PPL:   2.970\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.169 | Token Loss: 0.223\n",
            "Epoch: 39 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.075 |  Val. PPL:   2.929\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.150 | Token Loss: 0.220\n",
            "Epoch: 40 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.057 |  Val. PPL:   2.878\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.172 | Token Loss: 0.224\n",
            "Epoch: 41 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.077 |  Val. PPL:   2.935\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.176 | Token Loss: 0.224\n",
            "Epoch: 42 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.081 |  Val. PPL:   2.947\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.194 | Token Loss: 0.231\n",
            "Epoch: 43 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.098 |  Val. PPL:   2.997\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.227\n",
            "Epoch: 44 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.094 |  Val. PPL:   2.986\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.121\n",
            "Val\tCrit Loss: 1.190 | Token Loss: 0.226\n",
            "Epoch: 45 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.093 |  Val. PPL:   2.984\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.172 | Token Loss: 0.228\n",
            "Epoch: 46 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.077 |  Val. PPL:   2.937\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.120\n",
            "Val\tCrit Loss: 1.155 | Token Loss: 0.220\n",
            "Epoch: 47 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.062 |  Val. PPL:   2.891\n",
            "Train\tCrit Loss: 0.200 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.181 | Token Loss: 0.226\n",
            "Epoch: 48 | Time: 0m 27s\n",
            "\tTrain Loss: 0.192 | Train PPL:   1.212\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.962\n",
            "Train\tCrit Loss: 0.196 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.163 | Token Loss: 0.223\n",
            "Epoch: 49 | Time: 0m 27s\n",
            "\tTrain Loss: 0.189 | Train PPL:   1.208\n",
            "\t Val. Loss: 1.069 |  Val. PPL:   2.913\n",
            "Train\tCrit Loss: 0.197 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.177 | Token Loss: 0.224\n",
            "Epoch: 50 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.209\n",
            "\t Val. Loss: 1.081 |  Val. PPL:   2.948\n",
            "Train\tCrit Loss: 0.198 | Token Loss: 0.122\n",
            "Val\tCrit Loss: 1.156 | Token Loss: 0.219\n",
            "Epoch: 51 | Time: 0m 27s\n",
            "\tTrain Loss: 0.190 | Train PPL:   1.210\n",
            "\t Val. Loss: 1.063 |  Val. PPL:   2.894\n",
            "Train\tCrit Loss: 0.199 | Token Loss: 0.123\n",
            "Val\tCrit Loss: 1.182 | Token Loss: 0.224\n",
            "Epoch: 52 | Time: 0m 27s\n",
            "\tTrain Loss: 0.191 | Train PPL:   1.211\n",
            "\t Val. Loss: 1.086 |  Val. PPL:   2.962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-11a8bfa0e890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mdouble_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     mix_ratio=0.9)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-e4ce168cb8c0>\u001b[0m in \u001b[0;36mrun_train_eval_loop\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, criterion, device, epochs, clip, best_valid_loss, file_path, double_loss, scheduler, mix_ratio)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdouble_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-6a49ac91852e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, device, double_loss)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_tok_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#output = [batch size, trg len - 1, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-0b31b460a3d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, trg, trg_mask, src_tok_types)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                          \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                                          \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                          src_tok_types)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#output = [batch size, trg len, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-168090165279>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg, enc_src, trg_mask, src_mask, src_tok_types)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#trg = [batch size, trg len, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-5257014854e4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg, enc_src, trg_mask, src_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#positionwise feedforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0m_trg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositionwise_feedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#dropout, residual and layer norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-279165f31071>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#x = [batch size, seq len, pf dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#x = [batch size, seq len, hid dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZO2dHwDSKQT",
        "outputId": "e2c2cafd-3830-4e89-f07a-1923c480c54e"
      },
      "source": [
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt .\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt'\n",
        "\n",
        "chkpt = torch.load(file_path)\n",
        "print(chkpt['loss'])\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRBviYJnKOUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca35af9b-37b0-4f7a-d724-fd34982d442c"
      },
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn6.pt'\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-9,verbose=True)\n",
        "run_train_eval_loop(model,\n",
        "                    train_dataloader,\n",
        "                    val_dataloader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    device,\n",
        "                    epochs=100,\n",
        "                    clip=1.4,\n",
        "                    best_valid_loss=float('inf'),\n",
        "                    file_path=file_path,\n",
        "                    double_loss=True,\n",
        "                    scheduler=scheduler,\n",
        "                    mix_ratio=0.9) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\tCrit Loss: 1.313 | Token Loss: 0.306\n",
            "Val\tCrit Loss: 1.007 | Token Loss: 0.220\n",
            "Epoch: 01 | Time: 1m 21s\n",
            "\tTrain Loss: 1.212 | Train PPL:   3.361\n",
            "\t Val. Loss: 0.928 |  Val. PPL:   2.530\n",
            "Train\tCrit Loss: 1.229 | Token Loss: 0.296\n",
            "Val\tCrit Loss: 0.922 | Token Loss: 0.212\n",
            "Epoch: 02 | Time: 1m 21s\n",
            "\tTrain Loss: 1.136 | Train PPL:   3.114\n",
            "\t Val. Loss: 0.851 |  Val. PPL:   2.342\n",
            "Train\tCrit Loss: 1.148 | Token Loss: 0.298\n",
            "Val\tCrit Loss: 0.898 | Token Loss: 0.217\n",
            "Epoch: 03 | Time: 1m 22s\n",
            "\tTrain Loss: 1.063 | Train PPL:   2.896\n",
            "\t Val. Loss: 0.830 |  Val. PPL:   2.292\n",
            "Train\tCrit Loss: 1.089 | Token Loss: 0.296\n",
            "Val\tCrit Loss: 0.865 | Token Loss: 0.215\n",
            "Epoch: 04 | Time: 1m 22s\n",
            "\tTrain Loss: 1.010 | Train PPL:   2.746\n",
            "\t Val. Loss: 0.800 |  Val. PPL:   2.225\n",
            "Train\tCrit Loss: 1.055 | Token Loss: 0.292\n",
            "Val\tCrit Loss: 0.831 | Token Loss: 0.210\n",
            "Epoch: 05 | Time: 1m 22s\n",
            "\tTrain Loss: 0.978 | Train PPL:   2.660\n",
            "\t Val. Loss: 0.769 |  Val. PPL:   2.157\n",
            "Train\tCrit Loss: 1.023 | Token Loss: 0.283\n",
            "Val\tCrit Loss: 0.815 | Token Loss: 0.204\n",
            "Epoch: 06 | Time: 1m 22s\n",
            "\tTrain Loss: 0.949 | Train PPL:   2.582\n",
            "\t Val. Loss: 0.754 |  Val. PPL:   2.126\n",
            "Train\tCrit Loss: 0.993 | Token Loss: 0.276\n",
            "Val\tCrit Loss: 0.793 | Token Loss: 0.203\n",
            "Epoch: 07 | Time: 1m 21s\n",
            "\tTrain Loss: 0.921 | Train PPL:   2.513\n",
            "\t Val. Loss: 0.734 |  Val. PPL:   2.084\n",
            "Train\tCrit Loss: 0.968 | Token Loss: 0.265\n",
            "Val\tCrit Loss: 0.780 | Token Loss: 0.197\n",
            "Epoch: 08 | Time: 1m 22s\n",
            "\tTrain Loss: 0.897 | Train PPL:   2.453\n",
            "\t Val. Loss: 0.722 |  Val. PPL:   2.058\n",
            "Train\tCrit Loss: 0.946 | Token Loss: 0.260\n",
            "Val\tCrit Loss: 0.770 | Token Loss: 0.194\n",
            "Epoch: 09 | Time: 1m 21s\n",
            "\tTrain Loss: 0.878 | Train PPL:   2.406\n",
            "\t Val. Loss: 0.712 |  Val. PPL:   2.039\n",
            "Train\tCrit Loss: 0.931 | Token Loss: 0.259\n",
            "Val\tCrit Loss: 0.769 | Token Loss: 0.193\n",
            "Epoch: 10 | Time: 1m 21s\n",
            "\tTrain Loss: 0.864 | Train PPL:   2.373\n",
            "\t Val. Loss: 0.712 |  Val. PPL:   2.037\n",
            "Train\tCrit Loss: 0.913 | Token Loss: 0.254\n",
            "Val\tCrit Loss: 0.755 | Token Loss: 0.190\n",
            "Epoch: 11 | Time: 1m 21s\n",
            "\tTrain Loss: 0.848 | Train PPL:   2.334\n",
            "\t Val. Loss: 0.699 |  Val. PPL:   2.011\n",
            "Train\tCrit Loss: 0.900 | Token Loss: 0.250\n",
            "Val\tCrit Loss: 0.737 | Token Loss: 0.184\n",
            "Epoch: 12 | Time: 1m 21s\n",
            "\tTrain Loss: 0.835 | Train PPL:   2.305\n",
            "\t Val. Loss: 0.682 |  Val. PPL:   1.977\n",
            "Train\tCrit Loss: 0.895 | Token Loss: 0.250\n",
            "Val\tCrit Loss: 0.756 | Token Loss: 0.187\n",
            "Epoch: 13 | Time: 1m 21s\n",
            "\tTrain Loss: 0.830 | Train PPL:   2.294\n",
            "\t Val. Loss: 0.699 |  Val. PPL:   2.012\n",
            "Train\tCrit Loss: 0.866 | Token Loss: 0.244\n",
            "Val\tCrit Loss: 0.759 | Token Loss: 0.188\n",
            "Epoch: 14 | Time: 1m 22s\n",
            "\tTrain Loss: 0.804 | Train PPL:   2.235\n",
            "\t Val. Loss: 0.702 |  Val. PPL:   2.018\n",
            "Train\tCrit Loss: 0.846 | Token Loss: 0.241\n",
            "Val\tCrit Loss: 0.732 | Token Loss: 0.183\n",
            "Epoch: 15 | Time: 1m 22s\n",
            "\tTrain Loss: 0.786 | Train PPL:   2.194\n",
            "\t Val. Loss: 0.677 |  Val. PPL:   1.968\n",
            "Train\tCrit Loss: 0.848 | Token Loss: 0.241\n",
            "Val\tCrit Loss: 0.704 | Token Loss: 0.176\n",
            "Epoch: 16 | Time: 1m 22s\n",
            "\tTrain Loss: 0.788 | Train PPL:   2.198\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.826 | Token Loss: 0.236\n",
            "Val\tCrit Loss: 0.737 | Token Loss: 0.182\n",
            "Epoch: 17 | Time: 1m 21s\n",
            "\tTrain Loss: 0.767 | Train PPL:   2.153\n",
            "\t Val. Loss: 0.682 |  Val. PPL:   1.978\n",
            "Train\tCrit Loss: 0.824 | Token Loss: 0.235\n",
            "Val\tCrit Loss: 0.719 | Token Loss: 0.178\n",
            "Epoch: 18 | Time: 1m 21s\n",
            "\tTrain Loss: 0.765 | Train PPL:   2.149\n",
            "\t Val. Loss: 0.665 |  Val. PPL:   1.944\n",
            "Train\tCrit Loss: 0.811 | Token Loss: 0.232\n",
            "Val\tCrit Loss: 0.735 | Token Loss: 0.181\n",
            "Epoch: 19 | Time: 1m 22s\n",
            "\tTrain Loss: 0.753 | Train PPL:   2.124\n",
            "\t Val. Loss: 0.680 |  Val. PPL:   1.974\n",
            "Train\tCrit Loss: 0.797 | Token Loss: 0.230\n",
            "Val\tCrit Loss: 0.716 | Token Loss: 0.175\n",
            "Epoch: 20 | Time: 1m 21s\n",
            "\tTrain Loss: 0.740 | Train PPL:   2.096\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.939\n",
            "Train\tCrit Loss: 0.793 | Token Loss: 0.228\n",
            "Val\tCrit Loss: 0.722 | Token Loss: 0.178\n",
            "Epoch: 21 | Time: 1m 21s\n",
            "\tTrain Loss: 0.737 | Train PPL:   2.089\n",
            "\t Val. Loss: 0.667 |  Val. PPL:   1.949\n",
            "Train\tCrit Loss: 0.787 | Token Loss: 0.227\n",
            "Val\tCrit Loss: 0.719 | Token Loss: 0.176\n",
            "Epoch    22: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 22 | Time: 1m 21s\n",
            "\tTrain Loss: 0.731 | Train PPL:   2.077\n",
            "\t Val. Loss: 0.665 |  Val. PPL:   1.945\n",
            "Train\tCrit Loss: 0.774 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.699 | Token Loss: 0.172\n",
            "Epoch: 23 | Time: 1m 21s\n",
            "\tTrain Loss: 0.719 | Train PPL:   2.052\n",
            "\t Val. Loss: 0.647 |  Val. PPL:   1.909\n",
            "Train\tCrit Loss: 0.771 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.725 | Token Loss: 0.178\n",
            "Epoch: 24 | Time: 1m 21s\n",
            "\tTrain Loss: 0.717 | Train PPL:   2.048\n",
            "\t Val. Loss: 0.670 |  Val. PPL:   1.954\n",
            "Train\tCrit Loss: 0.776 | Token Loss: 0.227\n",
            "Val\tCrit Loss: 0.710 | Token Loss: 0.174\n",
            "Epoch: 25 | Time: 1m 21s\n",
            "\tTrain Loss: 0.721 | Train PPL:   2.057\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.928\n",
            "Train\tCrit Loss: 0.777 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.735 | Token Loss: 0.180\n",
            "Epoch: 26 | Time: 1m 21s\n",
            "\tTrain Loss: 0.722 | Train PPL:   2.058\n",
            "\t Val. Loss: 0.679 |  Val. PPL:   1.972\n",
            "Train\tCrit Loss: 0.763 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.704 | Token Loss: 0.173\n",
            "Epoch: 27 | Time: 1m 21s\n",
            "\tTrain Loss: 0.709 | Train PPL:   2.032\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
            "Train\tCrit Loss: 0.773 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.719 | Token Loss: 0.174\n",
            "Epoch: 28 | Time: 1m 21s\n",
            "\tTrain Loss: 0.719 | Train PPL:   2.051\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.943\n",
            "Train\tCrit Loss: 0.772 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.703 | Token Loss: 0.172\n",
            "Epoch    29: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 29 | Time: 1m 21s\n",
            "\tTrain Loss: 0.717 | Train PPL:   2.049\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.915\n",
            "Train\tCrit Loss: 0.768 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.704 | Token Loss: 0.174\n",
            "Epoch: 30 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.041\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
            "Train\tCrit Loss: 0.766 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.726 | Token Loss: 0.177\n",
            "Epoch: 31 | Time: 1m 21s\n",
            "\tTrain Loss: 0.712 | Train PPL:   2.038\n",
            "\t Val. Loss: 0.671 |  Val. PPL:   1.956\n",
            "Train\tCrit Loss: 0.766 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.710 | Token Loss: 0.174\n",
            "Epoch: 32 | Time: 1m 21s\n",
            "\tTrain Loss: 0.712 | Train PPL:   2.037\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.927\n",
            "Train\tCrit Loss: 0.772 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.710 | Token Loss: 0.175\n",
            "Epoch: 33 | Time: 1m 21s\n",
            "\tTrain Loss: 0.718 | Train PPL:   2.050\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.928\n",
            "Train\tCrit Loss: 0.764 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.724 | Token Loss: 0.177\n",
            "Epoch: 34 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.035\n",
            "\t Val. Loss: 0.669 |  Val. PPL:   1.952\n",
            "Train\tCrit Loss: 0.772 | Token Loss: 0.227\n",
            "Val\tCrit Loss: 0.707 | Token Loss: 0.174\n",
            "Epoch    35: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch: 35 | Time: 1m 21s\n",
            "\tTrain Loss: 0.717 | Train PPL:   2.049\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.922\n",
            "Train\tCrit Loss: 0.760 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.707 | Token Loss: 0.174\n",
            "Epoch: 36 | Time: 1m 21s\n",
            "\tTrain Loss: 0.706 | Train PPL:   2.026\n",
            "\t Val. Loss: 0.654 |  Val. PPL:   1.923\n",
            "Train\tCrit Loss: 0.762 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.725 | Token Loss: 0.177\n",
            "Epoch: 37 | Time: 1m 21s\n",
            "\tTrain Loss: 0.708 | Train PPL:   2.030\n",
            "\t Val. Loss: 0.670 |  Val. PPL:   1.954\n",
            "Train\tCrit Loss: 0.775 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.695 | Token Loss: 0.170\n",
            "Epoch: 38 | Time: 1m 21s\n",
            "\tTrain Loss: 0.720 | Train PPL:   2.055\n",
            "\t Val. Loss: 0.643 |  Val. PPL:   1.901\n",
            "Train\tCrit Loss: 0.756 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.718 | Token Loss: 0.175\n",
            "Epoch: 39 | Time: 1m 21s\n",
            "\tTrain Loss: 0.702 | Train PPL:   2.018\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.942\n",
            "Train\tCrit Loss: 0.765 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.711 | Token Loss: 0.174\n",
            "Epoch: 40 | Time: 1m 21s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.036\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.729 | Token Loss: 0.177\n",
            "Epoch: 41 | Time: 1m 21s\n",
            "\tTrain Loss: 0.712 | Train PPL:   2.039\n",
            "\t Val. Loss: 0.674 |  Val. PPL:   1.962\n",
            "Train\tCrit Loss: 0.768 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.706 | Token Loss: 0.173\n",
            "Epoch: 42 | Time: 1m 21s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.042\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.714 | Token Loss: 0.175\n",
            "Epoch: 43 | Time: 1m 21s\n",
            "\tTrain Loss: 0.708 | Train PPL:   2.029\n",
            "\t Val. Loss: 0.661 |  Val. PPL:   1.936\n",
            "Train\tCrit Loss: 0.765 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.702 | Token Loss: 0.174\n",
            "Epoch: 44 | Time: 1m 21s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.035\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.915\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.726 | Token Loss: 0.178\n",
            "Epoch: 45 | Time: 1m 21s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.028\n",
            "\t Val. Loss: 0.672 |  Val. PPL:   1.957\n",
            "Train\tCrit Loss: 0.768 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.728 | Token Loss: 0.177\n",
            "Epoch: 46 | Time: 1m 21s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.041\n",
            "\t Val. Loss: 0.673 |  Val. PPL:   1.960\n",
            "Train\tCrit Loss: 0.759 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.699 | Token Loss: 0.171\n",
            "Epoch: 47 | Time: 1m 21s\n",
            "\tTrain Loss: 0.705 | Train PPL:   2.024\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.907\n",
            "Train\tCrit Loss: 0.765 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.714 | Token Loss: 0.174\n",
            "Epoch: 48 | Time: 1m 21s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.035\n",
            "\t Val. Loss: 0.660 |  Val. PPL:   1.936\n",
            "Train\tCrit Loss: 0.769 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.711 | Token Loss: 0.175\n",
            "Epoch: 49 | Time: 1m 21s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.773 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.710 | Token Loss: 0.174\n",
            "Epoch: 50 | Time: 1m 21s\n",
            "\tTrain Loss: 0.719 | Train PPL:   2.052\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.929\n",
            "Train\tCrit Loss: 0.755 | Token Loss: 0.221\n",
            "Val\tCrit Loss: 0.710 | Token Loss: 0.174\n",
            "Epoch: 51 | Time: 1m 21s\n",
            "\tTrain Loss: 0.701 | Train PPL:   2.016\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.928\n",
            "Train\tCrit Loss: 0.762 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.724 | Token Loss: 0.175\n",
            "Epoch: 52 | Time: 1m 21s\n",
            "\tTrain Loss: 0.708 | Train PPL:   2.030\n",
            "\t Val. Loss: 0.669 |  Val. PPL:   1.953\n",
            "Train\tCrit Loss: 0.763 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.721 | Token Loss: 0.175\n",
            "Epoch: 53 | Time: 1m 21s\n",
            "\tTrain Loss: 0.709 | Train PPL:   2.033\n",
            "\t Val. Loss: 0.666 |  Val. PPL:   1.947\n",
            "Train\tCrit Loss: 0.769 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.710 | Token Loss: 0.175\n",
            "Epoch: 54 | Time: 1m 21s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.929\n",
            "Train\tCrit Loss: 0.764 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.733 | Token Loss: 0.178\n",
            "Epoch: 55 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.035\n",
            "\t Val. Loss: 0.677 |  Val. PPL:   1.969\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.708 | Token Loss: 0.173\n",
            "Epoch: 56 | Time: 1m 21s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.028\n",
            "\t Val. Loss: 0.655 |  Val. PPL:   1.924\n",
            "Train\tCrit Loss: 0.764 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.698 | Token Loss: 0.170\n",
            "Epoch: 57 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.034\n",
            "\t Val. Loss: 0.645 |  Val. PPL:   1.906\n",
            "Train\tCrit Loss: 0.769 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.714 | Token Loss: 0.175\n",
            "Epoch: 58 | Time: 1m 21s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
            "\t Val. Loss: 0.660 |  Val. PPL:   1.935\n",
            "Train\tCrit Loss: 0.769 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.718 | Token Loss: 0.175\n",
            "Epoch: 59 | Time: 1m 21s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.043\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.942\n",
            "Train\tCrit Loss: 0.763 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.716 | Token Loss: 0.175\n",
            "Epoch: 60 | Time: 1m 21s\n",
            "\tTrain Loss: 0.709 | Train PPL:   2.033\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.939\n",
            "Train\tCrit Loss: 0.771 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.698 | Token Loss: 0.172\n",
            "Epoch: 61 | Time: 1m 21s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.047\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.907\n",
            "Train\tCrit Loss: 0.768 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.709 | Token Loss: 0.174\n",
            "Epoch: 62 | Time: 1m 21s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.041\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.927\n",
            "Train\tCrit Loss: 0.770 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.719 | Token Loss: 0.175\n",
            "Epoch: 63 | Time: 1m 21s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.046\n",
            "\t Val. Loss: 0.665 |  Val. PPL:   1.944\n",
            "Train\tCrit Loss: 0.764 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.711 | Token Loss: 0.175\n",
            "Epoch: 64 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.033\n",
            "\t Val. Loss: 0.658 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.768 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.722 | Token Loss: 0.176\n",
            "Epoch: 65 | Time: 1m 21s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.042\n",
            "\t Val. Loss: 0.667 |  Val. PPL:   1.949\n",
            "Train\tCrit Loss: 0.769 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.723 | Token Loss: 0.177\n",
            "Epoch: 66 | Time: 1m 21s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
            "\t Val. Loss: 0.669 |  Val. PPL:   1.951\n",
            "Train\tCrit Loss: 0.766 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.698 | Token Loss: 0.171\n",
            "Epoch: 67 | Time: 1m 21s\n",
            "\tTrain Loss: 0.712 | Train PPL:   2.038\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.907\n",
            "Train\tCrit Loss: 0.763 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.734 | Token Loss: 0.178\n",
            "Epoch: 68 | Time: 1m 21s\n",
            "\tTrain Loss: 0.709 | Train PPL:   2.032\n",
            "\t Val. Loss: 0.678 |  Val. PPL:   1.970\n",
            "Train\tCrit Loss: 0.763 | Token Loss: 0.227\n",
            "Val\tCrit Loss: 0.718 | Token Loss: 0.176\n",
            "Epoch: 69 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.033\n",
            "\t Val. Loss: 0.663 |  Val. PPL:   1.942\n",
            "Train\tCrit Loss: 0.765 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.715 | Token Loss: 0.174\n",
            "Epoch: 70 | Time: 1m 21s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.037\n",
            "\t Val. Loss: 0.661 |  Val. PPL:   1.936\n",
            "Train\tCrit Loss: 0.765 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.723 | Token Loss: 0.175\n",
            "Epoch: 71 | Time: 1m 21s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.036\n",
            "\t Val. Loss: 0.669 |  Val. PPL:   1.952\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.726 | Token Loss: 0.176\n",
            "Epoch: 72 | Time: 1m 21s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.028\n",
            "\t Val. Loss: 0.671 |  Val. PPL:   1.956\n",
            "Train\tCrit Loss: 0.769 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.720 | Token Loss: 0.177\n",
            "Epoch: 73 | Time: 1m 21s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
            "\t Val. Loss: 0.666 |  Val. PPL:   1.946\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.698 | Token Loss: 0.170\n",
            "Epoch: 74 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.040\n",
            "\t Val. Loss: 0.645 |  Val. PPL:   1.906\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.221\n",
            "Val\tCrit Loss: 0.716 | Token Loss: 0.176\n",
            "Epoch: 75 | Time: 1m 21s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.028\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.939\n",
            "Train\tCrit Loss: 0.758 | Token Loss: 0.221\n",
            "Val\tCrit Loss: 0.702 | Token Loss: 0.174\n",
            "Epoch: 76 | Time: 1m 21s\n",
            "\tTrain Loss: 0.704 | Train PPL:   2.023\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.914\n",
            "Train\tCrit Loss: 0.766 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.722 | Token Loss: 0.178\n",
            "Epoch: 77 | Time: 1m 21s\n",
            "\tTrain Loss: 0.712 | Train PPL:   2.038\n",
            "\t Val. Loss: 0.668 |  Val. PPL:   1.950\n",
            "Train\tCrit Loss: 0.766 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.716 | Token Loss: 0.176\n",
            "Epoch: 78 | Time: 1m 21s\n",
            "\tTrain Loss: 0.712 | Train PPL:   2.038\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.939\n",
            "Train\tCrit Loss: 0.770 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.711 | Token Loss: 0.173\n",
            "Epoch: 79 | Time: 1m 21s\n",
            "\tTrain Loss: 0.715 | Train PPL:   2.045\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.929\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.718 | Token Loss: 0.175\n",
            "Epoch: 80 | Time: 1m 21s\n",
            "\tTrain Loss: 0.708 | Train PPL:   2.029\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.942\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.721 | Token Loss: 0.176\n",
            "Epoch: 81 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.040\n",
            "\t Val. Loss: 0.667 |  Val. PPL:   1.948\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.716 | Token Loss: 0.175\n",
            "Epoch: 82 | Time: 1m 21s\n",
            "\tTrain Loss: 0.708 | Train PPL:   2.029\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.938\n",
            "Train\tCrit Loss: 0.771 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.697 | Token Loss: 0.172\n",
            "Epoch: 83 | Time: 1m 21s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.046\n",
            "\t Val. Loss: 0.644 |  Val. PPL:   1.904\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.223\n",
            "Val\tCrit Loss: 0.709 | Token Loss: 0.174\n",
            "Epoch: 84 | Time: 1m 21s\n",
            "\tTrain Loss: 0.708 | Train PPL:   2.029\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.927\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.709 | Token Loss: 0.173\n",
            "Epoch: 85 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.040\n",
            "\t Val. Loss: 0.655 |  Val. PPL:   1.926\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.699 | Token Loss: 0.171\n",
            "Epoch: 86 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.041\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.908\n",
            "Train\tCrit Loss: 0.760 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.721 | Token Loss: 0.173\n",
            "Epoch: 87 | Time: 1m 21s\n",
            "\tTrain Loss: 0.706 | Train PPL:   2.026\n",
            "\t Val. Loss: 0.667 |  Val. PPL:   1.947\n",
            "Train\tCrit Loss: 0.765 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.720 | Token Loss: 0.175\n",
            "Epoch: 88 | Time: 1m 21s\n",
            "\tTrain Loss: 0.711 | Train PPL:   2.036\n",
            "\t Val. Loss: 0.666 |  Val. PPL:   1.946\n",
            "Train\tCrit Loss: 0.770 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.732 | Token Loss: 0.178\n",
            "Epoch: 89 | Time: 1m 21s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.045\n",
            "\t Val. Loss: 0.677 |  Val. PPL:   1.968\n",
            "Train\tCrit Loss: 0.771 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.709 | Token Loss: 0.175\n",
            "Epoch: 90 | Time: 1m 21s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.047\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.926\n",
            "Train\tCrit Loss: 0.764 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.718 | Token Loss: 0.176\n",
            "Epoch: 91 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.033\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.942\n",
            "Train\tCrit Loss: 0.768 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.704 | Token Loss: 0.172\n",
            "Epoch: 92 | Time: 1m 21s\n",
            "\tTrain Loss: 0.714 | Train PPL:   2.041\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.770 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.719 | Token Loss: 0.176\n",
            "Epoch: 93 | Time: 1m 21s\n",
            "\tTrain Loss: 0.716 | Train PPL:   2.046\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.943\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.704 | Token Loss: 0.173\n",
            "Epoch: 94 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.040\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
            "Train\tCrit Loss: 0.767 | Token Loss: 0.226\n",
            "Val\tCrit Loss: 0.705 | Token Loss: 0.173\n",
            "Epoch: 95 | Time: 1m 21s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.039\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.771 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.703 | Token Loss: 0.172\n",
            "Epoch: 96 | Time: 1m 21s\n",
            "\tTrain Loss: 0.717 | Train PPL:   2.047\n",
            "\t Val. Loss: 0.650 |  Val. PPL:   1.916\n",
            "Train\tCrit Loss: 0.763 | Token Loss: 0.225\n",
            "Val\tCrit Loss: 0.732 | Token Loss: 0.177\n",
            "Epoch: 97 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.033\n",
            "\t Val. Loss: 0.677 |  Val. PPL:   1.967\n",
            "Train\tCrit Loss: 0.758 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.719 | Token Loss: 0.176\n",
            "Epoch: 98 | Time: 1m 21s\n",
            "\tTrain Loss: 0.705 | Train PPL:   2.024\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.943\n",
            "Train\tCrit Loss: 0.761 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.728 | Token Loss: 0.177\n",
            "Epoch: 99 | Time: 1m 21s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.029\n",
            "\t Val. Loss: 0.673 |  Val. PPL:   1.961\n",
            "Train\tCrit Loss: 0.764 | Token Loss: 0.224\n",
            "Val\tCrit Loss: 0.723 | Token Loss: 0.177\n",
            "Epoch: 100 | Time: 1m 21s\n",
            "\tTrain Loss: 0.710 | Train PPL:   2.034\n",
            "\t Val. Loss: 0.668 |  Val. PPL:   1.951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x0qbQ0a_B9D"
      },
      "source": [
        "!cp /content/end_capstone_self_encode_sizeCor_stage2_256_wrn6.pt /content/drive/MyDrive/EVA4/END_Capstone/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzcGjSHHyBPk"
      },
      "source": [
        "!cp /content/end_capstone_self_encode_sizeCor_stage2_256_wrn7.pt /content/drive/MyDrive/EVA4/END_Capstone/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2husK3UdJv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d96c8a-57ac-400c-834d-e74fd3a1067c"
      },
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn7.pt'\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-9,verbose=True)\n",
        "run_train_eval_loop(model,\n",
        "                    train_dataloader,\n",
        "                    val_dataloader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    device,\n",
        "                    epochs=100,\n",
        "                    clip=1.4,\n",
        "                    best_valid_loss=float('inf'),\n",
        "                    file_path=file_path,\n",
        "                    double_loss=True,\n",
        "                    scheduler=scheduler,\n",
        "                    mix_ratio=0.95) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\tCrit Loss: 0.534 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.691 | Token Loss: 0.151\n",
            "Epoch: 01 | Time: 1m 21s\n",
            "\tTrain Loss: 0.515 | Train PPL:   1.673\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.943\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.673 | Token Loss: 0.149\n",
            "Epoch: 02 | Time: 1m 21s\n",
            "\tTrain Loss: 0.510 | Train PPL:   1.665\n",
            "\t Val. Loss: 0.647 |  Val. PPL:   1.910\n",
            "Train\tCrit Loss: 0.522 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.689 | Token Loss: 0.153\n",
            "Epoch: 03 | Time: 1m 21s\n",
            "\tTrain Loss: 0.503 | Train PPL:   1.654\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.939\n",
            "Train\tCrit Loss: 0.515 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.684 | Token Loss: 0.153\n",
            "Epoch: 04 | Time: 1m 21s\n",
            "\tTrain Loss: 0.497 | Train PPL:   1.644\n",
            "\t Val. Loss: 0.658 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.514 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.673 | Token Loss: 0.150\n",
            "Epoch: 05 | Time: 1m 21s\n",
            "\tTrain Loss: 0.496 | Train PPL:   1.641\n",
            "\t Val. Loss: 0.647 |  Val. PPL:   1.909\n",
            "Train\tCrit Loss: 0.511 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.675 | Token Loss: 0.150\n",
            "Epoch: 06 | Time: 1m 21s\n",
            "\tTrain Loss: 0.493 | Train PPL:   1.637\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.914\n",
            "Train\tCrit Loss: 0.503 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.674 | Token Loss: 0.151\n",
            "Epoch: 07 | Time: 1m 21s\n",
            "\tTrain Loss: 0.485 | Train PPL:   1.624\n",
            "\t Val. Loss: 0.648 |  Val. PPL:   1.911\n",
            "Train\tCrit Loss: 0.502 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.670 | Token Loss: 0.149\n",
            "Epoch: 08 | Time: 1m 21s\n",
            "\tTrain Loss: 0.485 | Train PPL:   1.624\n",
            "\t Val. Loss: 0.644 |  Val. PPL:   1.904\n",
            "Train\tCrit Loss: 0.496 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.672 | Token Loss: 0.150\n",
            "Epoch: 09 | Time: 1m 21s\n",
            "\tTrain Loss: 0.478 | Train PPL:   1.613\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.908\n",
            "Train\tCrit Loss: 0.493 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.684 | Token Loss: 0.153\n",
            "Epoch: 10 | Time: 1m 21s\n",
            "\tTrain Loss: 0.476 | Train PPL:   1.609\n",
            "\t Val. Loss: 0.658 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.488 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.669 | Token Loss: 0.151\n",
            "Epoch: 11 | Time: 1m 21s\n",
            "\tTrain Loss: 0.471 | Train PPL:   1.601\n",
            "\t Val. Loss: 0.643 |  Val. PPL:   1.902\n",
            "Train\tCrit Loss: 0.487 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.666 | Token Loss: 0.150\n",
            "Epoch: 12 | Time: 1m 21s\n",
            "\tTrain Loss: 0.470 | Train PPL:   1.600\n",
            "\t Val. Loss: 0.640 |  Val. PPL:   1.897\n",
            "Train\tCrit Loss: 0.489 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.674 | Token Loss: 0.151\n",
            "Epoch: 13 | Time: 1m 21s\n",
            "\tTrain Loss: 0.472 | Train PPL:   1.603\n",
            "\t Val. Loss: 0.648 |  Val. PPL:   1.911\n",
            "Train\tCrit Loss: 0.476 | Token Loss: 0.148\n",
            "Val\tCrit Loss: 0.687 | Token Loss: 0.154\n",
            "Epoch: 14 | Time: 1m 21s\n",
            "\tTrain Loss: 0.459 | Train PPL:   1.583\n",
            "\t Val. Loss: 0.661 |  Val. PPL:   1.936\n",
            "Train\tCrit Loss: 0.471 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.666 | Token Loss: 0.151\n",
            "Epoch: 15 | Time: 1m 21s\n",
            "\tTrain Loss: 0.455 | Train PPL:   1.577\n",
            "\t Val. Loss: 0.641 |  Val. PPL:   1.898\n",
            "Train\tCrit Loss: 0.475 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.653 | Token Loss: 0.147\n",
            "Epoch: 16 | Time: 1m 21s\n",
            "\tTrain Loss: 0.459 | Train PPL:   1.582\n",
            "\t Val. Loss: 0.628 |  Val. PPL:   1.874\n",
            "Train\tCrit Loss: 0.466 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.153\n",
            "Epoch: 17 | Time: 1m 21s\n",
            "\tTrain Loss: 0.450 | Train PPL:   1.569\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.468 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.668 | Token Loss: 0.152\n",
            "Epoch: 18 | Time: 1m 21s\n",
            "\tTrain Loss: 0.452 | Train PPL:   1.571\n",
            "\t Val. Loss: 0.642 |  Val. PPL:   1.900\n",
            "Train\tCrit Loss: 0.463 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.686 | Token Loss: 0.155\n",
            "Epoch: 19 | Time: 1m 21s\n",
            "\tTrain Loss: 0.447 | Train PPL:   1.564\n",
            "\t Val. Loss: 0.659 |  Val. PPL:   1.933\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.664 | Token Loss: 0.150\n",
            "Epoch: 20 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.638 |  Val. PPL:   1.893\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.679 | Token Loss: 0.153\n",
            "Epoch: 21 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.153\n",
            "Epoch    22: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 22 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.656 | Token Loss: 0.149\n",
            "Epoch: 23 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.631 |  Val. PPL:   1.879\n",
            "Train\tCrit Loss: 0.460 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.154\n",
            "Epoch: 24 | Time: 1m 21s\n",
            "\tTrain Loss: 0.444 | Train PPL:   1.559\n",
            "\t Val. Loss: 0.652 |  Val. PPL:   1.919\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.670 | Token Loss: 0.152\n",
            "Epoch: 25 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.644 |  Val. PPL:   1.904\n",
            "Train\tCrit Loss: 0.460 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.696 | Token Loss: 0.158\n",
            "Epoch: 26 | Time: 1m 21s\n",
            "\tTrain Loss: 0.445 | Train PPL:   1.560\n",
            "\t Val. Loss: 0.670 |  Val. PPL:   1.953\n",
            "Train\tCrit Loss: 0.453 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.665 | Token Loss: 0.150\n",
            "Epoch: 27 | Time: 1m 21s\n",
            "\tTrain Loss: 0.438 | Train PPL:   1.550\n",
            "\t Val. Loss: 0.639 |  Val. PPL:   1.894\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.681 | Token Loss: 0.152\n",
            "Epoch    28: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 28 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.654 |  Val. PPL:   1.924\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.662 | Token Loss: 0.150\n",
            "Epoch: 29 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.637 |  Val. PPL:   1.890\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.664 | Token Loss: 0.152\n",
            "Epoch: 30 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.638 |  Val. PPL:   1.893\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.154\n",
            "Epoch: 31 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.652 |  Val. PPL:   1.919\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.667 | Token Loss: 0.151\n",
            "Epoch: 32 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.641 |  Val. PPL:   1.899\n",
            "Train\tCrit Loss: 0.460 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.674 | Token Loss: 0.154\n",
            "Epoch: 33 | Time: 1m 21s\n",
            "\tTrain Loss: 0.445 | Train PPL:   1.560\n",
            "\t Val. Loss: 0.648 |  Val. PPL:   1.911\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.681 | Token Loss: 0.155\n",
            "Epoch    34: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch: 34 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.655 |  Val. PPL:   1.925\n",
            "Train\tCrit Loss: 0.459 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.668 | Token Loss: 0.152\n",
            "Epoch: 35 | Time: 1m 21s\n",
            "\tTrain Loss: 0.444 | Train PPL:   1.558\n",
            "\t Val. Loss: 0.642 |  Val. PPL:   1.900\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.674 | Token Loss: 0.153\n",
            "Epoch: 36 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.647 |  Val. PPL:   1.911\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.682 | Token Loss: 0.154\n",
            "Epoch: 37 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.926\n",
            "Train\tCrit Loss: 0.462 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.660 | Token Loss: 0.149\n",
            "Epoch: 38 | Time: 1m 21s\n",
            "\tTrain Loss: 0.447 | Train PPL:   1.563\n",
            "\t Val. Loss: 0.635 |  Val. PPL:   1.887\n",
            "Train\tCrit Loss: 0.451 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.681 | Token Loss: 0.153\n",
            "Epoch: 39 | Time: 1m 21s\n",
            "\tTrain Loss: 0.436 | Train PPL:   1.546\n",
            "\t Val. Loss: 0.654 |  Val. PPL:   1.924\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.154\n",
            "Val\tCrit Loss: 0.676 | Token Loss: 0.153\n",
            "Epoch: 40 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.914\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.688 | Token Loss: 0.155\n",
            "Epoch: 41 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.661 |  Val. PPL:   1.937\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.667 | Token Loss: 0.151\n",
            "Epoch: 42 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.641 |  Val. PPL:   1.899\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.153\n",
            "Epoch: 43 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.664 | Token Loss: 0.152\n",
            "Epoch: 44 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.639 |  Val. PPL:   1.894\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.685 | Token Loss: 0.155\n",
            "Epoch: 45 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.658 |  Val. PPL:   1.931\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.687 | Token Loss: 0.155\n",
            "Epoch: 46 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.660 |  Val. PPL:   1.935\n",
            "Train\tCrit Loss: 0.451 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.661 | Token Loss: 0.149\n",
            "Epoch: 47 | Time: 1m 21s\n",
            "\tTrain Loss: 0.436 | Train PPL:   1.546\n",
            "\t Val. Loss: 0.635 |  Val. PPL:   1.887\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.153\n",
            "Epoch: 48 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.652 |  Val. PPL:   1.919\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.671 | Token Loss: 0.153\n",
            "Epoch: 49 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.645 |  Val. PPL:   1.905\n",
            "Train\tCrit Loss: 0.459 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.671 | Token Loss: 0.153\n",
            "Epoch: 50 | Time: 1m 21s\n",
            "\tTrain Loss: 0.444 | Train PPL:   1.559\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.907\n",
            "Train\tCrit Loss: 0.450 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.671 | Token Loss: 0.152\n",
            "Epoch: 51 | Time: 1m 21s\n",
            "\tTrain Loss: 0.435 | Train PPL:   1.545\n",
            "\t Val. Loss: 0.645 |  Val. PPL:   1.906\n",
            "Train\tCrit Loss: 0.453 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.682 | Token Loss: 0.153\n",
            "Epoch: 52 | Time: 1m 21s\n",
            "\tTrain Loss: 0.438 | Train PPL:   1.549\n",
            "\t Val. Loss: 0.655 |  Val. PPL:   1.926\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.679 | Token Loss: 0.152\n",
            "Epoch: 53 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Train\tCrit Loss: 0.459 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.672 | Token Loss: 0.153\n",
            "Epoch: 54 | Time: 1m 21s\n",
            "\tTrain Loss: 0.444 | Train PPL:   1.558\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.909\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.687 | Token Loss: 0.155\n",
            "Epoch: 55 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.661 |  Val. PPL:   1.936\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.674 | Token Loss: 0.152\n",
            "Epoch: 56 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.648 |  Val. PPL:   1.911\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.656 | Token Loss: 0.149\n",
            "Epoch: 57 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.630 |  Val. PPL:   1.878\n",
            "Train\tCrit Loss: 0.460 | Token Loss: 0.153\n",
            "Val\tCrit Loss: 0.675 | Token Loss: 0.153\n",
            "Epoch: 58 | Time: 1m 21s\n",
            "\tTrain Loss: 0.445 | Train PPL:   1.560\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.914\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.153\n",
            "Epoch: 59 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.153\n",
            "Epoch: 60 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.662 | Token Loss: 0.151\n",
            "Epoch: 61 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.636 |  Val. PPL:   1.890\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.665 | Token Loss: 0.151\n",
            "Epoch: 62 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.639 |  Val. PPL:   1.895\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.679 | Token Loss: 0.152\n",
            "Epoch: 63 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.674 | Token Loss: 0.154\n",
            "Epoch: 64 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.648 |  Val. PPL:   1.912\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.684 | Token Loss: 0.155\n",
            "Epoch: 65 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.684 | Token Loss: 0.156\n",
            "Epoch: 66 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.658 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.653 | Token Loss: 0.148\n",
            "Epoch: 67 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
            "\t Val. Loss: 0.627 |  Val. PPL:   1.873\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.691 | Token Loss: 0.155\n",
            "Epoch: 68 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.943\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.153\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.154\n",
            "Epoch: 69 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.652 |  Val. PPL:   1.919\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.152\n",
            "Epoch: 70 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.685 | Token Loss: 0.154\n",
            "Epoch: 71 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.658 |  Val. PPL:   1.931\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.682 | Token Loss: 0.154\n",
            "Epoch: 72 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.926\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.155\n",
            "Epoch: 73 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.652 |  Val. PPL:   1.918\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.660 | Token Loss: 0.148\n",
            "Epoch: 74 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.635 |  Val. PPL:   1.886\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.153\n",
            "Epoch: 75 | Time: 1m 21s\n",
            "\tTrain Loss: 0.438 | Train PPL:   1.550\n",
            "\t Val. Loss: 0.651 |  Val. PPL:   1.917\n",
            "Train\tCrit Loss: 0.453 | Token Loss: 0.149\n",
            "Val\tCrit Loss: 0.659 | Token Loss: 0.151\n",
            "Epoch: 76 | Time: 1m 21s\n",
            "\tTrain Loss: 0.437 | Train PPL:   1.549\n",
            "\t Val. Loss: 0.634 |  Val. PPL:   1.885\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.673 | Token Loss: 0.155\n",
            "Epoch: 77 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
            "\t Val. Loss: 0.647 |  Val. PPL:   1.909\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.676 | Token Loss: 0.154\n",
            "Epoch: 78 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.650 |  Val. PPL:   1.916\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.676 | Token Loss: 0.153\n",
            "Epoch: 79 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.649 |  Val. PPL:   1.914\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.680 | Token Loss: 0.154\n",
            "Epoch: 80 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.654 |  Val. PPL:   1.923\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.684 | Token Loss: 0.155\n",
            "Epoch: 81 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.657 |  Val. PPL:   1.930\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.677 | Token Loss: 0.153\n",
            "Epoch: 82 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.650 |  Val. PPL:   1.916\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.659 | Token Loss: 0.150\n",
            "Epoch: 83 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.634 |  Val. PPL:   1.884\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.668 | Token Loss: 0.151\n",
            "Epoch: 84 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.551\n",
            "\t Val. Loss: 0.642 |  Val. PPL:   1.900\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.672 | Token Loss: 0.152\n",
            "Epoch: 85 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.646 |  Val. PPL:   1.909\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.657 | Token Loss: 0.149\n",
            "Epoch: 86 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.632 |  Val. PPL:   1.881\n",
            "Train\tCrit Loss: 0.452 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.680 | Token Loss: 0.151\n",
            "Epoch: 87 | Time: 1m 21s\n",
            "\tTrain Loss: 0.437 | Train PPL:   1.548\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.679 | Token Loss: 0.152\n",
            "Epoch: 88 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.921\n",
            "Train\tCrit Loss: 0.459 | Token Loss: 0.153\n",
            "Val\tCrit Loss: 0.689 | Token Loss: 0.155\n",
            "Epoch: 89 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.558\n",
            "\t Val. Loss: 0.662 |  Val. PPL:   1.939\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.669 | Token Loss: 0.153\n",
            "Epoch: 90 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.644 |  Val. PPL:   1.903\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.678 | Token Loss: 0.153\n",
            "Epoch: 91 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.652 |  Val. PPL:   1.919\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.668 | Token Loss: 0.150\n",
            "Epoch: 92 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.555\n",
            "\t Val. Loss: 0.642 |  Val. PPL:   1.900\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.680 | Token Loss: 0.154\n",
            "Epoch: 93 | Time: 1m 21s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.557\n",
            "\t Val. Loss: 0.653 |  Val. PPL:   1.922\n",
            "Train\tCrit Loss: 0.458 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.658 | Token Loss: 0.150\n",
            "Epoch: 94 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.633 |  Val. PPL:   1.883\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.664 | Token Loss: 0.151\n",
            "Epoch: 95 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
            "\t Val. Loss: 0.639 |  Val. PPL:   1.894\n",
            "Train\tCrit Loss: 0.457 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.668 | Token Loss: 0.151\n",
            "Epoch: 96 | Time: 1m 21s\n",
            "\tTrain Loss: 0.442 | Train PPL:   1.556\n",
            "\t Val. Loss: 0.642 |  Val. PPL:   1.901\n",
            "Train\tCrit Loss: 0.454 | Token Loss: 0.151\n",
            "Val\tCrit Loss: 0.690 | Token Loss: 0.155\n",
            "Epoch: 97 | Time: 1m 21s\n",
            "\tTrain Loss: 0.439 | Train PPL:   1.552\n",
            "\t Val. Loss: 0.664 |  Val. PPL:   1.942\n",
            "Train\tCrit Loss: 0.452 | Token Loss: 0.150\n",
            "Val\tCrit Loss: 0.683 | Token Loss: 0.154\n",
            "Epoch: 98 | Time: 1m 21s\n",
            "\tTrain Loss: 0.437 | Train PPL:   1.548\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.928\n",
            "Train\tCrit Loss: 0.455 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.687 | Token Loss: 0.155\n",
            "Epoch: 99 | Time: 1m 21s\n",
            "\tTrain Loss: 0.440 | Train PPL:   1.553\n",
            "\t Val. Loss: 0.661 |  Val. PPL:   1.936\n",
            "Train\tCrit Loss: 0.456 | Token Loss: 0.152\n",
            "Val\tCrit Loss: 0.683 | Token Loss: 0.155\n",
            "Epoch: 100 | Time: 1m 21s\n",
            "\tTrain Loss: 0.441 | Train PPL:   1.554\n",
            "\t Val. Loss: 0.656 |  Val. PPL:   1.927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K70eii8C1Fg-",
        "outputId": "7ce655e3-ddb4-4367-8275-f9a8cf7b565e"
      },
      "source": [
        "LEARNING_RATE = 0.00001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn92.pt'\n",
        "optimizer.load_state_dict(chkpt['optimizer'])\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, patience=5, min_lr=1e-9,verbose=True)\n",
        "run_train_eval_loop(model,\n",
        "                    train_dataloader,\n",
        "                    val_dataloader,\n",
        "                    optimizer,\n",
        "                    criterion,\n",
        "                    device,\n",
        "                    epochs=100,\n",
        "                    clip=1.4,\n",
        "                    best_valid_loss=float('inf'),\n",
        "                    file_path=file_path,\n",
        "                    double_loss=True,\n",
        "                    scheduler=scheduler,\n",
        "                    mix_ratio=0.95) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\tCrit Loss: 0.527 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.375 | Token Loss: 0.095\n",
            "Epoch: 01 | Time: 1m 22s\n",
            "\tTrain Loss: 0.693 | Train PPL:   2.000\n",
            "\t Val. Loss: 0.470 |  Val. PPL:   1.600\n",
            "Train\tCrit Loss: 0.527 | Token Loss: 0.163\n",
            "Val\tCrit Loss: 0.357 | Token Loss: 0.092\n",
            "Epoch: 02 | Time: 1m 22s\n",
            "\tTrain Loss: 0.691 | Train PPL:   1.995\n",
            "\t Val. Loss: 0.449 |  Val. PPL:   1.567\n",
            "Train\tCrit Loss: 0.528 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.363 | Token Loss: 0.093\n",
            "Epoch: 03 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.998\n",
            "\t Val. Loss: 0.455 |  Val. PPL:   1.577\n",
            "Train\tCrit Loss: 0.526 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.359 | Token Loss: 0.092\n",
            "Epoch: 04 | Time: 1m 22s\n",
            "\tTrain Loss: 0.690 | Train PPL:   1.994\n",
            "\t Val. Loss: 0.451 |  Val. PPL:   1.569\n",
            "Train\tCrit Loss: 0.530 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.372 | Token Loss: 0.094\n",
            "Epoch: 05 | Time: 1m 22s\n",
            "\tTrain Loss: 0.694 | Train PPL:   2.002\n",
            "\t Val. Loss: 0.466 |  Val. PPL:   1.593\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.362 | Token Loss: 0.092\n",
            "Epoch: 06 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.998\n",
            "\t Val. Loss: 0.455 |  Val. PPL:   1.575\n",
            "Train\tCrit Loss: 0.526 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.361 | Token Loss: 0.093\n",
            "Epoch: 07 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.997\n",
            "\t Val. Loss: 0.454 |  Val. PPL:   1.574\n",
            "Train\tCrit Loss: 0.531 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.366 | Token Loss: 0.094\n",
            "Epoch: 08 | Time: 1m 22s\n",
            "\tTrain Loss: 0.697 | Train PPL:   2.007\n",
            "\t Val. Loss: 0.460 |  Val. PPL:   1.584\n",
            "Train\tCrit Loss: 0.528 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.364 | Token Loss: 0.093\n",
            "Epoch: 09 | Time: 1m 22s\n",
            "\tTrain Loss: 0.691 | Train PPL:   1.996\n",
            "\t Val. Loss: 0.457 |  Val. PPL:   1.579\n",
            "Train\tCrit Loss: 0.534 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.366 | Token Loss: 0.093\n",
            "Epoch: 10 | Time: 1m 22s\n",
            "\tTrain Loss: 0.701 | Train PPL:   2.015\n",
            "\t Val. Loss: 0.459 |  Val. PPL:   1.583\n",
            "Train\tCrit Loss: 0.526 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.355 | Token Loss: 0.091\n",
            "Epoch: 11 | Time: 1m 22s\n",
            "\tTrain Loss: 0.690 | Train PPL:   1.994\n",
            "\t Val. Loss: 0.446 |  Val. PPL:   1.562\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.363 | Token Loss: 0.094\n",
            "Epoch: 12 | Time: 1m 22s\n",
            "\tTrain Loss: 0.694 | Train PPL:   2.001\n",
            "\t Val. Loss: 0.457 |  Val. PPL:   1.579\n",
            "Train\tCrit Loss: 0.531 | Token Loss: 0.167\n",
            "Val\tCrit Loss: 0.360 | Token Loss: 0.092\n",
            "Epoch: 13 | Time: 1m 22s\n",
            "\tTrain Loss: 0.698 | Train PPL:   2.009\n",
            "\t Val. Loss: 0.453 |  Val. PPL:   1.573\n",
            "Train\tCrit Loss: 0.530 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.369 | Token Loss: 0.094\n",
            "Epoch: 14 | Time: 1m 22s\n",
            "\tTrain Loss: 0.696 | Train PPL:   2.005\n",
            "\t Val. Loss: 0.463 |  Val. PPL:   1.589\n",
            "Train\tCrit Loss: 0.527 | Token Loss: 0.163\n",
            "Val\tCrit Loss: 0.357 | Token Loss: 0.091\n",
            "Epoch: 15 | Time: 1m 22s\n",
            "\tTrain Loss: 0.690 | Train PPL:   1.993\n",
            "\t Val. Loss: 0.448 |  Val. PPL:   1.565\n",
            "Train\tCrit Loss: 0.526 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.359 | Token Loss: 0.093\n",
            "Epoch: 16 | Time: 1m 22s\n",
            "\tTrain Loss: 0.691 | Train PPL:   1.996\n",
            "\t Val. Loss: 0.452 |  Val. PPL:   1.572\n",
            "Train\tCrit Loss: 0.533 | Token Loss: 0.167\n",
            "Val\tCrit Loss: 0.364 | Token Loss: 0.092\n",
            "Epoch: 17 | Time: 1m 22s\n",
            "\tTrain Loss: 0.700 | Train PPL:   2.013\n",
            "\t Val. Loss: 0.457 |  Val. PPL:   1.579\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.364 | Token Loss: 0.092\n",
            "Epoch: 18 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.998\n",
            "\t Val. Loss: 0.456 |  Val. PPL:   1.577\n",
            "Train\tCrit Loss: 0.527 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.382 | Token Loss: 0.096\n",
            "Epoch: 19 | Time: 1m 22s\n",
            "\tTrain Loss: 0.691 | Train PPL:   1.996\n",
            "\t Val. Loss: 0.478 |  Val. PPL:   1.612\n",
            "Train\tCrit Loss: 0.533 | Token Loss: 0.167\n",
            "Val\tCrit Loss: 0.372 | Token Loss: 0.095\n",
            "Epoch: 20 | Time: 1m 22s\n",
            "\tTrain Loss: 0.700 | Train PPL:   2.014\n",
            "\t Val. Loss: 0.467 |  Val. PPL:   1.595\n",
            "Train\tCrit Loss: 0.535 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.367 | Token Loss: 0.093\n",
            "Epoch: 21 | Time: 1m 22s\n",
            "\tTrain Loss: 0.701 | Train PPL:   2.015\n",
            "\t Val. Loss: 0.460 |  Val. PPL:   1.584\n",
            "Train\tCrit Loss: 0.528 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.372 | Token Loss: 0.094\n",
            "Epoch: 22 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.997\n",
            "\t Val. Loss: 0.466 |  Val. PPL:   1.594\n",
            "Train\tCrit Loss: 0.531 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.351 | Token Loss: 0.090\n",
            "Epoch: 23 | Time: 1m 22s\n",
            "\tTrain Loss: 0.695 | Train PPL:   2.003\n",
            "\t Val. Loss: 0.442 |  Val. PPL:   1.555\n",
            "Train\tCrit Loss: 0.530 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.351 | Token Loss: 0.091\n",
            "Epoch: 24 | Time: 1m 22s\n",
            "\tTrain Loss: 0.695 | Train PPL:   2.004\n",
            "\t Val. Loss: 0.442 |  Val. PPL:   1.556\n",
            "Train\tCrit Loss: 0.530 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.366 | Token Loss: 0.093\n",
            "Epoch: 25 | Time: 1m 22s\n",
            "\tTrain Loss: 0.695 | Train PPL:   2.005\n",
            "\t Val. Loss: 0.459 |  Val. PPL:   1.582\n",
            "Train\tCrit Loss: 0.527 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.352 | Token Loss: 0.090\n",
            "Epoch: 26 | Time: 1m 22s\n",
            "\tTrain Loss: 0.691 | Train PPL:   1.995\n",
            "\t Val. Loss: 0.442 |  Val. PPL:   1.555\n",
            "Train\tCrit Loss: 0.534 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.366 | Token Loss: 0.094\n",
            "Epoch: 27 | Time: 1m 22s\n",
            "\tTrain Loss: 0.699 | Train PPL:   2.012\n",
            "\t Val. Loss: 0.460 |  Val. PPL:   1.584\n",
            "Train\tCrit Loss: 0.526 | Token Loss: 0.163\n",
            "Val\tCrit Loss: 0.367 | Token Loss: 0.092\n",
            "Epoch: 28 | Time: 1m 22s\n",
            "\tTrain Loss: 0.689 | Train PPL:   1.991\n",
            "\t Val. Loss: 0.459 |  Val. PPL:   1.583\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.368 | Token Loss: 0.093\n",
            "Epoch: 29 | Time: 1m 22s\n",
            "\tTrain Loss: 0.694 | Train PPL:   2.001\n",
            "\t Val. Loss: 0.461 |  Val. PPL:   1.586\n",
            "Train\tCrit Loss: 0.528 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.369 | Token Loss: 0.094\n",
            "Epoch: 30 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.998\n",
            "\t Val. Loss: 0.463 |  Val. PPL:   1.589\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.368 | Token Loss: 0.094\n",
            "Epoch: 31 | Time: 1m 22s\n",
            "\tTrain Loss: 0.693 | Train PPL:   2.000\n",
            "\t Val. Loss: 0.462 |  Val. PPL:   1.587\n",
            "Train\tCrit Loss: 0.523 | Token Loss: 0.163\n",
            "Val\tCrit Loss: 0.352 | Token Loss: 0.091\n",
            "Epoch: 32 | Time: 1m 22s\n",
            "\tTrain Loss: 0.686 | Train PPL:   1.986\n",
            "\t Val. Loss: 0.444 |  Val. PPL:   1.559\n",
            "Train\tCrit Loss: 0.527 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.372 | Token Loss: 0.094\n",
            "Epoch: 33 | Time: 1m 22s\n",
            "\tTrain Loss: 0.691 | Train PPL:   1.995\n",
            "\t Val. Loss: 0.467 |  Val. PPL:   1.595\n",
            "Train\tCrit Loss: 0.532 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.357 | Token Loss: 0.092\n",
            "Epoch: 34 | Time: 1m 22s\n",
            "\tTrain Loss: 0.697 | Train PPL:   2.009\n",
            "\t Val. Loss: 0.449 |  Val. PPL:   1.567\n",
            "Train\tCrit Loss: 0.530 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.359 | Token Loss: 0.093\n",
            "Epoch: 35 | Time: 1m 22s\n",
            "\tTrain Loss: 0.695 | Train PPL:   2.004\n",
            "\t Val. Loss: 0.452 |  Val. PPL:   1.572\n",
            "Train\tCrit Loss: 0.531 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.366 | Token Loss: 0.093\n",
            "Epoch: 36 | Time: 1m 22s\n",
            "\tTrain Loss: 0.696 | Train PPL:   2.006\n",
            "\t Val. Loss: 0.459 |  Val. PPL:   1.583\n",
            "Train\tCrit Loss: 0.533 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.363 | Token Loss: 0.094\n",
            "Epoch: 37 | Time: 1m 22s\n",
            "\tTrain Loss: 0.699 | Train PPL:   2.012\n",
            "\t Val. Loss: 0.457 |  Val. PPL:   1.579\n",
            "Train\tCrit Loss: 0.526 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.364 | Token Loss: 0.093\n",
            "Epoch: 38 | Time: 1m 22s\n",
            "\tTrain Loss: 0.690 | Train PPL:   1.993\n",
            "\t Val. Loss: 0.457 |  Val. PPL:   1.580\n",
            "Train\tCrit Loss: 0.536 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.364 | Token Loss: 0.093\n",
            "Epoch: 39 | Time: 1m 22s\n",
            "\tTrain Loss: 0.703 | Train PPL:   2.019\n",
            "\t Val. Loss: 0.456 |  Val. PPL:   1.578\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.165\n",
            "Val\tCrit Loss: 0.353 | Token Loss: 0.091\n",
            "Epoch: 40 | Time: 1m 22s\n",
            "\tTrain Loss: 0.693 | Train PPL:   2.001\n",
            "\t Val. Loss: 0.444 |  Val. PPL:   1.558\n",
            "Train\tCrit Loss: 0.523 | Token Loss: 0.163\n",
            "Val\tCrit Loss: 0.368 | Token Loss: 0.094\n",
            "Epoch: 41 | Time: 1m 22s\n",
            "\tTrain Loss: 0.686 | Train PPL:   1.986\n",
            "\t Val. Loss: 0.462 |  Val. PPL:   1.587\n",
            "Train\tCrit Loss: 0.530 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.365 | Token Loss: 0.093\n",
            "Epoch: 42 | Time: 1m 22s\n",
            "\tTrain Loss: 0.694 | Train PPL:   2.002\n",
            "\t Val. Loss: 0.457 |  Val. PPL:   1.580\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.364 | Token Loss: 0.092\n",
            "Epoch: 43 | Time: 1m 22s\n",
            "\tTrain Loss: 0.694 | Train PPL:   2.003\n",
            "\t Val. Loss: 0.456 |  Val. PPL:   1.578\n",
            "Train\tCrit Loss: 0.532 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.360 | Token Loss: 0.091\n",
            "Epoch: 44 | Time: 1m 22s\n",
            "\tTrain Loss: 0.697 | Train PPL:   2.009\n",
            "\t Val. Loss: 0.451 |  Val. PPL:   1.570\n",
            "Train\tCrit Loss: 0.529 | Token Loss: 0.166\n",
            "Val\tCrit Loss: 0.376 | Token Loss: 0.095\n",
            "Epoch: 45 | Time: 1m 22s\n",
            "\tTrain Loss: 0.695 | Train PPL:   2.003\n",
            "\t Val. Loss: 0.471 |  Val. PPL:   1.602\n",
            "Train\tCrit Loss: 0.534 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.359 | Token Loss: 0.091\n",
            "Epoch: 46 | Time: 1m 22s\n",
            "\tTrain Loss: 0.698 | Train PPL:   2.010\n",
            "\t Val. Loss: 0.451 |  Val. PPL:   1.569\n",
            "Train\tCrit Loss: 0.528 | Token Loss: 0.164\n",
            "Val\tCrit Loss: 0.360 | Token Loss: 0.092\n",
            "Epoch: 47 | Time: 1m 22s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.997\n",
            "\t Val. Loss: 0.453 |  Val. PPL:   1.572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COeuVi0edn7c"
      },
      "source": [
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn6.pt .\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn7.pt .\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn9.pt .\n",
        "!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn9*.pt ."
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqsSdlhKdzr1",
        "outputId": "abbe23ec-00ae-4a95-e022-9fcd685ee6eb"
      },
      "source": [
        "#!cp /content/drive/MyDrive/EVA4/END_Capstone/end_capstone_self_encode_sizeCor_stage2_256_wrn5.pt .\n",
        "file_path='/content/end_capstone_self_encode_sizeCor_stage2_256_wrn91.pt'\n",
        "\n",
        "chkpt = torch.load(file_path)\n",
        "print(chkpt['loss'])\n",
        "model.load_state_dict(chkpt['model'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.44497802368593664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W5h0XBSpIIJ"
      },
      "source": [
        "### Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDo3e4HVKMxI"
      },
      "source": [
        "def get_code(sentence,\n",
        "             doc_tokenizer,\n",
        "             code_tokenizer,\n",
        "             code_tok_vectorizer,\n",
        "             model, \n",
        "             device, \n",
        "             max_len = 100):\n",
        "    \n",
        "    model.eval()\n",
        "    dataset_handler = NLPLDataSet(doc_tokenizer, code_tokenizer, code_tok_vectorizer)\n",
        "    src_indexes, src_mask =  dataset_handler.prepare_tokens(sentence, dataset_handler.doc_tokenizer)\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_mask = torch.LongTensor(src_mask).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_mask)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [code_tok_vectorizer.ID_SOS_FOR_CODEPIECE]\n",
        "    trg_tok_indexes = [code_tok_vectorizer.ID_SOS_FOR_TOKEN_TYPE]\n",
        "    #trg_mask = [1]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_tok_tensor = torch.LongTensor(trg_tok_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        base_mask = torch.LongTensor([1]*(i+1)).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor, base_mask)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, tok_output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask, trg_tok_tensor)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        pred_tok_type = tok_output.argmax(2)[:,-1].item()\n",
        "        trg_tok_indexes.append(pred_tok_type)\n",
        "\n",
        "        if (pred_token == code_tok_vectorizer.ID_EOS_FOR_CODEPIECE or \n",
        "            pred_token == code_tok_vectorizer.code_word2idx['___EOS___']):\n",
        "            break\n",
        "\n",
        "    trg_tokens = [code_tok_vectorizer.convert_id_to_codepiece(i) for i in trg_indexes]\n",
        "    trg_token_types = [code_tok_vectorizer.convert_id_to_toktype(i) for i in trg_tok_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], trg_token_types[1:], attention"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ammem8M7qAL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5381638-d1a0-404e-c826-15e8c4215e05"
      },
      "source": [
        "input_text = \"# Write a function to print the multiplication table of a given number\"\n",
        "splitted_text = auto_tokenizer.tokenize(input_text)\n",
        "mycode, mytoks, attention_val = get_code(input_text,\n",
        "                                 auto_tokenizer, \n",
        "                                 init_tokenizer,\n",
        "                                 code_tok_vectorizer,\n",
        "                                 model, \n",
        "                                 device,\n",
        "                                 max_len=512)\n",
        "\n",
        "print(init_tokenizer.untokenize(mycode)) ### Converts predicted tokens into Python Code\n",
        "exec(init_tokenizer.untokenize(mycode)) ### Optionally we check inline for basic errors.\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "def multiplication_table (n ):\n",
            "  for i in range (1 ,11 ):\n",
            "    print (n ,'x',i ,'=',n *i )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3ulPGT_q16Q",
        "outputId": "ddac581b-6b90-451a-de09-01bbc7bfe422"
      },
      "source": [
        "print(mycode)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['___NL___', 'def', 'multiplication_^', 'table', '(', 'n', ')', ':', '___NEWLINE___', '___INDENT___  ', 'for', 'i', 'in', 'range', '(', '1', ',', '11', ')', ':', '___NEWLINE___', '___INDENT___    ', 'print', '(', 'n', ',', \"'^\", 'x^', \"'\", ',', 'i', ',', \"'='\", ',', 'n', '*', 'i', ')', '___DEDENT___', '___DEDENT___', '___EOS___']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYGFkO7lt42Q"
      },
      "source": [
        "#### Attention Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayl995l96d6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d652b7b-5e1a-4527-be37-5993b50bf752"
      },
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "#display_attention(splitted_text, mycode, attention_val[:,2,:,:].unsqueeze(1), n_heads=1, n_rows=1, n_cols=1)\n",
        "n_heads=8\n",
        "n_rows=4\n",
        "n_cols=n_heads/n_rows\n",
        "display_attention(splitted_text, \n",
        "                  mycode, \n",
        "                  attention_val[:,:8,:,:], \n",
        "                  n_heads=n_heads, \n",
        "                  n_rows=n_rows, \n",
        "                  n_cols=n_cols)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1800 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLXo_F6z78om"
      },
      "source": [
        "nl_to_pl_df = pd.read_csv(\"/content/end_capstone.csv\")\n",
        "nl_to_pl_df['gen_code'] = \"NoCode\"\n",
        "nl_to_pl_df['R1_precision'] = 0.0\n",
        "nl_to_pl_df['R1_recall'] = 0.0\n",
        "nl_to_pl_df['R1_f'] = 0.0\n",
        "nl_to_pl_df['RL_precision'] = 0.0\n",
        "nl_to_pl_df['RL_recall'] = 0.0\n",
        "nl_to_pl_df['RL_f'] = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDKzcwH7uDiC"
      },
      "source": [
        "#### Evaluation with Rouge Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEdm9px1-L5a",
        "outputId": "fff9b1b2-c283-4da7-cbb7-4507e00ced19"
      },
      "source": [
        "!pip install rouge-score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rougeLsum', 'rougeL'], use_stemmer=False)\n",
        "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
        "                      'The quick brown dog jumps on the log.')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPo5pyTRf4tI",
        "outputId": "2f21b023-9489-4581-cb90-b9bc3396920c"
      },
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rougeLsum', 'rougeL'], use_stemmer=False)\n",
        "\n",
        "all_strings = nl_to_pl_df.loc[(nl_to_pl_df['cleaned_code_len'] <= 512), :]\n",
        "\n",
        "gen_code_arr = []\n",
        "#for one_string in all_strings[1500:1549].itertuples():\n",
        "error_count = 0\n",
        "for idx, one_string in enumerate(all_strings.itertuples()):\n",
        "    gen_code = \"NoCode\"\n",
        "    cleaned_string = one_string.docstring.rstrip('\\n').lstrip('#')\n",
        "    #print(cleaned_string)\n",
        "    try:\n",
        "        mycode, my_tok, attention_val = get_code(cleaned_string,\n",
        "                                        auto_tokenizer, \n",
        "                                        init_tokenizer,\n",
        "                                        code_tok_vectorizer,\n",
        "                                        model, \n",
        "                                        device,\n",
        "                                        max_len=200)\n",
        "        gen_code = init_tokenizer.untokenize(mycode)\n",
        "        scores = scorer.score(gen_code, one_string.cleaned_code)\n",
        "        #print(scores)\n",
        "        #one_string.gen_code = gen_code\n",
        "        #nl_to_pl_df.iloc[one_string.Index, -1] = gen_code\n",
        "        nl_to_pl_df.iloc[one_string.Index, 6] = gen_code\n",
        "        nl_to_pl_df.iloc[one_string.Index, 7] = scores['rougeLsum'].precision\n",
        "        nl_to_pl_df.iloc[one_string.Index, 8] = scores['rougeLsum'].recall\n",
        "        nl_to_pl_df.iloc[one_string.Index, 9] = scores['rougeLsum'].fmeasure\n",
        "        nl_to_pl_df.iloc[one_string.Index, 10] = scores['rougeL'].precision\n",
        "        nl_to_pl_df.iloc[one_string.Index, 11] = scores['rougeL'].recall\n",
        "        nl_to_pl_df.iloc[one_string.Index, 12] = scores['rougeL'].fmeasure\n",
        "        #gen_code_arr.append(gen_code)\n",
        "        #print()\n",
        "    except:\n",
        "        error_count += 1\n",
        "        print(f\"Total: {idx} Error Count: {error_count} for: {cleaned_string}\")\n",
        "        #gen_code_arr.append(gen_code)\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total: 74 Error Count: 1 for:  write a python program to Get the maximum and minimum value in a dictionary\n",
            "Total: 267 Error Count: 2 for: python program to implement stooge sort\n",
            "Total: 268 Error Count: 3 for:  Python program to find the  difference between two times\n",
            "Total: 386 Error Count: 4 for:  write a program to convert time from 12 hour to 24 hour format \n",
            "Total: 387 Error Count: 5 for:  write a program to find the difference between two timestamps \n",
            "Total: 396 Error Count: 6 for:  write a program to check whether a given string is Heterogram or not  \n",
            "Total: 399 Error Count: 7 for:  write a program that extract words starting with Vowel From A list\n",
            "Total: 406 Error Count: 8 for:  write a program to check if a string has at least one letter and one number\n",
            "Total: 434 Error Count: 9 for:  write a program to add two matrices using nested loop\n",
            "Total: 436 Error Count: 10 for:  write a program to multiply two matrices using nested loops\n",
            "Total: 471 Error Count: 11 for:  Write a python program to Implement Linear Search and print the key element if found\n",
            "Total: 473 Error Count: 12 for:  Write a python program to Implement Bubble sort and print the sorted list for the below list\n",
            "Total: 526 Error Count: 13 for:  Write a Python Program to Print the Pascal’s triangle for n number of rows given by the user\n",
            "Total: 620 Error Count: 14 for:  write a class to print user defined message whenever object of class is called is called.\n",
            "Total: 621 Error Count: 15 for:  write a class to show as how to make the class as callable\n",
            "Total: 626 Error Count: 16 for:  write a class to show implementation of static method\n",
            "Total: 635 Error Count: 17 for:  write a program to show fibonaaci using generator\n",
            "Total: 690 Error Count: 18 for:  write a program to show usage of kwargs\n",
            "Total: 704 Error Count: 19 for:  write a Python implementation of LIS problem \n",
            "Total: 711 Error Count: 20 for:  write a function to print the time it takes to run a function\n",
            "Total: 768 Error Count: 21 for:  write a python function for Named Entity Recognizer using NLTK\n",
            "Total: 772 Error Count: 22 for:  write a python function that given five positive integers and find the minimum and maximum values that can be calculated by summing exactly four of the five integers.\n",
            "Total: 927 Error Count: 23 for:  write Python Function to print leaders in array  \n",
            "Total: 929 Error Count: 24 for:  write a python Program to multiply two matrices and print the result\n",
            "Total: 967 Error Count: 25 for:  Write a Python function to check whether a list contains a sublist.\n",
            "Total: 974 Error Count: 26 for:  Write a Python function to read a square matrix from console and print the sum of matrix primary diagonal.Accept the size of the square matrix and elements for each column separated with a space (for every row) as input from the user and print the output.\n",
            "Total: 977 Error Count: 27 for:  Write a Python function to find the index of a given string at which a given substring starts. If the substring is not found in the given string return 'Not found' and print the output.\n",
            "Total: 1105 Error Count: 28 for:  Write a python program to find and print product of two matrices\n",
            "Total: 1126 Error Count: 29 for:  Write a python function to find and print longest continous odd sequence of a list of numbers given\n",
            "Total: 1131 Error Count: 30 for:  Write a python function to calculate number of ways of selecting p non  consecutive stations out of n stations \n",
            "Total: 1142 Error Count: 31 for:  Write a python function to implement 0/1 Knapsack problem\n",
            "Total: 1150 Error Count: 32 for:  Write python function which Given an list distinct integers candidates and a target integer target, return a list of all unique combinations of candidates where the chosen numbers sum to target. \n",
            "Total: 1164 Error Count: 33 for:  Write a python function to perform Matrix Chain multiplication i.e. Given a sequence of matrices, find the most efficient way to multiply these matrices together\n",
            "Total: 1175 Error Count: 34 for:  write a python function to filter Rows with a specific pair sum and return boolean value\n",
            "Total: 1177 Error Count: 35 for:  Write a python program to test if all elements are unique in columns in matrix and print them\n",
            "Total: 1233 Error Count: 36 for:  write a python program to convert List of Dictionaries to List of Lists and print it \n",
            "Total: 1234 Error Count: 37 for:  write a python program for printing custom order dictionary \n",
            "Total: 1235 Error Count: 38 for:  write a python program to extract Numerical Dictionary values and print it\n",
            "Total: 1392 Error Count: 39 for:  write a python program to print display the powers of 2 using anonymous function\n",
            "Total: 1436 Error Count: 40 for:  write a Python program to find the minute at which the minute hand and hour hand coincide \n",
            "Total: 1437 Error Count: 41 for:  write a Python function to convert Fraction to Mixed Number\n",
            "Total: 1441 Error Count: 42 for:  write a Python function that finds a root of a polynomial curve using the Newton-Raphson method.\n",
            "Total: 1460 Error Count: 43 for:  write Python program to find Mathematical Median of Cumulative Records \n",
            "Total: 1471 Error Count: 44 for:  Python program that accepts an integer (n) and computes the value of n+nn+nnn.\n",
            "Total: 1486 Error Count: 45 for:  Python program to make a chain of function decorators (bold, italic, underline etc.\n",
            "Total: 1491 Error Count: 46 for:  Python program to create a list containing the power of said number in bases raised to the corresponding number in the index using Python map\n",
            "Total: 1542 Error Count: 47 for: 40. Python Program to Add Two Matrices\n",
            "Total: 1543 Error Count: 48 for: 41. Python Program to Add Two Matrices using Nested List Comprehension\n",
            "Total: 1546 Error Count: 49 for: 44. Python Program to Multiply Two Matrices using Nested Loop\n",
            "Total: 1547 Error Count: 50 for: 44. Python Program to Multiply Two Matrices using Nested List Comprehension\n",
            "Total: 1619 Error Count: 51 for: 40. Python Program to Add Two Matrices\n",
            "Total: 1620 Error Count: 52 for: 41. Python Program to Add Two Matrices using Nested List Comprehension\n",
            "Total: 1623 Error Count: 53 for: 44. Python Program to Multiply Two Matrices using Nested Loop\n",
            "Total: 1624 Error Count: 54 for: 44. Python Program to Multiply Two Matrices using Nested List Comprehension\n",
            "Total: 1636 Error Count: 55 for:  Given a collection of intervals which are already sorted by start number, merge all overlapping intervals.\n",
            "Total: 1639 Error Count: 56 for:  write a program to multiply two Matrix \n",
            "Total: 1692 Error Count: 57 for:  Check if there is a value for a key in JSON\n",
            "Total: 1764 Error Count: 58 for:  31. Python Program to find Diameter, Circumference, and Area Of a Circle\n",
            "Total: 1766 Error Count: 59 for:  33. Python Program to Calculate Simple Interest\n",
            "Total: 1769 Error Count: 60 for:  36. Recursive Python function to solve the tower of hanoi  \n",
            "Total: 1774 Error Count: 61 for:  43. python function for finding sine angle\n",
            "Total: 1776 Error Count: 62 for:  45. python function for finding tangent angle\n",
            "Total: 1831 Error Count: 63 for:  write a program to convert a dictionary value list to dictionary list and prints it.\n",
            "Total: 1871 Error Count: 64 for:  Write a python program to convert each list element to key-value pair. Print the final dictionary\n",
            "Total: 1879 Error Count: 65 for:  Write a python function to sort a list of tuples by the second Item \n",
            "Total: 1882 Error Count: 66 for:  Write a python program to join Tuples from a list of tupels if they have similar initial element. Print out the output\n",
            "Total: 1992 Error Count: 67 for: Write a function to find the  difference between two times\n",
            "Total: 1995 Error Count: 68 for: Write a function to print all time when angle between hour hand and minute\n",
            "Total: 2309 Error Count: 69 for:  write a program to convert a dictionary value list to dictionary list and prints it.\n",
            "Total: 2349 Error Count: 70 for:  Write a python program to convert each list element to key-value pair. Print the final dictionary\n",
            "Total: 2357 Error Count: 71 for:  Write a python function to sort a list of tuples by the second Item \n",
            "Total: 2360 Error Count: 72 for:  Write a python program to join Tuples from a list of tupels if they have similar initial element. Print out the output\n",
            "Total: 2370 Error Count: 73 for:  write a python class to instantiate an object with two string attributes and write a function to return the list of attributes\n",
            "Total: 2400 Error Count: 74 for:  write a python function to create two threads and start and join the two threads \n",
            "Total: 2404 Error Count: 75 for:   Write a python class to welcome \n",
            "Total: 2422 Error Count: 76 for:  Write python function role a dice\n",
            "Total: 2467 Error Count: 77 for:  Given a collection of intervals which are already sorted by start number, merge all overlapping intervals.\n",
            "Total: 2470 Error Count: 78 for:  write a program to multiply two Matrix \n",
            "Total: 2520 Error Count: 79 for:  Check if there is a value for a key in JSON\n",
            "Total: 2608 Error Count: 80 for:  write a program to convert a dictionary value list to dictionary list and prints it.\n",
            "Total: 2648 Error Count: 81 for:  Write a python program to convert each list element to key-value pair. Print the final dictionary\n",
            "Total: 2656 Error Count: 82 for:  Write a python function to sort a list of tuples by the second Item \n",
            "Total: 2659 Error Count: 83 for:  Write a python program to join Tuples from a list of tupels if they have similar initial element. Print out the output\n",
            "Total: 2769 Error Count: 84 for: Write a function to find the  difference between two times\n",
            "Total: 2772 Error Count: 85 for: Write a function to print all time when angle between hour hand and minute\n",
            "Total: 2784 Error Count: 86 for:  write a python function for Named Entity Recognizer using NLTK\n",
            "Total: 2788 Error Count: 87 for:  write a python function that given five positive integers and find the minimum and maximum values that can be calculated by summing exactly four of the five integers.\n",
            "Total: 2818 Error Count: 88 for:  Write a python program to Implement Linear Search and print the key element if found\n",
            "Total: 2820 Error Count: 89 for:  Write a python program to Implement Bubble sort and print the sorted list for the below list\n",
            "Total: 2873 Error Count: 90 for:  Write a Python Program to Print the Pascal’s triangle for n number of rows given by the user\n",
            "Total: 2933 Error Count: 91 for:  Write Python function to check if a string has at least one letter and one number\n",
            "Total: 2964 Error Count: 92 for:  write a python program to Print Quotient and Remainder of two numbers \n",
            "Total: 2978 Error Count: 93 for:  Write a Python Program to Add Two Matrices and print result.\n",
            "Total: 2979 Error Count: 94 for:  write Python Program to Multiply Two Matrices and print result.\n",
            "Total: 3154 Error Count: 95 for:  Write a python class Shape and Sub class Square:\n",
            "Total: 3224 Error Count: 96 for:  write a python program to add two matrices and print them\n",
            "Total: 3235 Error Count: 97 for:  write a python program to display the Fibonacci sequence up to n-th term\n",
            "Total: 3268 Error Count: 98 for:  Write a Python function that returns the values   of the largest and second largest elements in the passed list.\n",
            "Total: 3363 Error Count: 99 for:  write a python function to implement linear extrapolation\n",
            "Total: 3367 Error Count: 100 for:  write a python function to print the raceman sequence\n",
            "Total: 3528 Error Count: 101 for:  write Python Function to print leaders in array  \n",
            "Total: 3530 Error Count: 102 for:  write a python Program to multiply two matrices and print the result\n",
            "Total: 3568 Error Count: 103 for:  Write a Python function to check whether a list contains a sublist.\n",
            "Total: 3575 Error Count: 104 for:  Write a Python function to read a square matrix from console and print the sum of matrix primary diagonal.Accept the size of the square matrix and elements for each column separated with a space (for every row) as input from the user and print the output.\n",
            "Total: 3578 Error Count: 105 for:  Write a Python function to find the index of a given string at which a given substring starts. If the substring is not found in the given string return 'Not found' and print the output.\n",
            "Total: 3773 Error Count: 106 for:  write a python program to add two matrices\n",
            "Total: 3774 Error Count: 107 for:  write a python program to multiply two matrices\n",
            "Total: 3783 Error Count: 108 for:  Given a collection of intervals which are already sorted by start number, merge all overlapping intervals.\n",
            "Total: 3786 Error Count: 109 for:  write a program to multiply two Matrix \n",
            "Total: 3836 Error Count: 110 for:  Check if there is a value for a key in JSON\n",
            "Total: 3915 Error Count: 111 for:  37 Write a python program to calculate the LCM and HCF of two given numbers\n",
            "Total: 4014 Error Count: 112 for:  write Python3 code to demonstrate working of  Sort tuple list by Nth element of tuple  using sort() + lambda \n",
            "Total: 4016 Error Count: 113 for:  write Python program to demonstrate that we can access multidimensional list using square brackets \n",
            "Total: 4092 Error Count: 114 for: Multiply Two Matrices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMjqZKifDwPm"
      },
      "source": [
        "metrics = [ col for col in nl_to_pl_df.columns.values if \"R1\" in col or \"RL\" in col ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xz9N0xRmw1m",
        "outputId": "26c8fddc-47f4-4e1c-c137-9b99fb178745"
      },
      "source": [
        "nl_to_pl_df.loc[(nl_to_pl_df['gen_code'] == \"NoCode\"),:].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "docstring           244\n",
              "code                244\n",
              "docstring_len       244\n",
              "code_len            244\n",
              "cleaned_code        244\n",
              "cleaned_code_len    244\n",
              "gen_code            244\n",
              "R1_precision        244\n",
              "R1_recall           244\n",
              "R1_f                244\n",
              "RL_precision        244\n",
              "RL_recall           244\n",
              "RL_f                244\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpqlz6MOmw1v",
        "outputId": "1d048344-6478-42d0-99aa-7fc6296f5035"
      },
      "source": [
        "nl_to_pl_df.loc[(nl_to_pl_df['gen_code'] != \"NoCode\"), metrics].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "R1_precision    0.810637\n",
              "R1_recall       0.836924\n",
              "R1_f            0.816128\n",
              "RL_precision    0.796703\n",
              "RL_recall       0.820371\n",
              "RL_f            0.801579\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUhaSnyD0QE",
        "outputId": "d9f51501-19ea-47b3-c619-0bf2db769b82"
      },
      "source": [
        "nl_to_pl_df.loc[:, metrics].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "R1_precision    0.770035\n",
              "R1_recall       0.794166\n",
              "R1_f            0.774787\n",
              "RL_precision    0.753456\n",
              "RL_recall       0.774927\n",
              "RL_f            0.757618\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}