{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "ENDS4- Upgraded Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajy4683/EVAP2/blob/master/ENDS4_Upgraded_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zEMwkVYM5ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c00ba93-8841-4fbe-eae0-3851892c0abf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov 19 16:19:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFXA3BeONGhK"
      },
      "source": [
        "# 2 - Updated Sentiment Analysis\n",
        "\n",
        "Sentiment analysis on IMDB datasets using LSTMs.\n",
        "\n",
        "We will use:\n",
        "- packed padded sequences\n",
        "- pre-trained word embeddings\n",
        "- different RNN architecture\n",
        "- bidirectional RNN\n",
        "- multi-layer RNN\n",
        "- regularization\n",
        "- a different optimizer\n",
        "\n",
        "To make it more interesting, we will feed the sentences in reversed order to our model and see how it behaves. \n",
        "We will target to reach ~87% accuracy without using Bidirectional LSTMs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaqiD36uNGhM"
      },
      "source": [
        "## Preparing Data\n",
        "\n",
        "As before, we'll set the seed, define the `Fields` and get the train/valid/test splits.\n",
        "\n",
        "We'll be using *packed padded sequences*, which will make our RNN only process the non-padded elements of our sequence, and for any padded element the `output` will be a zero tensor. To use packed padded sequences, we have to tell the RNN how long the actual sequences are. We do this by setting `include_lengths = True` for our `TEXT` field. This will cause `batch.text` to now be a tuple with the first element being our sentence (a numericalized tensor that has been padded) and the second element being the actual lengths of our sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oalMASBqNGhN"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9335LIJNGhR"
      },
      "source": [
        "We then load the IMDb dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsVaCQXkNGhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc9af6a-b1df-44de-9ead-79316007d0d8"
      },
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 10.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGU4RlyAik_Z"
      },
      "source": [
        "## Reverse the datasets \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RobmLrddDKxu"
      },
      "source": [
        "def sentence_reversal(input_dataset):\n",
        "    for sentence_ in input_dataset:\n",
        "        sentence_.text.reverse()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhPXeYcbNGhV"
      },
      "source": [
        "Then create the validation set from our training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lY862q5NGhW"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUilUH9UDj0A"
      },
      "source": [
        "sentence_reversal(train_data)\n",
        "#sentence_reversal(test_data)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUeUfgNMD4bb"
      },
      "source": [
        "## Verify if the training dataset is indeed reversed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QHyky66D2pn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ad66c2-097d-49cf-b900-3b9be609fd6f"
      },
      "source": [
        "for idx,sentence_ in enumerate(train_data):\n",
        "    if(idx > 50):\n",
        "        break\n",
        "    print(sentence_.text[-10:])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['where', 'I', 'actually', 'felt', 'deeply', 'embarrassed', 'for', 'everyone', 'involved', '.']\n",
            "['convincing', 'as', 'a', 'someone', 'that', 'played', 'lots', 'of', 'soccer', '.']\n",
            "['me', 'crying', 'every', 'time', '.', 'A', 'truly', 'sweet', 'romance', '.']\n",
            "['-', 'its', '\"', 'of', 'the', \"'\", '30s', '&', '40s', '.']\n",
            "['fond', 'of', 'it', '!', '*', 'from', '*', '*', '*', '*']\n",
            "['for', 'addressing', 'many', 'of', 'the', 'shortcomings', 'of', 'the', 'scripting', '.']\n",
            "['on', 'this', 'silly', ',', 'and', 'already', 'irrelevant', ',', 'DVD', '.']\n",
            "[\"'s\", 'ego', 'is', 'the', 'largest', 'character', 'in', 'this', 'film', '.']\n",
            "['that', 'movie', 'than', 'rekindling', 'interest', 'in', 'that', 'classic', 'series', '.']\n",
            "['recommend', 'this', 'to', 'any', 'fan', 'of', 'romance', 'stories', '.', '7/10']\n",
            "['musical', 'of', 'the', 'forties', 'on', 'one', 'tenth', 'the', 'budget', '.']\n",
            "['violent', ':', 'in', 'a', 'tasteful', 'manner', ',', 'of', 'course', '.']\n",
            "['buy', 'this', 'movie', 'you', \"'ll\", 'be', 'glad', 'you', 'did', '.']\n",
            "[',', 'you', \"'ll\", 'like', 'this', 'show', '.', 'A', 'lot', '.']\n",
            "['be', 're', '-', 'aired', '.', 'DVD', 'release', ',', 'anyone', '?']\n",
            "['this', ',', 'you', 'really', 'want', 'to', 'see', 'it', 'through', '.']\n",
            "['movie', 'should', 'be', 'forgotten', ',', 'sorry', 'to', 'say', '.', ':(']\n",
            "['to', 'mention', 'that', '.', 'It', 'comes', 'up', 'a', 'lot', '.']\n",
            "['they', 'had', 'done', 'the', 'decent', 'thing', 'and', 'killed', 'themselves', '.']\n",
            "['too.<br', '/><br', '/>86', 'mins', '.', 'rated', 'R', 'for', 'Language', '.']\n",
            "['to', 'be', 'put', 'back', 'in', 'the', 'time', 'capsule', '.', 'D']\n",
            "['do', 'so', 'too', '.', 'Well', 'recommended', 'at', 'any', 'rate', '.']\n",
            "['and', 'now', 'I', 'want', 'to', 'know', 'what', 'happens', 'next', '!']\n",
            "['I', 'see', 'no', 'violence!!\"<br', '/><br', '/>CRAIG', 'ROBERTSON', 'Fife', ',', 'Scotland']\n",
            "[',', 'why', 'the', 'hell', 'was', 'Dr', '.', 'Cox', 'bald', '?']\n",
            "['Mary', 'as', 'well', 'as', 'other', 'characters', 'in', 'other', 'films', '.']\n",
            "['I', 'strongly', 'recommend', 'you', 'to', 'see', 'this', 'film', 'today', '!']\n",
            "['for', 'getting', 'to', 'shoot', 'in', 'such', 'a', 'beautiful', 'location', '.']\n",
            "['story', 'was', 'a', 'desperate', 'attempt', 'for', 'a', 'good', 'screenplay', '.']\n",
            "['and', 'enjoy', 'watching', 'it', 'again', 'from', 'time', 'to', 'time', '.']\n",
            "['person', 'who', 'really', 'liked', 'this', 'flick', '.', '(', 'B', ')']\n",
            "['a', 'below', 'average', 'teen', 'comedy', 'that', \"'s\", 'worth', 'skipping', '.']\n",
            "['there', 'somewhere', 'aimed', 'for', 'Earth.<br', '/><br', '/>(Unratable', 'honestly', '...', ')']\n",
            "['axe', '.', 'The', 'same', 'exact', 'sound', 'for', 'every', 'chop', '!']\n",
            "['day', 'at', 'home', 'and', 'make', 'it', 'for', 'an', 'couch', 'matinée']\n",
            "['a', 'late', ',', 'very', 'ripe', 'league', 'of', 'its', 'own', '.']\n",
            "['period', 'of', 'time', 'for', 'human', 'beings', 'around', 'the', 'world', '.']\n",
            "['and', 'I', 'would', 'definitely', 'recommend', 'it', 'to', 'anyone.<br', '/><br', '/>10/10']\n",
            "['suffering', 'from', 'insomnia', '(', 'I', 'dozed', 'off', 'twice', ')', '.']\n",
            "['powerful', 'social', 'satire', 'and', 'no', 'self', '-', 'indulgent', 'sentimentalism', '.']\n",
            "['about', 'race', 'relations', 'then', 'this', 'movie', 'is', \"n't\", 'for', 'you']\n",
            "['-', 'who', 'killed', 'Sir', 'Thomas', 'MacDonald', \"'s\", 'dog', 'Ghillie', '?']\n",
            "[',', 'April', '14', ',', '1991', '-', 'Hoyts', 'Cinema', 'Centre', 'Melbourne']\n",
            "['score', 'which', 'kept', 'us', 'all', 'on', 'pins', 'and', 'needles', '.']\n",
            "['that', ',', 'this', 'just', 'looks', 'like', 'a', 'bad', 'movie', '.']\n",
            "['look', 'forward', 'to', 'more', 'of', 'Richard', 'Shepard', \"'s\", 'projects', '.']\n",
            "['for', 'the', 'first', 'lets', 'say', '10', 'minutes', 'of', 'movie', '.']\n",
            "['the', 'gems', 'out', 'there', '.', 'Check', 'this', 'film', 'out', '!']\n",
            "['most', 'of', 'his', 'few', 'moments', 'as', 'Avonlea', \"'s\", 'doctor', '.']\n",
            "['the', 'first', 'few', 'minutes', 'and', 'you', 'wo', \"n't\", 'be', 'disappointed']\n",
            "['out', '\"', 'Nemesis\".<br', '/><br', '/>I', 'rated', 'this', 'movie', '1/10', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nm_YhFhirWn"
      },
      "source": [
        "## Verify that test data has not been tampered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og4EN5DURMRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca64caed-82d6-4fd8-fc15-7549926780a2"
      },
      "source": [
        "for idx,sentence_ in enumerate(test_data):\n",
        "    if(idx > 50):\n",
        "        break\n",
        "    print(sentence_.text[:10])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Not', 'a', 'stunner', ',', 'but', 'a', 'good', 'movie', 'to', 'see']\n",
            "['Hong', 'Kong', ',', 'the', '1920s', '.', 'A', 'young', 'man', 'from']\n",
            "['Having', 'seen', 'this', 'without', 'knowing', 'all', 'the', 'hoopla', 'surrounding', 'the']\n",
            "['I', \"'m\", 'not', 'a', 'big', 'fan', 'of', 'musicals', ',', 'but']\n",
            "['When', 'I', 'was', 'younger', 'I', 'saw', 'the', 'end', 'of', 'HAIR']\n",
            "['I', 'was', 'surprised', 'that', '\"', 'Forgiving', 'the', 'Franklins', '\"', 'did']\n",
            "['The', 'first', 'time', 'I', 'saw', 'this', 'movie', ',', 'it', 'did']\n",
            "['Heath', 'Ledgers', 'acting', 'in', 'this', 'film', 'really', 'bugs', 'me', ',']\n",
            "['One', 'of', 'the', 'oddest', ',', 'most', 'strikingly', 'eerie', 'and', 'creepy']\n",
            "['It', 'amazes', 'me', 'that', 'production', 'companies', 'will', 'sue', 'because', 'of']\n",
            "['If', 'you', 'do', \"n't\", 'have', 'anything', 'better', 'to', 'do', ',']\n",
            "['This', 'almost', 'documentary', 'look', 'at', 'an', 'enterprising', 'boy', 'who', 'lives']\n",
            "['I', 'first', 'caught', 'up', 'with', 'Jennifer', 'years', 'ago', 'while', 'out']\n",
            "['I', 'really', 'liked', 'the', 'movie', ',', 'thought', 'it', 'was', 'very']\n",
            "['\"', 'Tipping', 'The', 'Velvet', '\"', 'is', 'one', 'of', 'the', 'modern']\n",
            "['The', 'fact', 'that', 'this', 'film', 'was', 'shown', 'at', 'London', \"'s\"]\n",
            "['Krajobraz', 'po', 'bitwie', 'like', 'many', 'films', 'of', 'Wajda', 'is', ',']\n",
            "['This', 'is', 'one', 'of', 'Chaplin', \"'s\", 'First', 'National', 'films', 'from']\n",
            "['Excellent', 'Hitchcock', 'thriller', 'with', 'Robert', 'Cummings', 'proving', 'once', 'again', 'that']\n",
            "['What', 'the', 'heck', 'do', 'people', 'expect', 'in', 'Horror', 'films', 'these']\n",
            "['I', 'm', 'usually', 'wary', 'of', 'movies', 'hovering', 'around', 'the', '6/10']\n",
            "['\"', 'Best', 'in', 'Show', '\"', 'is', 'a', 'often', 'hilarious', 'mockumentary']\n",
            "['It', \"'s\", 'always', 'a', 'pleasure', 'to', 'see', 'characters', 'in', 'a']\n",
            "['Especially', 'after', 'watching', 'THE', 'MATRIX', 'RELOADED', '!', '!', '*', 'SPOILERS*<br']\n",
            "['1st', 'watched', '10/28/2007', ',', '8', 'out', 'of', '10(Dir', '-', 'Jesus']\n",
            "['Soul', \"'s\", 'Midnight', 'stars', 'Armande', 'Assante', '(', 'Simon', ')', 'who']\n",
            "['OK', ',', 'it', \"'s\", 'easy', 'not', 'to', 'confuse', 'this', 'with']\n",
            "['This', 'is', 'one', 'of', 'my', '3', 'favorite', 'movies', '.', 'I']\n",
            "['Despite', 'the', 'title', 'and', 'unlike', 'some', 'other', 'stories', 'about', 'love']\n",
            "['This', 'movie', 'accurately', 'portrays', 'the', 'struggle', 'life', 'was', 'for', 'the']\n",
            "['Feels', 'like', 'an', 'impressionistic', 'film', ';', 'if', 'there', 'is', 'such']\n",
            "['A', 'very', 'funny', 'movie', '.', 'Michael', 'Douglas', \"'\", '\"', 'do']\n",
            "['We', 'enjoy', 'a', 'film', 'like', '\"', 'Fame', '\"', 'because', 'we']\n",
            "['Years', 'ago', 'when', 'I', 'first', 'read', 'John', 'Irving', \"'s\", 'The']\n",
            "['While', 'it', 'comes', 'no', 'closer', 'to', 'the', 'Tarzan', 'of', 'Edgar']\n",
            "['Had', 'no', 'idea', 'what', 'I', 'was', 'going', 'to', 'experience', 'viewing']\n",
            "['Yes', 'it', \"'s\", 'a', 'Fast', 'Times', 'wannabe', ',', 'but', 'it']\n",
            "['Excellent', 'introspective', '/', 'interpersonal', 'piece', 'that', 'really', 'had', 'some', 'teeth']\n",
            "['Just', 'thinking', 'about', 'the', 'movie', ',', 'i', 'laugh', 'to', 'myself']\n",
            "['\"', 'Love', 'is', 'a', 'Many', '-', 'Splendored', 'Thing', '\"', 'is']\n",
            "['I', 'was', 'a', 'huge', 'fan', 'of', 'Asterix', 'comics', 'when', 'I']\n",
            "['I', 'saw', 'this', 'film', 'knowing', 'absolutely', 'nothing', 'about', 'both', 'it']\n",
            "['Oppenheimer', 'was', 'a', 'GREAT', 'series', '(', 'it', 'was', 'the', 'first']\n",
            "['Tim', 'Robbins', 'did', 'a', 'masterful', 'job', 'directing', 'this', 'film', '.']\n",
            "['I', 'was', '-Unlike', 'most', 'of', 'the', 'reviewers-', 'not', 'born', 'in']\n",
            "['I', \"'ve\", 'seen', 'a', 'few', 'movies', 'in', 'my', 'time', ',']\n",
            "['I', 'remember', 'when', 'this', 'NBC', 'mini', '-', 'series', 'aired', 'when']\n",
            "['A', 'rich', 'old', 'lady', 'calls', 'on', 'a', 'flirtatious', 'divorcée', 'to']\n",
            "['The', '1990s', 'was', 'a', 'great', 'decade', 'for', 'British', 'sitcom', 'with']\n",
            "['I', \"'ve\", 'been', 'waiting', '30', 'years', 'to', 'see', 'this', 'film']\n",
            "['Why', 'take', 'a', 'perfectly', 'good', 'original', 'drama', ',', 'based', 'on']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cep1Cf9NGhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a185193e-441f-4817-e483-ffd22fd59308"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
            "100%|█████████▉| 398740/400000 [00:17<00:00, 22924.96it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUQZguIQNGhg"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMlzKHf1XKfQ"
      },
      "source": [
        "## Actual model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnbO4FfgNGhk"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUucGAf4qAKo"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN_List(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.ModuleList()\n",
        "        self.n_layers = n_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        for i in range(n_layers):\n",
        "            self.rnn.append(nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=1, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout))  \n",
        "        \n",
        "\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        #packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        hidden_cell_state_tuple = tuple()\n",
        "        for offset in range(self.n_layers):\n",
        "            if offset == 0:\n",
        "                packed_output, hidden_cell_state_tuple = self.rnn[offset](packed_embedded)\n",
        "            else:    \n",
        "                packed_output, hidden_cell_state_tuple = self.rnn[offset](packed_embedded, hidden_cell_state_tuple)\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        hidden, cell = hidden_cell_state_tuple\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on-VY_lfNGhn"
      },
      "source": [
        "Like before, we'll create an instance of our RNN class, with the new parameters and arguments for the number of layers, bidirectionality and dropout probability.\n",
        "\n",
        "To ensure the pre-trained vectors can be loaded into the model, the `EMBEDDING_DIM` must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
        "\n",
        "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's `pad_token` attribute, which is `<pad>` by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtidBotyNGho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36767486-1f00-47cd-c685-3638fc9c3e14"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 384\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 3\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "# model = RNN(INPUT_DIM, \n",
        "#             EMBEDDING_DIM, \n",
        "#             HIDDEN_DIM, \n",
        "#             OUTPUT_DIM, \n",
        "#             N_LAYERS, \n",
        "#             BIDIRECTIONAL, \n",
        "#             DROPOUT, \n",
        "#             PAD_IDX)\n",
        "\n",
        "model = RNN_List(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "100%|█████████▉| 398740/400000 [00:29<00:00, 22924.96it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1-d9z-mcbeL",
        "outputId": "f8234e67-a47f-4d0e-a19d-f633c844ed58"
      },
      "source": [
        "#model = model.to(device)\n",
        "model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN_List(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (rnn): ModuleList(\n",
              "    (0): LSTM(100, 384, dropout=0.2, bidirectional=True)\n",
              "    (1): LSTM(100, 384, dropout=0.2, bidirectional=True)\n",
              "    (2): LSTM(100, 384, dropout=0.2, bidirectional=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk9cmDIANGhs"
      },
      "source": [
        "We'll print out the number of parameters in our model. \n",
        "\n",
        "Notice how we have almost twice as many parameters as before!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YpYoXpeNGht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef44326-a166-4e4c-b86a-39735730dbd2"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 6,979,945 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVOt1qD5NGhx"
      },
      "source": [
        "The final addition is copying the pre-trained word embeddings we loaded earlier into the `embedding` layer of our model.\n",
        "\n",
        "We retrieve the embeddings from the field's vocab, and check they're the correct size, _**[vocab size, embedding dim]**_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky2fBmosNGhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0876fd-ce93-4eed-92e4-3af4112ace43"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmtw-WxBNGh1"
      },
      "source": [
        "We then replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "\n",
        "**Note**: this should always be done on the `weight.data` and not the `weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dh_DOvkNGh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa90b16-fc52-431c-caf4-5cd062fd52dd"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.3970,  0.4024,  1.0612,  ..., -0.0136, -0.3363,  0.6442],\n",
              "        [-0.5197,  1.0395,  0.2092,  ..., -0.8857, -0.2294,  0.1244],\n",
              "        [ 0.0057, -0.0707, -0.0804,  ..., -0.3292, -0.0130,  0.0716]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J-3l7lNNGh4"
      },
      "source": [
        "As our `<unk>` and `<pad>` token aren't in the pre-trained vocabulary they have been initialized using `unk_init` (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment. \n",
        "\n",
        "We do this by manually setting their row in the embedding weights matrix to zeros. We get their row by finding the index of the tokens, which we have already done for the padding index.\n",
        "\n",
        "**Note**: like initializing the embeddings, this should be done on the `weight.data` and not the `weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rym2MF1YNGh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb65ca5-f734-4014-8099-6db9e457b21c"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.3970,  0.4024,  1.0612,  ..., -0.0136, -0.3363,  0.6442],\n",
            "        [-0.5197,  1.0395,  0.2092,  ..., -0.8857, -0.2294,  0.1244],\n",
            "        [ 0.0057, -0.0707, -0.0804,  ..., -0.3292, -0.0130,  0.0716]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ldQ7vQeNGh9"
      },
      "source": [
        "We can now see the first two rows of the embedding weights matrix have been set to zeros. As we passed the index of the pad token to the `padding_idx` of the embedding layer it will remain zeros throughout training, however the `<unk>` token embedding will be learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmR5B58Ku8gW"
      },
      "source": [
        "element_ = next(iter(train_iterator))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyGJAI65vS8c"
      },
      "source": [
        "elem_array = [*element_.text]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fFZSlWvwlZD",
        "outputId": "2bcb8b7b-bdd6-491c-f98b-12699ce3c7a9"
      },
      "source": [
        "elem_array[0].cpu().shape, elem_array[1].cpu().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([191, 64]), torch.Size([64]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwpPrX-2xFnc",
        "outputId": "4d846919-296c-4756-cbe6-59b30155c0b6"
      },
      "source": [
        "text_array = elem_array[0]\n",
        "text_array.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([381, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD1RrCZf0iBM",
        "outputId": "9a4c2abb-b6ed-41db-bed0-e0278b393748"
      },
      "source": [
        "elem_array[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191,\n",
              "        191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 191, 190, 190, 190,\n",
              "        190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190, 190,\n",
              "        190, 190, 190, 190, 190, 190, 190, 190, 190, 189, 189, 189, 189, 189,\n",
              "        189, 189, 189, 189, 189, 189, 189, 189], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I_XXa6b3g-Y",
        "outputId": "51e6efc9-27c6-4d42-aca7-2ded0f393260"
      },
      "source": [
        "text_array[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rx5sjxlw43b"
      },
      "source": [
        "\" \".join([TEXT.vocab.itos[text_array[offset][-1]] for offset in range(text_array.shape[0]) ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPyNTq4k3P2f"
      },
      "source": [
        "with torch.no_grad():\n",
        "    emb_out = model.embedding(text_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3KRXKpx3s9H"
      },
      "source": [
        "emb_pack = nn.utils.rnn.pack_padded_sequence(emb_out, elem_array[1].cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fWXu_xp4yrJ",
        "outputId": "4364f8b6-3152-4f53-e63e-e53ed820c28d"
      },
      "source": [
        "emb_pack.data[1,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.4927,  0.3494, -0.3233, -1.8189, -0.9395,  2.8164,  0.2858,  0.8032,\n",
              "         0.6189, -0.7230,  0.2782, -0.9035, -1.3616,  0.4640, -0.4662,  0.5132,\n",
              "         1.5805,  2.1826, -0.4103, -0.2576,  0.1045, -0.8688,  1.4957, -0.2583,\n",
              "        -0.0282, -0.0297,  0.0640, -0.7224, -0.5380,  0.5293, -0.6616,  0.8416,\n",
              "        -0.3224,  0.4930, -0.1878, -0.0139, -0.8935,  0.9628,  1.9609, -0.1048,\n",
              "         0.1071,  1.2595, -1.0393, -0.1827, -0.9304, -0.5972, -0.8050, -0.1499,\n",
              "         0.5111, -0.2358, -0.3499,  0.2673,  1.1686, -0.6818,  0.4988,  0.3094,\n",
              "        -0.1351,  2.1641,  1.4065,  0.4533, -0.6638, -1.6466, -0.6420, -0.3813,\n",
              "         2.0745, -0.6641, -1.5548,  0.5919,  0.1381,  0.0372,  0.4015, -0.1743,\n",
              "        -0.0430, -1.6807,  0.6356, -0.4548,  0.9208,  1.0485, -0.2114, -0.4623,\n",
              "        -0.7928, -0.1096,  0.0108,  0.4000,  0.8154,  2.5640, -0.8559, -0.5328,\n",
              "        -0.0546, -0.1156,  0.6490,  0.0595,  1.5805, -0.9836,  1.0787, -1.3883,\n",
              "         0.2567,  0.8978,  0.0594, -1.3462], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g51UNIdllB1a"
      },
      "source": [
        "input, batch_sizes, sorted_indices, unsorted_indices = emb_pack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89QF1CCalF9p",
        "outputId": "2525f86a-ee05-44c8-c3d6-8b04261d2850"
      },
      "source": [
        "model.rnn.permute_hidden(hidden_local, sorted_indices).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFYjzjZni5Q5"
      },
      "source": [
        "%load_ext autoreload\n",
        "#%autoreload 2\n",
        "#import torch.nn as nn\n",
        "packed_output_local2, (hidden_local2, cell_local2)  =model.rnn(emb_pack, (None, None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7gIZCP9mn9M",
        "outputId": "e6b89584-d4b7-42c4-e38e-afd4f5c0350e"
      },
      "source": [
        "hidden_local2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ets2OcYdks-j",
        "outputId": "568068d9-2d18-4464-fc82-832a275686b9"
      },
      "source": [
        "emb_pack.data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13071, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhZs7ZlVkhVN"
      },
      "source": [
        "model.rnn.permute_hidden()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3yNAwvV6CbP",
        "outputId": "80ca90ac-04d1-4907-de9e-c0b52fa419fa"
      },
      "source": [
        "packed_output_local.data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13071, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuPth-Y-6bKb",
        "outputId": "bee79b36-c3b8-4c02-e555-14825f41db55"
      },
      "source": [
        "hidden_local.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ah9Hcsc9FKf",
        "outputId": "d18c7d57-dc86-4b7b-8ae9-faf0a2d1ab0c"
      },
      "source": [
        "hidden_local[-2,:,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkEnaiE6PXd"
      },
      "source": [
        "#unpack sequence\n",
        "output_local, output_lengths_local = nn.utils.rnn.pad_packed_sequence(packed_output_local)\n",
        "\n",
        "#output = [sent len, batch size, hid dim * num directions]\n",
        "#output over padding tokens are zero tensors\n",
        "\n",
        "#hidden = [num layers * num directions, batch size, hid dim]\n",
        "#cell = [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "#concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "#and apply dropout\n",
        "\n",
        "#hidden = model.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44OJQ97_-OGl",
        "outputId": "8968bdf1-f480-4c28-a718-4d6a3d82b7de"
      },
      "source": [
        "output_local.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([358, 64, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC7q-cKgNGh-"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrXfp5tlNGiF"
      },
      "source": [
        "We implement the function to calculate accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oSNaS2oNGiG"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiHKuWH7NGiI"
      },
      "source": [
        "We define a function for training our model. \n",
        "\n",
        "As we have set `include_lengths = True`, our `batch.text` is now a tuple with the first element being the numericalized tensor and the second element being the actual lengths of each sequence. We separate these into their own variables, `text` and `text_lengths`, before passing them to the model.\n",
        "\n",
        "**Note**: as we are now using dropout, we must remember to use `model.train()` to ensure the dropout is \"turned on\" while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6yE65JrNGiJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        predictions = model(text, text_lengths.cpu()).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYSugLiVNGiM"
      },
      "source": [
        "Then we define a function for testing our model, again remembering to separate `batch.text`.\n",
        "\n",
        "**Note**: as we are now using dropout, we must remember to use `model.eval()` to ensure the dropout is \"turned off\" while evaluating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYRJBqNwNGiN"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths.cpu()).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJiv8yY-NGiQ"
      },
      "source": [
        "And also create a nice function to tell us how long our epochs are taking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLUsX1tpNGiQ"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIeWyfnLG5jU"
      },
      "source": [
        "## Epochs with training data reversed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9J7iauePs5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390d1509-6b7e-4b2b-9896-3cebe4fa8a06"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.643 | Train Acc: 62.81%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 53.79%\n",
            "Epoch: 02 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.516 | Train Acc: 74.66%\n",
            "\t Val. Loss: 0.505 |  Val. Acc: 75.36%\n",
            "Epoch: 03 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.415 | Train Acc: 81.17%\n",
            "\t Val. Loss: 0.466 |  Val. Acc: 78.56%\n",
            "Epoch: 04 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.275 | Train Acc: 88.74%\n",
            "\t Val. Loss: 0.345 |  Val. Acc: 85.91%\n",
            "Epoch: 05 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.196 | Train Acc: 92.32%\n",
            "\t Val. Loss: 0.359 |  Val. Acc: 84.33%\n",
            "Epoch: 06 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.146 | Train Acc: 94.53%\n",
            "\t Val. Loss: 0.334 |  Val. Acc: 86.94%\n",
            "Epoch: 07 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.109 | Train Acc: 96.18%\n",
            "\t Val. Loss: 0.362 |  Val. Acc: 87.38%\n",
            "Epoch: 08 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.080 | Train Acc: 97.16%\n",
            "\t Val. Loss: 0.359 |  Val. Acc: 86.77%\n",
            "Epoch: 09 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.056 | Train Acc: 98.12%\n",
            "\t Val. Loss: 0.395 |  Val. Acc: 86.94%\n",
            "Epoch: 10 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.040 | Train Acc: 98.75%\n",
            "\t Val. Loss: 0.415 |  Val. Acc: 86.40%\n",
            "Epoch: 11 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.02%\n",
            "\t Val. Loss: 0.459 |  Val. Acc: 86.82%\n",
            "Epoch: 12 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.21%\n",
            "\t Val. Loss: 0.475 |  Val. Acc: 86.77%\n",
            "Epoch: 13 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.50%\n",
            "\t Val. Loss: 0.556 |  Val. Acc: 86.36%\n",
            "Epoch: 14 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.44%\n",
            "\t Val. Loss: 0.500 |  Val. Acc: 86.48%\n",
            "Epoch: 15 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.012 | Train Acc: 99.62%\n",
            "\t Val. Loss: 0.509 |  Val. Acc: 87.26%\n",
            "Epoch: 16 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.010 | Train Acc: 99.62%\n",
            "\t Val. Loss: 0.521 |  Val. Acc: 85.96%\n",
            "Epoch: 17 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.010 | Train Acc: 99.65%\n",
            "\t Val. Loss: 0.578 |  Val. Acc: 87.09%\n",
            "Epoch: 18 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.008 | Train Acc: 99.73%\n",
            "\t Val. Loss: 0.577 |  Val. Acc: 87.43%\n",
            "Epoch: 19 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.77%\n",
            "\t Val. Loss: 0.519 |  Val. Acc: 85.85%\n",
            "Epoch: 20 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.76%\n",
            "\t Val. Loss: 0.615 |  Val. Acc: 86.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo9FA9N3jEjU"
      },
      "source": [
        "### Top accuracy reached = 87.43%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR_fzE9WhpAV"
      },
      "source": [
        "## Epochs with training data reset to regular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpYXAvs6hEKO",
        "outputId": "7edb1615-eff4-4e3b-8209-bcc9141c7bc7"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.090 | Train Acc: 97.07%\n",
            "\t Val. Loss: 0.374 |  Val. Acc: 88.38%\n",
            "Epoch: 02 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.032 | Train Acc: 98.93%\n",
            "\t Val. Loss: 0.499 |  Val. Acc: 88.33%\n",
            "Epoch: 03 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.47%\n",
            "\t Val. Loss: 0.522 |  Val. Acc: 88.26%\n",
            "Epoch: 04 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.56%\n",
            "\t Val. Loss: 0.547 |  Val. Acc: 88.79%\n",
            "Epoch: 05 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.011 | Train Acc: 99.65%\n",
            "\t Val. Loss: 0.617 |  Val. Acc: 88.21%\n",
            "Epoch: 06 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.006 | Train Acc: 99.83%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 88.05%\n",
            "Epoch: 07 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.005 | Train Acc: 99.86%\n",
            "\t Val. Loss: 0.728 |  Val. Acc: 88.25%\n",
            "Epoch: 08 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.006 | Train Acc: 99.79%\n",
            "\t Val. Loss: 0.801 |  Val. Acc: 88.28%\n",
            "Epoch: 09 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.77%\n",
            "\t Val. Loss: 0.730 |  Val. Acc: 88.42%\n",
            "Epoch: 10 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.85%\n",
            "\t Val. Loss: 0.785 |  Val. Acc: 88.12%\n",
            "Epoch: 11 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.006 | Train Acc: 99.81%\n",
            "\t Val. Loss: 0.741 |  Val. Acc: 87.80%\n",
            "Epoch: 12 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.75%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 88.18%\n",
            "Epoch: 13 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.003 | Train Acc: 99.89%\n",
            "\t Val. Loss: 0.791 |  Val. Acc: 88.08%\n",
            "Epoch: 14 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.85%\n",
            "\t Val. Loss: 0.785 |  Val. Acc: 88.18%\n",
            "Epoch: 15 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.86%\n",
            "\t Val. Loss: 0.853 |  Val. Acc: 88.05%\n",
            "Epoch: 16 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.005 | Train Acc: 99.83%\n",
            "\t Val. Loss: 0.840 |  Val. Acc: 87.85%\n",
            "Epoch: 17 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.003 | Train Acc: 99.91%\n",
            "\t Val. Loss: 0.811 |  Val. Acc: 88.10%\n",
            "Epoch: 18 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.002 | Train Acc: 99.91%\n",
            "\t Val. Loss: 0.895 |  Val. Acc: 87.89%\n",
            "Epoch: 19 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.002 | Train Acc: 99.96%\n",
            "\t Val. Loss: 0.915 |  Val. Acc: 88.37%\n",
            "Epoch: 20 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.89%\n",
            "\t Val. Loss: 1.057 |  Val. Acc: 86.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NCi3aILmvZU"
      },
      "source": [
        "## Max accuracy = 88.79%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZeVxkpVNGia"
      },
      "source": [
        "## User Input\n",
        "\n",
        "We can now use our model to predict the sentiment of any sentence we give it. As it has been trained on movie reviews, the sentences provided should also be movie reviews.\n",
        "\n",
        "When using a model for inference it should always be in evaluation mode. If this tutorial is followed step-by-step then it should already be in evaluation mode (from doing `evaluate` on the test set), however we explicitly set it to avoid any risk.\n",
        "\n",
        "Our `predict_sentiment` function does a few things:\n",
        "- sets the model to evaluation mode\n",
        "- tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
        "- indexes the tokens by converting them into their integer representation from our vocabulary\n",
        "- gets the length of our sequence\n",
        "- converts the indexes, which are a Python list into a PyTorch tensor\n",
        "- add a batch dimension by `unsqueeze`ing \n",
        "- converts the length into a tensor\n",
        "- squashes the output prediction from a real number between 0 and 1 with the `sigmoid` function\n",
        "- converts the tensor holding a single value into an integer with the `item()` method\n",
        "\n",
        "We are expecting reviews with a negative sentiment to return a value close to 0 and positive reviews to return a value close to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJaCZ9XLNGia"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kox1_cKDNGid"
      },
      "source": [
        "An example negative review..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uYMZk4ENGie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4b9306-738f-4235-f48f-de009a47c329"
      },
      "source": [
        "predict_sentiment(model, \"This film is terrible\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002504574367776513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-JOtouqNGii"
      },
      "source": [
        "An example positive review..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDWK2rjHNGii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24b6189-1205-4c9f-9ed1-bb3c3694bb54"
      },
      "source": [
        "predict_sentiment(model, \"Can a romantic movie be any worse than this!\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001538451761007309"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uKy8qyEnANY",
        "outputId": "91525742-0aaf-49bb-b092-a277c438f561"
      },
      "source": [
        "predict_sentiment(model, \"The movie was so bad that you would want to watch it over and over again to understand how can some one make one\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2725890576839447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWrEXQ2NnUXJ",
        "outputId": "0b46ab5f-3c32-42ef-daba-0844848125a6"
      },
      "source": [
        "predict_sentiment(model, \"If you haven't watched this movie yet you are making a terrible mistake\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0005374264437705278"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}